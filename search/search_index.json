{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Welcome to weather tools","text":"<p>A Python package and command-line interface for working with weather data operations.</p> <p>This package provides both a Python API and a powerful CLI for loading and using SILO weather data from local netCDF files.</p>"},{"location":"#features","title":"Features","text":"<ul> <li>Dual Mode Access: Query SILO API directly or work with local NetCDF files</li> <li>Command-Line Interface: Simple commands for both online API and offline data</li> <li>Python API: Programmatic access to SILO data using xarray</li> <li>Multiple Data Sources: PatchedPoint (station) and DataDrill (gridded) datasets</li> <li>Flexible Output: Export data to CSV, JSON, APSIM, or standard formats</li> <li>Station Search: Find weather stations by name or proximity</li> <li>Easy Installation: Use with <code>uvx</code> for zero-installation usage</li> </ul>"},{"location":"#quick-start","title":"Quick Start","text":""},{"location":"#cli-usage","title":"CLI Usage","text":"<p>SILO API (Online - requires API key):</p> <pre><code># Query station data\nuvx git+https://github.com/harryeslick/weather_tools.git silo patched-point \\\n  --station 30043 --start-date 2023-01-01 --end-date 2023-01-31 \\\n  --output station_data.csv\n\n# Query gridded data  \nuvx git+https://github.com/harryeslick/weather_tools.git silo data-drill \\\n  --lat -27.5 --lon 153.0 --start-date 2023-01-01 --end-date 2023-01-31 \\\n  --output brisbane_2023.csv\n</code></pre> <p>Local NetCDF files (Offline):</p> <pre><code># Extract weather data for Brisbane from local files\nuvx git+https://github.com/harryeslick/weather_tools.git local extract \\\n  --lat -27.5 --lon 153.0 \\\n  --start-date 2020-01-01 --end-date 2020-12-31 \\\n  --output brisbane_2020.csv\n</code></pre>"},{"location":"#python-api","title":"Python API","text":"<pre><code>from weather_tools import read_silo_xarray\n\n# Load daily weather variables\nds = read_silo_xarray(variables=\"daily\")\n\n# Extract data for a specific location and date range\ndf = ds.sel(lat=-27.5, lon=153.0, method=\"nearest\").sel(\n    time=slice(\"2020-01-01\", \"2020-12-31\")\n).to_dataframe().reset_index()\n</code></pre>"},{"location":"#documentation-sections","title":"Documentation Sections","text":"<ul> <li>CLI Reference: Complete command-line interface documentation</li> <li>API Reference: Python API documentation  </li> <li>Examples: Jupyter notebook examples</li> </ul>"},{"location":"#data-requirements","title":"Data Requirements","text":"<p>To use this package you will need to download the netCDF files which you require from SILO:</p> <ul> <li>Data Source: SILO Gridded Data</li> <li>AWS S3 Index: Complete file list</li> </ul>"},{"location":"CHANGELOG/","title":"Changelog","text":"<p>All notable changes to this project will be documented in this file.</p> <p>The format is based on Keep a Changelog,</p>"},{"location":"CHANGELOG/#002-2025-05-05","title":"[0.0.2] - 2025-05-05","text":""},{"location":"CHANGELOG/#added","title":"Added","text":"<ul> <li>Read silo data from local netCDF files using Xarray</li> </ul>"},{"location":"cli/","title":"Command Line Interface (CLI)","text":"<p>The weather-tools package provides a powerful command-line interface for working with SILO weather data. You can query data directly from the SILO API or extract data from local netCDF files.</p>"},{"location":"cli/#installation","title":"Installation","text":""},{"location":"cli/#using-uv-recommended","title":"Using uv (Recommended)","text":"<pre><code># Install with uv\nuv pip install weather-tools\n\n# Or run directly with uvx (no installation)\nuvx weather-tools --help\n</code></pre>"},{"location":"cli/#using-pip","title":"Using pip","text":"<pre><code># Install from local directory\npip install -e .\n\n# Or install from GitHub\npip install git+https://github.com/harryeslick/weather_tools.git\n</code></pre> <p>After installation, the <code>weather-tools</code> command will be available.</p>"},{"location":"cli/#commands-overview","title":"Commands Overview","text":"<p>The CLI provides two command groups:</p>"},{"location":"cli/#silo-api-commands-online","title":"SILO API Commands (Online)","text":"<ul> <li><code>silo patched-point</code> - Query SILO PatchedPoint dataset (station-based data)</li> <li><code>silo data-drill</code> - Query SILO DataDrill dataset (gridded data)</li> <li><code>silo search</code> - Search for SILO stations by name or find nearby stations</li> </ul>"},{"location":"cli/#local-netcdf-commands-offline","title":"Local NetCDF Commands (Offline)","text":"<ul> <li><code>local info</code> - Display information about available local SILO data</li> <li><code>local extract</code> - Extract weather data from local netCDF files</li> </ul>"},{"location":"cli/#quick-start-examples","title":"Quick Start Examples","text":""},{"location":"cli/#query-silo-api-no-downloads-required","title":"Query SILO API (No Downloads Required)","text":"<pre><code># Set your API key\nexport SILO_API_KEY=\"your_api_key_here\"\n\n# Query station data (PatchedPoint)\nweather-tools silo patched-point --station 30043 \\\n  --start-date 2023-01-01 --end-date 2023-01-31 --output data.csv\n\n# Query gridded data (DataDrill)\nweather-tools silo data-drill --latitude -27.5 --longitude 151.0 \\\n  --start-date 2023-01-01 --end-date 2023-01-31 --output gridded_data.csv\n\n# Search for stations\nweather-tools silo search --name \"Brisbane\"\nweather-tools silo search --station 30043 --radius 50\n</code></pre>"},{"location":"cli/#use-local-netcdf-files","title":"Use Local NetCDF Files","text":"<pre><code># Display available local SILO data\nweather-tools local info\n\n# Extract data from local files\nweather-tools local extract --lat -27.5 --lon 153.0 \\\n  --start-date 2020-01-01 --end-date 2020-12-31 \\\n  --output brisbane_2020.csv\n</code></pre>"},{"location":"cli/#command-reference","title":"Command Reference","text":""},{"location":"cli/#global-options","title":"Global Options","text":"<pre><code>Usage: weather-tools [OPTIONS] COMMAND [ARGS]...\n\nCommands:\n  silo      Query SILO API directly (requires API key)\n  info      Display information about available local SILO data\n  extract   Extract weather data from local netCDF files\n\nOptions:\n  --install-completion    Install completion for the current shell\n  --show-completion      Show completion for the current shell\n  --help                 Show this message and exit\n</code></pre>"},{"location":"cli/#silo-api-commands","title":"SILO API Commands","text":"<p>These commands query the SILO API directly - no local files required!</p>"},{"location":"cli/#silo-patched-point-command","title":"<code>silo patched-point</code> Command","text":"<p>Query the SILO PatchedPoint dataset for station-based weather data.</p> <pre><code>weather-tools silo patched-point [OPTIONS]\n</code></pre>"},{"location":"cli/#required-options","title":"Required Options","text":"Option Type Description <code>--station</code> TEXT Station code (e.g., 30043) <code>--start-date</code> TEXT Start date (YYYY-MM-DD) <code>--end-date</code> TEXT End date (YYYY-MM-DD)"},{"location":"cli/#optional-parameters","title":"Optional Parameters","text":"Option Type Description Default <code>--format</code> TEXT Output format: 'csv', 'json', 'apsim', 'standard' Auto-detected from output filename <code>--var</code> TEXT Weather variables (e.g. daily_rain, max_temp) (can be used multiple times) All available <code>--output</code> PATH Output filename Required <code>--api-key</code> TEXT SILO API key (or set SILO_API_KEY env var)"},{"location":"cli/#examples","title":"Examples","text":"<pre><code># Basic station data query\nweather-tools silo patched-point --station 30043 \\\n    --start-date 2023-01-01 --end-date 2023-01-31 \\\n    --output data.csv\n\n# Query with specific variables\nweather-tools silo patched-point --station 30043 \\\n    --start-date 2023-01-01 --end-date 2023-01-31 \\\n    --var daily_rain --var max_temp --var min_temp \\\n    --output station_data.csv\n\n# Auto-detect format from extension\nweather-tools silo patched-point --station 30043 \\\n    --start-date 2023-01-01 --end-date 2023-01-31 \\\n    --output data.json  # Automatically uses JSON format\n</code></pre>"},{"location":"cli/#silo-data-drill-command","title":"<code>silo data-drill</code> Command","text":"<p>Query the SILO DataDrill dataset for gridded weather data.</p> <pre><code>weather-tools silo data-drill [OPTIONS]\n</code></pre>"},{"location":"cli/#required-options_1","title":"Required Options","text":"Option Type Description <code>--latitude</code> FLOAT Latitude coordinate <code>--longitude</code> FLOAT Longitude coordinate <code>--start-date</code> TEXT Start date (YYYY-MM-DD) <code>--end-date</code> TEXT End date (YYYY-MM-DD)"},{"location":"cli/#optional-parameters_1","title":"Optional Parameters","text":"Option Type Description Default <code>--format</code> TEXT Output format: 'csv', 'json', 'apsim', 'standard' Auto-detected from output filename <code>--var</code> TEXT Weather variables (can be used multiple times) All available <code>--output</code> PATH Output filename Required <code>--api-key</code> TEXT SILO API key (or set SILO_API_KEY env var)"},{"location":"cli/#examples_1","title":"Examples","text":"<pre><code># Query gridded data for Brisbane\nweather-tools silo data-drill --latitude -27.5 --longitude 153.0 \\\n    --start-date 2023-01-01 --end-date 2023-01-31 \\\n    --output brisbane_weather.csv\n\n# Query with APSIM format\nweather-tools silo data-drill --latitude -27.5 --longitude 153.0 \\\n    --start-date 2023-01-01 --end-date 2023-01-31 \\\n    --output weather.apsim  # Auto-detects APSIM format\n</code></pre>"},{"location":"cli/#silo-search-command","title":"<code>silo search</code> Command","text":"<p>Search for SILO weather stations by name or find stations near a location.</p> <pre><code>weather-tools silo search [OPTIONS]\n</code></pre>"},{"location":"cli/#search-options-choose-one","title":"Search Options (choose one)","text":"Option Type Description <code>--name</code> TEXT Search stations by name <code>--station</code> TEXT Find stations near this station code <code>--lat</code> FLOAT Latitude for proximity search (requires --lon) <code>--lon</code> FLOAT Longitude for proximity search (requires --lat)"},{"location":"cli/#optional-parameters_2","title":"Optional Parameters","text":"Option Type Description Default <code>--radius</code> FLOAT Search radius in km <code>50.0</code> <code>--api-key</code> TEXT SILO API key (or set SILO_API_KEY env var) <code>--output</code> TEXT Output filename (optional)"},{"location":"cli/#examples_2","title":"Examples","text":"<pre><code># Search by station name\nweather-tools silo search --name \"Brisbane\"\n\n# Find stations near a specific station\nweather-tools silo search --station 30043 --radius 50\n\n# Find stations near coordinates\nweather-tools silo search --lat -27.5 --lon 153.0 --radius 100\n\n# Save results to file\nweather-tools silo search --name \"Sydney\" --output sydney_stations.txt\n</code></pre>"},{"location":"cli/#setting-your-api-key","title":"Setting Your API Key","text":"<p>For security, it's best to set your API key as an environment variable:</p> <pre><code># In your terminal or .bashrc/.zshrc\nexport SILO_API_KEY=\"your_api_key_here\"\n\n# Then you can use commands without --api-key option\nweather-tools silo patched-point --station 30043 ...\n</code></pre> <p>Or create a <code>.env</code> file in your project:</p> <pre><code># .env file\nSILO_API_KEY=your_api_key_here\n</code></pre>"},{"location":"cli/#local-netcdf-commands","title":"Local NetCDF Commands","text":"<p>These commands work with downloaded SILO gridded data files.</p>"},{"location":"cli/#local-info-command","title":"<code>local info</code> Command","text":"<p>Display information about available SILO data directories and files.</p> <pre><code>weather-tools local info [OPTIONS]\n</code></pre>"},{"location":"cli/#options","title":"Options","text":"Option Type Description Default <code>--silo-dir</code> PATH Path to SILO data directory <code>~/DATA/silo_grids</code> <code>--help</code> Show help message and exit"},{"location":"cli/#example-usage","title":"Example Usage","text":"<pre><code># Show info for default SILO directory\nweather-tools local info\n\n# Show info for custom SILO directory\nweather-tools local info --silo-dir /path/to/my/silo/data\n</code></pre>"},{"location":"cli/#sample-output","title":"Sample Output","text":"<pre><code>SILO data directory: /Users/user/Developer/DATA/silo_grids\n\n\ud83d\udcc1 Available variable directories:\n  \ud83d\udcc2 daily_rain: 25 files\n    \ud83d\udcc5 Years: 2000-2024\n  \ud83d\udcc2 evap_syn: 25 files\n    \ud83d\udcc5 Years: 2000-2024\n  \ud83d\udcc2 max_temp: 25 files\n    \ud83d\udcc5 Years: 2000-2024\n  \ud83d\udcc2 min_temp: 25 files\n    \ud83d\udcc5 Years: 2000-2024\n  \ud83d\udcc2 monthly_rain: 136 files\n    \ud83d\udcc5 Years: 1889-2024\n</code></pre>"},{"location":"cli/#local-extract-command","title":"<code>local extract</code> Command","text":"<p>Extract weather data for a specific location and date range, saving results to CSV.</p> <pre><code>weather-tools local extract [OPTIONS]\n</code></pre>"},{"location":"cli/#required-options_2","title":"Required Options","text":"Option Type Description <code>--lat</code> FLOAT Latitude coordinate (required) <code>--lon</code> FLOAT Longitude coordinate (required) <code>--start-date</code> TEXT Start date in YYYY-MM-DD format (required) <code>--end-date</code> TEXT End date in YYYY-MM-DD format (required)"},{"location":"cli/#optional-options","title":"Optional Options","text":"Option Type Description Default <code>--output</code> TEXT Output CSV filename <code>weather_data.csv</code> <code>--variables</code> TEXT Weather variables to extract (see below) <code>daily</code> <code>--silo-dir</code> PATH Path to SILO data directory <code>~/DATA/silo_grids</code> <code>--tolerance</code> FLOAT Maximum distance (in degrees) for nearest neighbor selection <code>0.1</code> <code>--keep-location</code> BOOLEAN Keep location columns (crs, lat, lon) in output CSV <code>False</code> (columns are dropped by default) <code>--help</code> Show help message and exit"},{"location":"cli/#variable-options","title":"Variable Options","text":"<p>The <code>--variables</code> option accepts the following values:</p> Value Variables Included Description <code>daily</code> max_temp, min_temp, daily_rain, evap_syn Daily weather variables (default) <code>monthly</code> monthly_rain Monthly rainfall data Individual variables Any combination of: <code>max_temp</code>, <code>min_temp</code>, <code>daily_rain</code>, <code>evap_syn</code>, <code>monthly_rain</code> Specify individual variables"},{"location":"cli/#example-usage_1","title":"Example Usage","text":""},{"location":"cli/#basic-extraction","title":"Basic Extraction","text":"<pre><code># Extract daily variables for Brisbane in 2020\nweather-tools local extract --lat -27.5 --lon 153.0 --start-date 2020-01-01 --end-date 2020-12-31\n</code></pre>"},{"location":"cli/#monthly-data","title":"Monthly Data","text":"<pre><code># Extract monthly rainfall data\nweather-tools local extract \\\n  --lat -27.5 --lon 153.0 \\\n  --start-date 2020-01-01 --end-date 2020-12-31 \\\n  --variables monthly \\\n  --output monthly_rainfall.csv\n</code></pre>"},{"location":"cli/#specific-variables","title":"Specific Variables","text":"<pre><code># Extract only temperature data\nweather-tools local extract \\\n  --lat -27.5 --lon 153.0 \\\n  --start-date 2020-01-01 --end-date 2020-12-31 \\\n  --variables max_temp --variables min_temp \\\n  --output temperatures.csv\n</code></pre>"},{"location":"cli/#custom-directory-and-output","title":"Custom Directory and Output","text":"<pre><code># Use custom SILO directory and output file\nweather-tools local extract \\\n  --lat -27.5 --lon 153.0 \\\n  --start-date 2020-01-01 --end-date 2020-12-31 \\\n  --silo-dir /path/to/my/silo/data \\\n  --output custom_weather_data.csv\n</code></pre>"},{"location":"cli/#using-custom-tolerance","title":"Using Custom Tolerance","text":"<pre><code># Use stricter tolerance (0.01 degrees \u2248 1.1 km)\nweather-tools local extract \\\n  --lat -27.5 --lon 153.0 \\\n  --start-date 2020-01-01 --end-date 2020-12-31 \\\n  --tolerance 0.01\n\n# Use more permissive tolerance (0.5 degrees \u2248 55 km)\nweather-tools local extract \\\n  --lat -27.5 --lon 153.0 \\\n  --start-date 2020-01-01 --end-date 2020-12-31 \\\n  --tolerance 0.5\n</code></pre>"},{"location":"cli/#keeping-location-columns","title":"Keeping Location Columns","text":"<p>By default, location columns (crs, lat, lon) are dropped from the output CSV. Use <code>--keep-location</code> to retain them:</p> <pre><code># Keep location columns in output\nweather-tools local extract \\\n  --lat -27.5 --lon 153.0 \\\n  --start-date 2020-01-01 --end-date 2020-12-31 \\\n  --keep-location \\\n  --output data_with_coords.csv\n</code></pre>"},{"location":"cli/#sample-output_1","title":"Sample Output","text":"<pre><code>Loading SILO data from: /Users/user/Developer/DATA/silo_grids\nVariables: daily\nLoading SILO dataset...  [####################################]  100%\nExtracting data for location: lat=-27.5, lon=153.0\nDate range: 2020-01-01 to 2020-12-31\n\u2705 Data extracted successfully!\n\ud83d\udcca Shape: 366 rows, 5 columns\n\ud83d\udcbe Saved to: /path/to/weather_data.csv\n\n\ud83d\udccb Preview (first 5 rows):\n        time  max_temp  min_temp  daily_rain  evap_syn\n0 2020-01-01      30.5      21.7         0.1       7.6\n1 2020-01-02      31.0      21.0         0.0       7.2\n2 2020-01-03      31.1      20.2         0.0       7.7\n3 2020-01-04      31.7      20.4         0.0       8.1\n4 2020-01-05      32.1      19.8         0.0       8.1\n</code></pre>"},{"location":"cli/#output-format","title":"Output Format","text":"<p>The CLI generates CSV files with the following structure:</p> Column Description <code>time</code> Date/time index (YYYY-MM-DD format) <code>lat</code> Latitude (nearest grid point to your coordinates) - dropped by default <code>lon</code> Longitude (nearest grid point to your coordinates) - dropped by default <code>crs</code> Coordinate reference system information - dropped by default Weather variables Columns for each requested variable (e.g., <code>max_temp</code>, <code>min_temp</code>, <code>daily_rain</code>, <code>evap_syn</code>) <p>Location Columns</p> <p>By default, the <code>crs</code>, <code>lat</code>, and <code>lon</code> columns are dropped from the output CSV to reduce file size. Use the <code>--keep-location</code> flag if you need these columns in your output.</p>"},{"location":"cli/#units","title":"Units","text":"Variable Units Description <code>max_temp</code> \u00b0C Maximum temperature <code>min_temp</code> \u00b0C Minimum temperature <code>daily_rain</code> mm Daily rainfall <code>evap_syn</code> mm Synthetic evaporation <code>monthly_rain</code> mm Monthly rainfall"},{"location":"cli/#data-requirements","title":"Data Requirements","text":""},{"location":"cli/#expected-directory-structure","title":"Expected Directory Structure","text":"<p>The CLI expects SILO data to be organized as follows:</p> <pre><code>~/DATA/silo_grids/\n\u251c\u2500\u2500 daily_rain/\n\u2502   \u251c\u2500\u2500 2020.daily_rain.nc\n\u2502   \u251c\u2500\u2500 2021.daily_rain.nc\n\u2502   \u2514\u2500\u2500 ...\n\u251c\u2500\u2500 evap_syn/\n\u2502   \u251c\u2500\u2500 2020.evap_syn.nc\n\u2502   \u251c\u2500\u2500 2021.evap_syn.nc\n\u2502   \u2514\u2500\u2500 ...\n\u251c\u2500\u2500 max_temp/\n\u2502   \u251c\u2500\u2500 2020.max_temp.nc\n\u2502   \u251c\u2500\u2500 2021.max_temp.nc\n\u2502   \u2514\u2500\u2500 ...\n\u251c\u2500\u2500 min_temp/\n\u2502   \u251c\u2500\u2500 2020.min_temp.nc\n\u2502   \u251c\u2500\u2500 2021.min_temp.nc\n\u2502   \u2514\u2500\u2500 ...\n\u2514\u2500\u2500 monthly_rain/\n    \u251c\u2500\u2500 2020.monthly_rain.nc\n    \u251c\u2500\u2500 2021.monthly_rain.nc\n    \u2514\u2500\u2500 ...\n</code></pre>"},{"location":"cli/#downloading-silo-data","title":"Downloading SILO Data","text":"<p>To use this package, you need to download the netCDF files from SILO:</p> <ul> <li>Data Source: SILO Gridded Data</li> <li>AWS S3 Index: Complete file list</li> </ul>"},{"location":"cli/#tips-and-best-practices","title":"Tips and Best Practices","text":""},{"location":"cli/#performance","title":"Performance","text":"<ul> <li>Start small: Test with short date ranges first (e.g., 1 month) before extracting large datasets</li> <li>Use specific variables: Only extract the variables you need to reduce processing time</li> <li>Monitor disk space: Large date ranges can generate substantial CSV files</li> </ul>"},{"location":"cli/#date-formats","title":"Date Formats","text":"<ul> <li>Always use YYYY-MM-DD format for dates</li> <li>Ensure your date range falls within the available data years</li> <li>Use the <code>info</code> command to check available years for each variable</li> </ul>"},{"location":"cli/#coordinate-selection","title":"Coordinate Selection","text":"<ul> <li>The CLI automatically selects the nearest grid point to your coordinates</li> <li>SILO data has approximately 5km resolution</li> <li>Coordinates are returned in the output to show the actual grid point used</li> </ul>"},{"location":"cli/#tolerance-parameter","title":"Tolerance Parameter","text":"<p>The <code>--tolerance</code> parameter controls the maximum distance (in degrees) for nearest neighbor selection:</p> <ul> <li>Default value: 0.1 degrees (approximately 11 km)</li> <li>Purpose: Prevents selection of grid points that are too far from your requested coordinates</li> <li>When to adjust:</li> <li>Use smaller values (e.g., 0.01) when you need strict spatial accuracy</li> <li>Use larger values (e.g., 0.5) when working near data boundaries or with sparse grids</li> <li>The selection will fail if no grid point exists within the tolerance distance</li> </ul> <p>Distance reference (at mid-latitudes): - 0.01 degrees \u2248 1.1 km - 0.1 degrees \u2248 11 km (default) - 0.5 degrees \u2248 55 km - 1.0 degrees \u2248 111 km</p> <p>Example scenarios:</p> <pre><code># Strict tolerance for urban planning (must be very close)\nweather-tools local extract --lat -27.5 --lon 153.0 \\\n  --start-date 2020-01-01 --end-date 2020-12-31 \\\n  --tolerance 0.01\n\n# Permissive tolerance for regional analysis\nweather-tools local extract --lat -27.5 --lon 153.0 \\\n  --start-date 2020-01-01 --end-date 2020-12-31 \\\n  --tolerance 0.5\n</code></pre>"},{"location":"cli/#error-handling","title":"Error Handling","text":"<p>The CLI provides informative error messages for common issues:</p> <ul> <li>Invalid date formats</li> <li>Missing SILO data directories</li> <li>Coordinates outside the data extent</li> <li>Network connectivity issues (when using uvx with GitHub)</li> </ul>"},{"location":"cli/#advanced-usage","title":"Advanced Usage","text":""},{"location":"cli/#shell-completion","title":"Shell Completion","text":"<p>Install shell completion for better command-line experience:</p> <pre><code>weather-tools --install-completion\n</code></pre>"},{"location":"cli/#batch-processing","title":"Batch Processing","text":"<p>Use shell scripting for batch processing multiple locations:</p> <pre><code>#!/bin/bash\nlocations=(\n  \"-27.5,153.0,brisbane\"\n  \"-33.9,151.2,sydney\"\n  \"-37.8,144.9,melbourne\"\n)\n\nfor location in \"${locations[@]}\"; do\n  IFS=',' read -r lat lon name &lt;&lt;&lt; \"$location\"\n  weather-tools local extract --lat \"$lat\" --lon \"$lon\" \\\n    --start-date 2020-01-01 --end-date 2020-12-31 \\\n    --output \"${name}_2020.csv\"\ndone\n</code></pre>"},{"location":"cli/#integration-with-python","title":"Integration with Python","text":"<p>Combine CLI output with Python analysis:</p> <pre><code>import pandas as pd\nimport subprocess\n\n# Extract data using CLI\nsubprocess.run([\n    \"weather-tools\", \"extract\",\n    \"--lat\", \"-27.5\", \"--lon\", \"153.0\",\n    \"--start-date\", \"2020-01-01\", \"--end-date\", \"2020-12-31\",\n    \"--output\", \"analysis_data.csv\"\n])\n\n# Load and analyze with pandas\ndf = pd.read_csv(\"analysis_data.csv\")\ndf['time'] = pd.to_datetime(df['time'])\nprint(df.describe())\n</code></pre>"},{"location":"cli_reference/","title":"<code>weather-tools</code>","text":"<p>CLI tool for extracting weather data from SILO datasets (local netCDF files or API)</p> <p>Usage:</p> <pre><code>$ weather-tools [OPTIONS] COMMAND [ARGS]...\n</code></pre> <p>Options:</p> <ul> <li><code>-v, --version</code>: Show version and exit</li> <li><code>--install-completion</code>: Install completion for the current shell.</li> <li><code>--show-completion</code>: Show completion for the current shell, to copy it or customize the installation.</li> <li><code>--help</code>: Show this message and exit.</li> </ul> <p>Commands:</p> <ul> <li><code>silo</code>: Query SILO API directly (requires API key)</li> <li><code>local</code>: Work with local SILO netCDF files</li> <li><code>metno</code>: Query met.no forecast API for Australian...</li> <li><code>geotiff</code>: Work with SILO Cloud-Optimized GeoTIFF files</li> </ul>"},{"location":"cli_reference/#weather-tools-silo","title":"<code>weather-tools silo</code>","text":"<p>Query SILO API directly (requires API key)</p> <p>Usage:</p> <pre><code>$ weather-tools silo [OPTIONS] COMMAND [ARGS]...\n</code></pre> <p>Options:</p> <ul> <li><code>--help</code>: Show this message and exit.</li> </ul> <p>Commands:</p> <ul> <li><code>patched-point</code>: Query SILO PatchedPoint dataset...</li> <li><code>data-drill</code>: Query SILO DataDrill dataset (gridded data).</li> <li><code>search</code>: Search for SILO stations by name or find...</li> </ul>"},{"location":"cli_reference/#weather-tools-silo-patched-point","title":"<code>weather-tools silo patched-point</code>","text":"<p>Query SILO PatchedPoint dataset (station-based data).</p> <p>Format is auto-detected from output filename extension: - .csv \u2192 csv format - .json \u2192 json format - .apsim \u2192 apsim format - .txt \u2192 standard format</p> <p>Use 'weather-tools silo search' to find station codes by name.</p> <p>Examples:     # Get rainfall and temperature for Brisbane Aero (format auto-detected)     weather-tools silo patched-point --station 30043 \\         --start-date 2023-01-01 --end-date 2023-01-31 \\         --var rainfall --var max_temp --var min_temp --output data.csv</p> <pre><code># Get all variables in APSIM format\nweather-tools silo patched-point --station 30043 \\\n    --start-date 2023-01-01 --end-date 2023-01-31 \\\n    --output data.apsim\n\n# Force specific format (extension will be corrected)\nweather-tools silo patched-point --station 30043 \\\n    --start-date 2023-01-01 --end-date 2023-01-31 \\\n    --format json --output data.json\n</code></pre> <p>Usage:</p> <pre><code>$ weather-tools silo patched-point [OPTIONS]\n</code></pre> <p>Options:</p> <ul> <li><code>--station TEXT</code>: BOM station code (e.g., '30043' for Brisbane Aero)  [required]</li> <li><code>--start-date TEXT</code>: Start date (YYYY-MM-DD)  [required]</li> <li><code>--end-date TEXT</code>: End date (YYYY-MM-DD)  [required]</li> <li><code>--format TEXT</code>: Output format: csv, json, apsim, standard (auto-detected from filename if not specified)</li> <li><code>--var TEXT</code>: Climate variables: daily_rain, monthly_rain, max_temp, min_temp, vp, vp_deficit, rh_tmax, rh_tmin, mslp, evap_pan, evap_syn, evap_comb, evap_morton_lake, radiation, et_short_crop, et_tall_crop, et_morton_actual, et_morton_potential, et_morton_wet</li> <li><code>-o, --output TEXT</code>: Output filename</li> <li><code>--api-key TEXT</code>: SILO API key (email address)  [env var: SILO_API_KEY]</li> <li><code>--enable-cache / --no-enable-cache</code>: Enable response caching  [default: no-enable-cache]</li> <li><code>--log-level TEXT</code>: Logging level for SILO client (e.g. INFO, DEBUG, WARNING)  [default: INFO]</li> <li><code>--help</code>: Show this message and exit.</li> </ul>"},{"location":"cli_reference/#weather-tools-silo-data-drill","title":"<code>weather-tools silo data-drill</code>","text":"<p>Query SILO DataDrill dataset (gridded data).</p> <p>Examples:     # Get rainfall for a specific location     weather-tools silo data-drill --latitude -27.5 --longitude 151.0 \\         --start-date 2023-01-01 --end-date 2023-01-31 \\         --var rainfall --output data.csv</p> <pre><code># Get all variables for a location\nweather-tools silo data-drill --latitude -27.5 --longitude 151.0 \\\n    --start-date 2023-01-01 --end-date 2023-01-31 \\\n    --format alldata --output data.txt\n</code></pre> <p>Usage:</p> <pre><code>$ weather-tools silo data-drill [OPTIONS]\n</code></pre> <p>Options:</p> <ul> <li><code>--latitude FLOAT</code>: Latitude in decimal degrees (-44 to -10)  [required]</li> <li><code>--longitude FLOAT</code>: Longitude in decimal degrees (113 to 154)  [required]</li> <li><code>--start-date TEXT</code>: Start date (YYYY-MM-DD)  [required]</li> <li><code>--end-date TEXT</code>: End date (YYYY-MM-DD)  [required]</li> <li><code>--format TEXT</code>: Output format: csv, json, apsim, alldata, standard  [default: csv]</li> <li><code>--var TEXT</code>: Climate variables: daily_rain, monthly_rain, max_temp, min_temp, vp, vp_deficit, rh_tmax, rh_tmin, mslp, evap_pan, evap_syn, evap_comb, evap_morton_lake, radiation, et_short_crop, et_tall_crop, et_morton_actual, et_morton_potential, et_morton_wet</li> <li><code>-o, --output TEXT</code>: Output filename</li> <li><code>--api-key TEXT</code>: SILO API key (email address)  [env var: SILO_API_KEY]</li> <li><code>--enable-cache / --no-enable-cache</code>: Enable response caching  [default: no-enable-cache]</li> <li><code>--log-level TEXT</code>: Logging level for SILO client (e.g. INFO, DEBUG, WARNING)  [default: INFO]</li> <li><code>--help</code>: Show this message and exit.</li> </ul>"},{"location":"cli_reference/#weather-tools-silo-search","title":"<code>weather-tools silo search</code>","text":"<p>Search for SILO stations by name or find nearby stations.</p> <p>Examples:     # Search by name     weather-tools silo search --name Brisbane</p> <pre><code># Search by name and filter by state\nweather-tools silo search --name Brisbane --state QLD\n\n# Find nearby stations\nweather-tools silo search --station 30043 --radius 50\n\n# Get station details\nweather-tools silo search --station 30043 --details\n</code></pre> <p>Usage:</p> <pre><code>$ weather-tools silo search [OPTIONS]\n</code></pre> <p>Options:</p> <ul> <li><code>--name TEXT</code>: Search for stations by name fragment (e.g., 'Brisbane')</li> <li><code>--station TEXT</code>: Station code for nearby search or details lookup</li> <li><code>--radius INTEGER</code>: Search radius in km (for nearby search)</li> <li><code>--state [QLD|NSW|VIC|TAS|SA|WA|NT|ACT]</code>: Filter by state (QLD, NSW, VIC, TAS, SA, WA, NT, ACT)</li> <li><code>--details / --no-details</code>: Get detailed info for a specific station  [default: no-details]</li> <li><code>--api-key TEXT</code>: SILO API key (email address)  [env var: SILO_API_KEY]</li> <li><code>-o, --output TEXT</code>: Output filename</li> <li><code>--log-level TEXT</code>: Logging level for SILO client (e.g. INFO, DEBUG, WARNING)  [default: INFO]</li> <li><code>--help</code>: Show this message and exit.</li> </ul>"},{"location":"cli_reference/#weather-tools-local","title":"<code>weather-tools local</code>","text":"<p>Work with local SILO netCDF files</p> <p>Usage:</p> <pre><code>$ weather-tools local [OPTIONS] COMMAND [ARGS]...\n</code></pre> <p>Options:</p> <ul> <li><code>--help</code>: Show this message and exit.</li> </ul> <p>Commands:</p> <ul> <li><code>extract</code>: Extract weather data from local netCDF...</li> <li><code>info</code>: Display information about available local...</li> <li><code>download</code>: Download SILO gridded NetCDF files from...</li> </ul>"},{"location":"cli_reference/#weather-tools-local-extract","title":"<code>weather-tools local extract</code>","text":"<p>Extract weather data from local netCDF files for a specific location and date range.</p> <p>Example:     weather-tools local extract --lat -27.5 --lon 153.0 --start-date 2020-01-01 --end-date 2025-01-01 --output weather.csv</p> <p>Usage:</p> <pre><code>$ weather-tools local extract [OPTIONS]\n</code></pre> <p>Options:</p> <ul> <li><code>--lat FLOAT</code>: Latitude coordinate  [required]</li> <li><code>--lon FLOAT</code>: Longitude coordinate  [required]</li> <li><code>--start-date TEXT</code>: Start date (YYYY-MM-DD format)  [required]</li> <li><code>--end-date TEXT</code>: End date (YYYY-MM-DD format)  [required]</li> <li><code>--output TEXT</code>: Output CSV filename  [default: weather_data.csv]</li> <li><code>--variables TEXT</code>: Weather variables to extract. Use 'daily' or 'monthly' for presets, or specify individual variables</li> <li><code>--silo-dir PATH</code>: Path to SILO data directory</li> <li><code>--tolerance FLOAT</code>: Maximum distance (in degrees) for nearest neighbor selection  [default: 0.1]</li> <li><code>--keep-location / --no-keep-location</code>: Keep location columns (crs, lat, lon) in output CSV  [default: no-keep-location]</li> <li><code>--help</code>: Show this message and exit.</li> </ul>"},{"location":"cli_reference/#weather-tools-local-info","title":"<code>weather-tools local info</code>","text":"<p>Display information about available local SILO data.</p> <p>Usage:</p> <pre><code>$ weather-tools local info [OPTIONS]\n</code></pre> <p>Options:</p> <ul> <li><code>--silo-dir PATH</code>: Path to SILO data directory</li> <li><code>--help</code>: Show this message and exit.</li> </ul>"},{"location":"cli_reference/#weather-tools-local-download","title":"<code>weather-tools local download</code>","text":"<p>Download SILO gridded NetCDF files from AWS S3.</p> <p>Files are organized in the same structure expected by 'weather-tools local extract':     output_dir/     \u251c\u2500\u2500 daily_rain/     \u2502   \u251c\u2500\u2500 2020.daily_rain.nc     \u2502   \u2514\u2500\u2500 2021.daily_rain.nc     \u251c\u2500\u2500 max_temp/     \u2502   \u2514\u2500\u2500 ...     \u2514\u2500\u2500 ...</p> <p>By default, existing files are skipped. Use --force to re-download.</p> <p>Examples:     # Download daily variables for 2020-2023     weather-tools local download --var daily --start-year 2020 --end-year 2023</p> <pre><code># Download specific variables\nweather-tools local download --var daily_rain --var max_temp \\\n    --start-year 2022 --end-year 2023\n\n# Download to custom directory\nweather-tools local download --var monthly \\\n    --start-year 2020 --end-year 2023 \\\n    --silo-dir /data/silo_grids\n\n# Force re-download existing files\nweather-tools local download --var daily_rain \\\n    --start-year 2023 --end-year 2023 --force\n</code></pre> <p>Usage:</p> <pre><code>$ weather-tools local download [OPTIONS]\n</code></pre> <p>Options:</p> <ul> <li><code>--start-year INTEGER</code>: First year to download (inclusive)  [required]</li> <li><code>--end-year INTEGER</code>: Last year to download (inclusive)  [required]</li> <li><code>--var [daily_rain|monthly_rain|max_temp|min_temp|vp|vp_deficit|rh_tmax|rh_tmin|mslp|evap_pan|evap_syn|evap_comb|evap_morton_lake|radiation|et_short_crop|et_tall_crop|et_morton_actual|et_morton_potential|et_morton_wet|wind_speed|wind_speed_max|cloud_fraction|weather_symbol]</code>: Variable names (daily_rain, max_temp, etc.) or presets (daily, monthly). Can specify multiple.</li> <li><code>--silo-dir PATH</code>: Output directory for downloaded files</li> <li><code>--force / --no-force</code>: Overwrite existing files  [default: no-force]</li> <li><code>--timeout INTEGER</code>: Download timeout in seconds  [default: 600]</li> <li><code>--help</code>: Show this message and exit.</li> </ul>"},{"location":"cli_reference/#weather-tools-metno","title":"<code>weather-tools metno</code>","text":"<p>Query met.no forecast API for Australian locations</p> <p>Usage:</p> <pre><code>$ weather-tools metno [OPTIONS] COMMAND [ARGS]...\n</code></pre> <p>Options:</p> <ul> <li><code>--help</code>: Show this message and exit.</li> </ul> <p>Commands:</p> <ul> <li><code>forecast</code>: Get met.no weather forecast for an...</li> <li><code>merge</code>: Merge SILO historical data with met.no...</li> <li><code>info</code>: Display information about the met.no API...</li> </ul>"},{"location":"cli_reference/#weather-tools-metno-forecast","title":"<code>weather-tools metno forecast</code>","text":"<p>Get met.no weather forecast for an Australian location.</p> <p>Retrieves up to 9 days of forecast data from met.no's locationforecast API. Daily summaries are automatically aggregated from hourly forecasts.</p> <p>Example:     weather-tools metno forecast --lat -27.5 --lon 153.0 --days 7 --output brisbane_forecast.csv</p> <p>Usage:</p> <pre><code>$ weather-tools metno forecast [OPTIONS]\n</code></pre> <p>Options:</p> <ul> <li><code>--lat FLOAT</code>: Latitude coordinate (-9 to -44 for Australia)  [required]</li> <li><code>--lon FLOAT</code>: Longitude coordinate (113 to 154 for Australia)  [required]</li> <li><code>--days INTEGER</code>: Number of forecast days (1-9)  [default: 7]</li> <li><code>--output TEXT</code>: Output CSV filename (optional)</li> <li><code>--format-silo / --no-format-silo</code>: Convert to SILO column names  [default: format-silo]</li> <li><code>--user-agent TEXT</code>: Custom User-Agent for met.no API</li> <li><code>--help</code>: Show this message and exit.</li> </ul>"},{"location":"cli_reference/#weather-tools-metno-merge","title":"<code>weather-tools metno merge</code>","text":"<p>Merge SILO historical data with met.no forecast data.</p> <p>Combines historical observations from SILO DataDrill API with met.no forecast data for seamless downstream analysis.</p> <p>Example:     weather-tools metno merge --lat -27.5 --lon 153.0 \\         --start-date 2023-01-01 --end-date 2023-12-31 \\         --forecast-days 7 --output combined_weather.csv</p> <p>Usage:</p> <pre><code>$ weather-tools metno merge [OPTIONS]\n</code></pre> <p>Options:</p> <ul> <li><code>--lat FLOAT</code>: Latitude coordinate (-9 to -44 for Australia)  [required]</li> <li><code>--lon FLOAT</code>: Longitude coordinate (113 to 154 for Australia)  [required]</li> <li><code>--start-date TEXT</code>: Historical data start date (YYYY-MM-DD)  [required]</li> <li><code>--end-date TEXT</code>: Historical data end date (YYYY-MM-DD)  [required]</li> <li><code>--output TEXT</code>: Output CSV filename  [required]</li> <li><code>--forecast-days INTEGER</code>: Number of forecast days to append (1-9)  [default: 7]</li> <li><code>--api-key TEXT</code>: SILO API key (email address)  [env var: SILO_API_KEY]</li> <li><code>--fill-missing / --no-fill-missing</code>: Fill missing SILO variables with estimates  [default: no-fill-missing]</li> <li><code>--enable-cache / --no-enable-cache</code>: Enable response caching for SILO API  [default: no-enable-cache]</li> <li><code>--user-agent TEXT</code>: Custom User-Agent for met.no API</li> <li><code>--log-level TEXT</code>: Logging level for SILO client (e.g. INFO, DEBUG, WARNING)  [default: INFO]</li> <li><code>--help</code>: Show this message and exit.</li> </ul>"},{"location":"cli_reference/#weather-tools-metno-info","title":"<code>weather-tools metno info</code>","text":"<p>Display information about the met.no API and variable mappings.</p> <p>Shows available variables, data coverage, and API details.</p> <p>Usage:</p> <pre><code>$ weather-tools metno info [OPTIONS]\n</code></pre> <p>Options:</p> <ul> <li><code>--help</code>: Show this message and exit.</li> </ul>"},{"location":"cli_reference/#weather-tools-geotiff","title":"<code>weather-tools geotiff</code>","text":"<p>Work with SILO Cloud-Optimized GeoTIFF files</p> <p>Usage:</p> <pre><code>$ weather-tools geotiff [OPTIONS] COMMAND [ARGS]...\n</code></pre> <p>Options:</p> <ul> <li><code>--help</code>: Show this message and exit.</li> </ul> <p>Commands:</p> <ul> <li><code>download</code>: Download SILO GeoTIFF files for a date...</li> </ul>"},{"location":"cli_reference/#weather-tools-geotiff-download","title":"<code>weather-tools geotiff download</code>","text":"<p>Download SILO GeoTIFF files for a date range, optionally clipped to geometry/bbox.</p> <p>Files are organized in the structure:     output_dir/     \u251c\u2500\u2500 daily_rain/     \u2502   \u251c\u2500\u2500 2023/     \u2502   \u2502   \u251c\u2500\u2500 20230101.daily_rain.tif     \u2502   \u2502   \u2514\u2500\u2500 20230102.daily_rain.tif     \u2502   \u2514\u2500\u2500 ...     \u2514\u2500\u2500 ...</p> <p>By default, existing files are skipped. Use --force to re-download.</p> <p>Examples:     # Download entire files for daily rainfall     weather-tools geotiff download \\         --var daily_rain --var max_temp \\         --start-date 2023-01-01 --end-date 2023-01-31</p> <pre><code># Download with bounding box clipping\nweather-tools geotiff download \\\n    --var daily_rain \\\n    --start-date 2023-01-01 --end-date 2023-01-31 \\\n    --bbox 150.5 -28.5 154.0 -26.0\n\n# Download with geometry file clipping\nweather-tools geotiff download \\\n    --var daily_rain \\\n    --start-date 2023-01-01 --end-date 2023-01-31 \\\n    --geometry region.geojson\n</code></pre> <p>Usage:</p> <pre><code>$ weather-tools geotiff download [OPTIONS]\n</code></pre> <p>Options:</p> <ul> <li><code>--start-date TEXT</code>: Start date (YYYY-MM-DD format)  [required]</li> <li><code>--end-date TEXT</code>: End date (YYYY-MM-DD format)  [required]</li> <li><code>--var TEXT</code>: Variable names (daily_rain, max_temp, etc.) or presets (daily, monthly). Can specify multiple.</li> <li><code>--output-dir PATH</code>: Output directory for downloaded GeoTIFF files</li> <li><code>--bbox FLOAT</code>: Bounding box: min_lon min_lat max_lon max_lat (4 values, mutually exclusive with --geometry)</li> <li><code>--geometry PATH</code>: Path to GeoJSON file with Polygon for clipping (mutually exclusive with --bbox)</li> <li><code>--force / --no-force</code>: Overwrite existing files  [default: no-force]</li> <li><code>--help</code>: Show this message and exit.</li> </ul>"},{"location":"merge_weather_data/","title":"Merge Weather Data","text":"<p>The <code>merge_weather_data</code> module bridges SILO historical observations and met.no forecasts. It ensures the datasets align, handles overlaps, and produces a combined time series ready for downstream analytics.</p>"},{"location":"merge_weather_data/#primary-workflow","title":"Primary Workflow","text":"<pre><code>from weather_tools.merge_weather_data import merge_historical_and_forecast, get_merge_summary\n\nmerged = merge_historical_and_forecast(\n    silo_data=silo_dataframe,\n    metno_data=metno_dataframe,\n    transition_date=None,           # auto (last SILO date + 1 day)\n    validate=True,\n    fill_missing=True,\n    overlap_strategy=\"prefer_silo\", # or 'prefer_metno' / 'error'\n)\n\nsummary = get_merge_summary(merged)\n</code></pre>"},{"location":"merge_weather_data/#merge_historical_and_forecast","title":"merge_historical_and_forecast(...)","text":"<p>Orchestrates the entire merge process:</p> <ol> <li>Normalises date columns and sorts both inputs.</li> <li>Optionally validates continuity and critical columns.</li> <li>Applies the requested overlap strategy:</li> <li><code>prefer_silo</code> (default): keep SILO records when dates collide.</li> <li><code>prefer_metno</code>: prefer met.no records for overlaps.</li> <li><code>error</code>: raise <code>MergeValidationError</code> if overlap exists.</li> <li>Converts met.no columns (e.g., <code>min_temperature</code>) into SILO-style columns (<code>min_temp</code>) via <code>prepare_metno_for_merge</code>.</li> <li>Adds metadata columns (<code>data_source</code>, <code>is_forecast</code>, <code>forecast_generated_at</code>).</li> <li>Concatenates, aligns columns, and returns a chronological DataFrame.</li> </ol>"},{"location":"merge_weather_data/#important-flags","title":"Important Flags","text":"<ul> <li><code>transition_date</code>: force the hand-over date if you do not want the automatic transition.</li> <li><code>fill_missing</code>: backfill SILO-only variables in the forecast (radiation, vapour pressure, etc.) using <code>fill_missing_silo_variables</code>.</li> </ul>"},{"location":"merge_weather_data/#validation-utilities","title":"Validation Utilities","text":""},{"location":"merge_weather_data/#validate_merge_compatibility","title":"validate_merge_compatibility(...)","text":"<p>Runs checks before merging:</p> <ul> <li>Ensures <code>date</code> columns exist.</li> <li>Detects gaps or overlaps depending on <code>overlap_strategy</code>.</li> <li>Confirms SILO has <code>min_temp</code>, <code>max_temp</code>, <code>daily_rain</code>.</li> <li>Accepts met.no data in either native (<code>min_temperature</code>) or SILO (<code>min_temp</code>) naming schemes.</li> </ul> <p>Returns <code>(is_valid: bool, issues: List[str])</code>. The merge function raises <code>MergeValidationError</code> when validation fails and <code>validate=True</code>.</p>"},{"location":"merge_weather_data/#validate_date_continuity","title":"validate_date_continuity(...)","text":"<p>Lower-level helper that inspects two DataFrames for gaps or overlaps relative to a maximum allowed gap (default: 1 day).</p>"},{"location":"merge_weather_data/#preparing-metno-data","title":"Preparing met.no Data","text":""},{"location":"merge_weather_data/#prepare_metno_for_merge","title":"prepare_metno_for_merge(...)","text":"<pre><code>from weather_tools.merge_weather_data import prepare_metno_for_merge\n\nprepared = prepare_metno_for_merge(metno_daily_df, silo_history_df, fill_missing=True)\n</code></pre> <ul> <li>Renames met.no columns to their SILO equivalents using <code>convert_metno_to_silo_columns</code>.</li> <li>Adds SILO-specific date columns (<code>day</code>, <code>year</code>) when missing.</li> <li>Optionally fills SILO-only variables by calling <code>fill_missing_silo_variables</code>.</li> </ul>"},{"location":"merge_weather_data/#fill_missing_silo_variables","title":"fill_missing_silo_variables(...)","text":"<p>Supports three strategies when met.no data lacks SILO-only columns:</p> Strategy Behaviour <code>\"default\"</code> Inserts conservative defaults (e.g., <code>radiation=20.0</code>, <code>evap_syn=5.0</code>). <code>\"last_known\"</code> Reuses the last available SILO value when possible. <code>\"median\"</code> Fills using the median from the SILO history. <p>This allows downstream systems expecting complete SILO schema to continue operating.</p>"},{"location":"merge_weather_data/#summaries-and-diagnostics","title":"Summaries and Diagnostics","text":""},{"location":"merge_weather_data/#get_merge_summary","title":"get_merge_summary(...)","text":"<p>Produces quick stats about the merged dataset:</p> <ul> <li>Total record count and per-source counts.</li> <li>Date ranges for SILO and met.no segments.</li> <li>Computed transition date.</li> </ul> <p>Useful for sanity checks or logging after a merge.</p>"},{"location":"merge_weather_data/#exceptions","title":"Exceptions","text":"<ul> <li><code>MergeValidationError</code> \u2014 raised when a merge cannot proceed safely.</li> <li><code>DateGapError</code> \u2014 specialised for gaps between SILO and met.no periods.</li> <li><code>ColumnMismatchError</code> \u2014 raised when required columns are missing.</li> </ul> <p>Handle exceptions to alert users or prompt data remediation.</p>"},{"location":"merge_weather_data/#typical-pipeline","title":"Typical Pipeline","text":"<ol> <li>Fetch SILO history using <code>SiloAPI.get_gridded_data</code> or local NetCDF extracts.</li> <li>Retrieve met.no forecasts with <code>MetNoAPI.to_dataframe(aggregate_to_daily=True)</code>.</li> <li>Call <code>merge_historical_and_forecast</code> and inspect <code>get_merge_summary</code>.</li> <li>Persist or visualise as required.</li> </ol> <p>Check the Forecast example notebook for a live demonstration of this workflow.</p>"},{"location":"metno_api/","title":"Met.no API Client","text":"<p>The <code>metno_api</code> module provides a typed Python client for the met.no locationforecast v2.0 API, making it easy to fetch short-range weather forecasts for any global coordinate. It integrates tightly with the rest of <code>weather_tools</code>, returning Pydantic models and ready-to-use pandas DataFrames.</p>"},{"location":"metno_api/#highlights","title":"Highlights","text":"<ul> <li>\u2705 Pydantic-powered queries via <code>MetNoQuery</code> for validated coordinates and formats.</li> <li>\u2705 Automatic retries, caching, and backoff to keep requests resilient and efficient.</li> <li>\u2705 Convenience helpers to aggregate hourly forecasts into daily summaries.</li> <li>\u2705 DataFrame conversion for both hourly and daily views.</li> <li>\u2705 Seamless hand-off to <code>merge_weather_data.merge_historical_and_forecast</code> for blending with SILO archives.</li> </ul>"},{"location":"metno_api/#requirements","title":"Requirements","text":"<ul> <li>met.no requires a descriptive <code>User-Agent</code> header containing a contact address. The client generates a sensible default (<code>weather-tools/&lt;version&gt; (Python &lt;major&gt;.&lt;minor&gt;)</code>), but you should provide your own identifier in production.</li> <li>Forecast requests do not require authentication, but met.no enforces rate limits\u2014respect their usage policy and cache responses where possible.</li> </ul>"},{"location":"metno_api/#quick-start","title":"Quick Start","text":"<pre><code>from weather_tools.metno_api import MetNoAPI\nfrom weather_tools.metno_models import MetNoFormat, MetNoQuery\nfrom weather_tools.silo_models import AustralianCoordinates\n\n# Configure the client (always include your contact details!)\napi = MetNoAPI(user_agent=\"my-app/1.0 (contact: you@example.com)\")\n\n# Build a query for a location near Sydney Airport\nquery = MetNoQuery(\n    coordinates=AustralianCoordinates(latitude=-33.94, longitude=151.18),\n    format=MetNoFormat.COMPACT,\n)\n\n# Execute and inspect the response metadata\nresponse = api.query_forecast(query)\nprint(response.get_meta())\n</code></pre>"},{"location":"metno_api/#aggregating-to-daily-data","title":"Aggregating to Daily Data","text":"<p>The API returns hourly forecasts in GeoJSON format. Use <code>MetNoAPI.to_dataframe</code> to convert the payload into either daily summaries or the raw hourly table:</p> <pre><code>daily_df = api.to_dataframe(response, aggregate_to_daily=True)\nhourly_df = api.to_dataframe(response, aggregate_to_daily=False)\n</code></pre> <ul> <li>Daily data mirrors the <code>DailyWeatherSummary</code> model, providing min/max temperature, total precipitation, wind statistics, humidity, pressure, cloud cover, and the dominant weather symbol.</li> <li>Hourly data preserves the original timestamps alongside instantaneous variables and precipitation totals for the next 1/6/12 hours.</li> </ul>"},{"location":"metno_api/#convenience-helper-get_daily_forecast","title":"Convenience Helper: <code>get_daily_forecast</code>","text":"<p>For common use cases you can skip manual query construction:</p> <pre><code>daily = api.get_daily_forecast(latitude=-33.94, longitude=151.18, days=7)\n</code></pre> <p>This method returns a list of <code>DailyWeatherSummary</code> models and automatically truncates the forecast horizon (met.no serves up to 9 days).</p>"},{"location":"metno_api/#configuration-options","title":"Configuration Options","text":"<p>Instantiate <code>MetNoAPI</code> with custom behaviour when needed:</p> <pre><code>api = MetNoAPI(\n    user_agent=\"my-app/1.0 (contact: you@example.com)\",\n    timeout=45,\n    max_retries=4,\n    retry_delay=1.5,\n    enable_cache=True,\n    cache_expiry_hours=2,\n    log_level=\"DEBUG\",\n)\n</code></pre> Parameter Type Default Description <code>user_agent</code> str auto Identifies your application to met.no <code>timeout</code> int 30 HTTP timeout in seconds <code>max_retries</code> int 3 Attempts for transient failures <code>retry_delay</code> float 1.0 Base delay for exponential backoff <code>enable_cache</code> bool True In-memory response cache toggle <code>cache_expiry_hours</code> int 1 Lifetime for cached responses <code>log_level</code> str/int INFO Logging level for diagnostics <p>Use <code>clear_cache()</code> and <code>get_cache_size()</code> to manage cached responses explicitly.</p>"},{"location":"metno_api/#error-handling","title":"Error Handling","text":"<p>The client surfaces clear exceptions:</p> <ul> <li><code>MetNoUserAgentError</code> \u2014 missing/invalid User-Agent (met.no returns HTTP 403).</li> <li><code>MetNoRateLimitError</code> \u2014 too many requests (HTTP 429).</li> <li><code>MetNoAPIError</code> \u2014 other HTTP failures or JSON parsing issues.</li> </ul> <p>Wrap network calls accordingly:</p> <pre><code>try:\n    response = api.query_forecast(query)\nexcept MetNoRateLimitError:\n    logger.warning(\"Slow down\u2014met.no rate limit hit\")\nexcept MetNoUserAgentError as e:\n    raise RuntimeError(\"Update your User-Agent\") from e\n</code></pre>"},{"location":"metno_api/#integration-with-silo-data","title":"Integration with SILO Data","text":"<p>Daily summaries pair naturally with SILO history:</p> <pre><code>from weather_tools.merge_weather_data import merge_historical_and_forecast\n\nmerged = merge_historical_and_forecast(\n    silo_data=silo_history_dataframe,\n    metno_data=daily_df,\n    fill_missing=True,\n    overlap_strategy=\"prefer_silo\",\n)\n</code></pre> <p>See Merge Weather Data for a deeper dive into the blending workflow.</p>"},{"location":"metno_api/#additional-resources","title":"Additional Resources","text":"<ul> <li>Met.no API documentation</li> <li>Met.no Models \u2014 Pydantic types used by the client.</li> <li>Forecast example notebook \u2014 end-to-end usage with SILO integration.</li> </ul>"},{"location":"metno_models/","title":"Met.no Data Models","text":"<p>The <code>metno_models</code> module defines the Pydantic models that underpin the met.no integration. They provide validation, serialization helpers, and consistent data structures for both API requests and responses.</p>"},{"location":"metno_models/#metnoformat","title":"MetNoFormat","text":"<pre><code>from weather_tools.metno_models import MetNoFormat\n\nMetNoFormat.COMPACT   # default 9-day forecast with core variables\nMetNoFormat.COMPLETE  # extended payload with percentiles and extra fields\n</code></pre> <p>Use the enum when constructing <code>MetNoQuery</code> or when you need to select the endpoint manually.</p>"},{"location":"metno_models/#metnoquery","title":"MetNoQuery","text":"<p>Represents a validated met.no request:</p> <pre><code>from weather_tools.metno_models import MetNoQuery\nfrom weather_tools.silo_models import AustralianCoordinates\n\nquery = MetNoQuery(\n    coordinates=AustralianCoordinates(latitude=-33.86, longitude=151.21),\n    format=MetNoFormat.COMPACT,\n)\n\nparams = query.to_api_params()\n# {'lat': -33.86, 'lon': 151.21}\n</code></pre>"},{"location":"metno_models/#key-fields","title":"Key Fields","text":"Field Type Description <code>coordinates</code> Any (typically <code>AustralianCoordinates</code>) Validated latitude/longitude pair <code>format</code> <code>MetNoFormat</code> Forecast format (defaults to <code>COMPACT</code>) <p><code>to_api_params()</code> converts the model to the <code>lat</code>, <code>lon</code>, and optional <code>altitude</code> parameters required by met.no.</p>"},{"location":"metno_models/#metnoresponse","title":"MetNoResponse","text":"<p>Wraps the GeoJSON payload returned by met.no and tracks metadata:</p> <pre><code>from weather_tools.metno_models import MetNoResponse\n\nresponse = MetNoResponse(raw_data=payload, format=MetNoFormat.COMPACT, coordinates=query.coordinates)\n\ntimestamps = response.get_timeseries()\nmeta = response.get_meta()\n</code></pre>"},{"location":"metno_models/#fields","title":"Fields","text":"Field Type Description <code>raw_data</code> <code>Dict[str, Any]</code> GeoJSON response <code>format</code> <code>MetNoFormat</code> Format used for the request <code>coordinates</code> Any Coordinates associated with the forecast <code>generated_at</code> <code>datetime</code> Timestamp when the forecast was retrieved (<code>UTC</code>) <p>Utility methods: - <code>get_timeseries()</code> extracts the list of hourly forecast entries. - <code>get_meta()</code> returns the metadata embedded in the GeoJSON properties.</p>"},{"location":"metno_models/#forecasttimestamp","title":"ForecastTimestamp","text":"<p>Describes the data available for a single forecast time step. This model is mostly used internally when constructing daily summaries, but it can help with type hints if you build custom parsers.</p> <p>Important fields include: - <code>time</code> (<code>datetime</code>) \u2014 forecast timestamp (UTC). - Instantaneous variables: <code>air_temperature</code>, <code>relative_humidity</code>, <code>wind_speed</code>, <code>cloud_area_fraction</code>, <code>air_pressure_at_sea_level</code>. - Period values: <code>precipitation_amount</code>, <code>precipitation_period_hours</code>. - <code>weather_symbol</code> \u2014 the symbol code supplied by met.no summaries.</p>"},{"location":"metno_models/#dailyweathersummary","title":"DailyWeatherSummary","text":"<p>Aggregates hourly data into a daily rollup compatible with SILO daily schemata:</p> <pre><code>from weather_tools.metno_models import DailyWeatherSummary\n\nsummary = DailyWeatherSummary(\n    date=date(2024, 10, 12),\n    min_temperature=12.4,\n    max_temperature=23.1,\n    total_precipitation=5.8,\n)\n</code></pre> <p>Fields closely align with the columns produced by <code>MetNoAPI.to_dataframe(aggregate_to_daily=True)</code>:</p> Field Description <code>date</code> Python <code>date</code> for the summary <code>min_temperature</code> / <code>max_temperature</code> Daily temperature extremes (\u00b0C) <code>total_precipitation</code> Total rainfall (mm) <code>avg_wind_speed</code> / <code>max_wind_speed</code> Wind statistics (m/s) <code>avg_relative_humidity</code> Average humidity (%) <code>avg_pressure</code> Sea level pressure (hPa) <code>avg_cloud_fraction</code> Cloud cover (%) <code>dominant_weather_symbol</code> Most common or severe symbol code for the day <p>Use <code>.model_dump()</code> to serialize the summaries for DataFrame construction or downstream storage.</p>"},{"location":"metno_models/#error-hierarchy","title":"Error Hierarchy","text":"<p>The module also declares the exception hierarchy used by the API client:</p> <ul> <li><code>MetNoAPIError</code> \u2014 base exception for request failures.</li> <li><code>MetNoUserAgentError</code> \u2014 raised on HTTP 403 due to missing/invalid User-Agent.</li> <li><code>MetNoRateLimitError</code> \u2014 raised on HTTP 429 when rate limits are exceeded.</li> </ul> <p>Catch these to implement robust retry or messaging logic in your applications.</p>"},{"location":"metno_models/#next-steps","title":"Next Steps","text":"<ul> <li>Read the Met.no API Client guide for request patterns.</li> <li>Combine forecasts with historical data in Merge Weather Data.</li> <li>Explore the Forecast example notebook for an end-to-end workflow.</li> </ul>"},{"location":"silo_api/","title":"SILO API Module","text":"<p>The <code>silo_api</code> module provides a Python interface for querying the SILO (Scientific Information for Land Owners) API directly, allowing you to fetch weather data without downloading large netCDF files.</p>"},{"location":"silo_api/#features","title":"Features","text":"<ul> <li>\u2705 Two dataset types: PatchedPoint (station-based) and DataDrill (gridded)</li> <li>\u2705 Multiple formats: CSV, APSIM, and near-station search</li> <li>\u2705 Automatic retry logic with exponential backoff</li> <li>\u2705 Response caching to reduce redundant API calls</li> <li>\u2705 Date validation ensures correct YYYYMMDD format</li> <li>\u2705 Configurable timeouts and retry behavior</li> <li>\u2705 Comprehensive logging for debugging and monitoring</li> </ul>"},{"location":"silo_api/#installation","title":"Installation","text":"<p>The SILO API module is included with the weather_tools package:</p> <pre><code>pip install weather-tools\n</code></pre>"},{"location":"silo_api/#quick-start","title":"Quick Start","text":""},{"location":"silo_api/#basic-usage","title":"Basic Usage","text":"<pre><code>from weather_tools.silo_api import SiloAPI, SiloAPIError\n\n# Initialize the API client\napi = SiloAPI(api_key=\"your_silo_api_key\")\n\ntry:\n    # Query PatchedPoint data for a station\n    result = api.query(\n        dataset=\"PatchedPoint\",\n        format=\"csv\",\n        station_code=\"30043\",\n        start_date=\"20230101\",\n        end_date=\"20230131\",\n        values=[\"rain\", \"maxtemp\", \"mintemp\"]\n    )\n    print(result)\nexcept SiloAPIError as e:\n    print(f\"API Error: {e}\")\n</code></pre>"},{"location":"silo_api/#datadrill-gridded-data","title":"DataDrill (Gridded Data)","text":"<pre><code># Query DataDrill data for specific coordinates\nresult = api.query(\n    dataset=\"DataDrill\",\n    format=\"csv\",\n    longitude=151.0,\n    latitude=-27.5,\n    start_date=\"20230101\",\n    end_date=\"20230131\",\n    values=[\"rain\", \"maxtemp\", \"mintemp\"]\n)\n</code></pre>"},{"location":"silo_api/#configuration-options","title":"Configuration Options","text":""},{"location":"silo_api/#initialize-with-custom-settings","title":"Initialize with Custom Settings","text":"<pre><code>from weather_tools.silo_api import SiloAPI\n\napi = SiloAPI(\n    api_key=\"your_api_key\",\n    timeout=60,              # Request timeout in seconds (default: 30)\n    max_retries=5,           # Maximum retry attempts (default: 3)\n    retry_delay=2.0,         # Base delay between retries (default: 1.0)\n    enable_cache=True        # Enable response caching (default: False)\n)\n</code></pre>"},{"location":"silo_api/#configuration-parameters","title":"Configuration Parameters","text":"Parameter Type Default Description <code>api_key</code> str Required Your SILO API key <code>timeout</code> float 30 Request timeout in seconds <code>max_retries</code> int 3 Maximum number of retry attempts <code>retry_delay</code> float 1.0 Base delay between retries (exponential backoff) <code>enable_cache</code> bool False Enable response caching"},{"location":"silo_api/#api-methods","title":"API Methods","text":""},{"location":"silo_api/#query","title":"query()","text":"<p>Main method for querying the SILO API.</p> <pre><code>result = api.query(\n    dataset: str,\n    format: str = \"csv\",\n    station_code: Optional[str] = None,\n    longitude: Optional[float] = None,\n    latitude: Optional[float] = None,\n    start_date: Optional[str] = None,\n    end_date: Optional[str] = None,\n    values: Optional[List[str]] = None,\n    radius: Optional[float] = None\n) -&gt; Union[str, Dict[str, Any]]\n</code></pre> <p>Parameters:</p> <ul> <li><code>dataset</code>: 'PatchedPoint' or 'DataDrill'</li> <li><code>format</code>: 'csv', 'apsim', or 'near'</li> <li><code>station_code</code>: SILO station code (required for PatchedPoint)</li> <li><code>longitude</code>, <code>latitude</code>: Location coordinates (required for DataDrill)</li> <li><code>start_date</code>, <code>end_date</code>: Date range in YYYYMMDD format</li> <li><code>values</code>: List of weather variables to request</li> <li><code>radius</code>: Search radius for 'near' format</li> </ul> <p>Returns: - CSV/APSIM data as string - JSON data as dictionary (for non-standard formats)</p> <p>Raises: - <code>ValueError</code>: For invalid parameters - <code>SiloAPIError</code>: For API request failures</p>"},{"location":"silo_api/#cache-management","title":"Cache Management","text":"<pre><code># Get number of cached responses\ncache_size = api.get_cache_size()\n\n# Clear the cache\napi.clear_cache()\n</code></pre>"},{"location":"silo_api/#datasets-and-formats","title":"Datasets and Formats","text":""},{"location":"silo_api/#patchedpoint-dataset","title":"PatchedPoint Dataset","text":"<p>Station-based data with quality-controlled observations.</p> <p>Supported Formats: - <code>csv</code>: Comma-separated values - <code>apsim</code>: APSIM format - <code>near</code>: Find nearby stations</p> <p>Example:</p> <pre><code># CSV format\nresult = api.query(\n    dataset=\"PatchedPoint\",\n    format=\"csv\",\n    station_code=\"30043\",\n    start_date=\"20230101\",\n    end_date=\"20230131\",\n    values=[\"rain\", \"maxtemp\", \"mintemp\"]\n)\n\n# APSIM format\nresult = api.query(\n    dataset=\"PatchedPoint\",\n    format=\"apsim\",\n    station_code=\"30043\",\n    start_date=\"20230101\",\n    end_date=\"20230131\"\n)\n\n# Find nearby stations\nresult = api.query(\n    dataset=\"PatchedPoint\",\n    format=\"near\",\n    station_code=\"30043\",\n    radius=50.0  # Search radius in km\n)\n</code></pre>"},{"location":"silo_api/#datadrill-dataset","title":"DataDrill Dataset","text":"<p>Gridded data interpolated to specific coordinates.</p> <p>Supported Formats: - <code>csv</code>: Comma-separated values - <code>apsim</code>: APSIM format</p> <p>Example:</p> <pre><code>result = api.query(\n    dataset=\"DataDrill\",\n    format=\"csv\",\n    longitude=151.0,\n    latitude=-27.5,\n    start_date=\"20230101\",\n    end_date=\"20230131\",\n    values=[\"rain\", \"maxtemp\", \"mintemp\"]\n)\n</code></pre>"},{"location":"silo_api/#weather-variables","title":"Weather Variables","text":"<p>Common weather variables available from SILO:</p> <ul> <li><code>rain</code>: Daily rainfall (mm)</li> <li><code>maxtemp</code>: Maximum temperature (\u00b0C)</li> <li><code>mintemp</code>: Minimum temperature (\u00b0C)</li> <li><code>vp</code>: Vapor pressure (hPa)</li> <li><code>evap_pan</code>: Class A pan evaporation (mm)</li> <li><code>evap_syn</code>: Synthetic estimate of evaporation (mm)</li> <li><code>evap_comb</code>: Combination of measured and synthetic evaporation (mm)</li> <li><code>radiation</code>: Solar radiation (MJ/m\u00b2)</li> <li><code>rh_tmax</code>: Relative humidity at time of maximum temperature (%)</li> <li><code>rh_tmin</code>: Relative humidity at time of minimum temperature (%)</li> </ul>"},{"location":"silo_api/#error-handling","title":"Error Handling","text":""},{"location":"silo_api/#exception-types","title":"Exception Types","text":"<p>SiloAPIError: Raised for API-related errors</p> <pre><code>from weather_tools.silo_api import SiloAPI, SiloAPIError\n\ntry:\n    result = api.query(...)\nexcept SiloAPIError as e:\n    print(f\"API Error: {e}\")\n</code></pre> <p>ValueError: Raised for invalid input parameters</p> <pre><code>try:\n    result = api.query(\n        dataset=\"InvalidDataset\",\n        format=\"csv\"\n    )\nexcept ValueError as e:\n    print(f\"Invalid parameter: {e}\")\n</code></pre>"},{"location":"silo_api/#common-errors","title":"Common Errors","text":"<p>HTTP Errors (4xx, 5xx):</p> <pre><code>SiloAPIError: HTTP 404: Not Found\n</code></pre> <p>SILO-Specific Errors:</p> <pre><code>SiloAPIError: Sorry, your request was rejected\n</code></pre> <p>Timeout Errors (after retries):</p> <pre><code>SiloAPIError: Request failed after 3 attempts: Connection timeout\n</code></pre> <p>Invalid Dataset:</p> <pre><code>ValueError: Unknown dataset: InvalidDataset. Valid datasets: ['PatchedPoint', 'DataDrill']\n</code></pre> <p>Invalid Date Format:</p> <pre><code>ValueError: start_date must be in YYYYMMDD format (e.g., '20230101'), got: 2023-01-01\n</code></pre> <p>Missing Required Parameters:</p> <pre><code>ValueError: station_code is required for PatchedPoint queries\nValueError: longitude and latitude are required for DataDrill queries\n</code></pre>"},{"location":"silo_api/#advanced-features","title":"Advanced Features","text":""},{"location":"silo_api/#response-caching","title":"Response Caching","text":"<p>Enable caching to avoid redundant API calls:</p> <pre><code>import logging\n\n# Configure logging to see cache activity\nlogging.basicConfig(level=logging.INFO)\n\n# Create API with caching enabled\napi = SiloAPI(api_key=\"your_key\", enable_cache=True)\n\n# First query - hits the API\nresult1 = api.query(\n    dataset=\"PatchedPoint\",\n    station_code=\"30043\",\n    start_date=\"20230101\",\n    end_date=\"20230131\",\n    values=[\"rain\"]\n)\n\n# Second identical query - uses cache\nresult2 = api.query(\n    dataset=\"PatchedPoint\",\n    station_code=\"30043\",\n    start_date=\"20230101\",\n    end_date=\"20230131\",\n    values=[\"rain\"]\n)\n\nprint(f\"Cache size: {api.get_cache_size()}\")  # Output: 1\nprint(f\"Results identical: {result1 == result2}\")  # Output: True\n\n# Clear cache when done\napi.clear_cache()\n</code></pre>"},{"location":"silo_api/#automatic-retries","title":"Automatic Retries","text":"<p>The API automatically retries on transient failures:</p> <pre><code>api = SiloAPI(\n    api_key=\"your_key\",\n    max_retries=5,      # Retry up to 5 times\n    retry_delay=2.0     # 2 second base delay (with exponential backoff)\n)\n\n# API will automatically retry on:\n# - Connection timeouts\n# - Connection errors\n# But NOT on:\n# - HTTP 4xx/5xx errors\n# - SILO-specific rejection messages\n</code></pre>"},{"location":"silo_api/#logging-and-debugging","title":"Logging and Debugging","text":"<p>Enable detailed logging to monitor API activity:</p> <pre><code>import logging\n\n# Configure logging\nlogging.basicConfig(\n    level=logging.DEBUG,  # Show all logs\n    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'\n)\n\napi = SiloAPI(api_key=\"your_key\")\n\n# You'll see detailed logs:\n# - Request attempts\n# - Cache hits/misses\n# - Retry attempts\n# - Success/failure messages\n</code></pre>"},{"location":"silo_api/#production-configuration","title":"Production Configuration","text":"<p>Recommended settings for production use:</p> <pre><code>import os\nimport logging\n\n# Configure logging for production\nlogging.basicConfig(\n    level=logging.INFO,  # Only info and above\n    format='%(asctime)s - %(levelname)s - %(message)s'\n)\n\n# Load API key from environment variable\napi_key = os.getenv(\"SILO_API_KEY\")\n\nif not api_key:\n    raise ValueError(\"SILO_API_KEY environment variable not set\")\n\n# Create production-ready API client\napi = SiloAPI(\n    api_key=api_key,\n    timeout=60,              # Generous timeout\n    max_retries=5,           # More retries for reliability\n    retry_delay=2.0,         # Longer delays between retries\n    enable_cache=True        # Enable caching\n)\n\ntry:\n    result = api.query(...)\n    logging.info(f\"Query successful, cache size: {api.get_cache_size()}\")\nexcept SiloAPIError as e:\n    logging.error(f\"API error: {e}\")\n    # Handle error appropriately\n</code></pre>"},{"location":"silo_api/#cli-usage","title":"CLI Usage","text":"<p>The SILO API functionality is also available via the command-line interface:</p> <pre><code># Query PatchedPoint data\nweather-tools silo patched-point --station 30043 \\\n    --start-date 2023-01-01 --end-date 2023-01-31 \\\n    --var rainfall --var max_temp --var min_temp --output silo_data.csv\n\n# Query DataDrill data\nweather-tools silo data-drill --latitude -27.5 --longitude 151.0 \\\n    --start-date 2023-01-01 --end-date 2023-01-31 \\\n    --var rainfall --var max_temp --output silo_data.csv\n\n# Find nearby stations\nweather-tools silo search --station 30043 --radius 50\n</code></pre> <p>See the CLI Reference for more details.</p>"},{"location":"silo_api/#getting-your-api-key","title":"Getting Your API Key","text":"<p>To use the SILO API, you need to obtain an API key:</p> <ol> <li>Visit the SILO website</li> <li>Register for API access</li> <li>Store your API key securely (use environment variables)</li> </ol> <p>Security Note: Never hardcode your API key in your source code. Use environment variables or secure configuration files:</p> <pre><code>import os\n\n# Load from environment variable\napi_key = os.getenv(\"SILO_API_KEY\")\n\n# Or use python-dotenv\nfrom dotenv import load_dotenv\nload_dotenv()\napi_key = os.getenv(\"SILO_API_KEY\")\n</code></pre>"},{"location":"silo_api/#best-practices","title":"Best Practices","text":"<ol> <li> <p>Use environment variables for API keys <code>python    api_key = os.getenv(\"SILO_API_KEY\")</code></p> </li> <li> <p>Enable caching for repeated queries <code>python    api = SiloAPI(api_key=key, enable_cache=True)</code></p> </li> <li> <p>Set appropriate timeouts    ```python    # Short timeout for quick checks    api = SiloAPI(api_key=key, timeout=10)</p> </li> </ol> <p># Longer timeout for large data downloads    api = SiloAPI(api_key=key, timeout=120)    ```</p> <ol> <li> <p>Handle exceptions appropriately <code>python    try:        result = api.query(...)    except ValueError as e:        # Handle input validation errors        logger.error(f\"Invalid input: {e}\")    except SiloAPIError as e:        # Handle API errors        logger.error(f\"API error: {e}\")</code></p> </li> <li> <p>Use logging in production <code>python    import logging    logging.basicConfig(        level=logging.WARNING,  # Only warnings and errors        format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'    )</code></p> </li> </ol>"},{"location":"silo_api/#data-models","title":"Data Models","text":"<p>The weather_tools package provides Pydantic models for structured API queries:</p>"},{"location":"silo_api/#patchedpointquery","title":"PatchedPointQuery","text":"<p>Model for PatchedPoint dataset queries:</p> <pre><code>from weather_tools import PatchedPointQuery\n\nquery = PatchedPointQuery(\n    station=\"30043\",\n    start_date=\"20230101\",\n    end_date=\"20230131\",\n    variables=[\"R\", \"X\", \"N\"],  # Rain, Max temp, Min temp\n    format=\"csv\"\n)\n</code></pre>"},{"location":"silo_api/#datadrillquery","title":"DataDrillQuery","text":"<p>Model for DataDrill dataset queries:</p> <pre><code>from weather_tools import DataDrillQuery\n\nquery = DataDrillQuery(\n    lat=-27.5,\n    lon=153.0,\n    start_date=\"20230101\", \n    end_date=\"20230131\",\n    variables=[\"R\", \"X\", \"N\"],\n    format=\"csv\"\n)\n</code></pre>"},{"location":"silo_api/#other-models","title":"Other Models","text":"<ul> <li><code>ClimateVariable</code>: Enum for valid climate variable codes</li> <li><code>SiloFormat</code>: Enum for output formats (csv, json, apsim, standard)</li> <li><code>SiloDataset</code>: Enum for dataset types (PatchedPoint, DataDrill)</li> <li><code>AustralianCoordinates</code>: Validator for Australian lat/lon coordinates</li> <li><code>SiloDateRange</code>: Validator for SILO date format (YYYYMMDD)</li> <li><code>SiloResponse</code>: Response wrapper with metadata</li> </ul> <p>These models provide validation, type hints, and automatic parameter generation for SILO API requests.</p>"},{"location":"silo_api/#see-also","title":"See Also","text":"<ul> <li>CLI Reference - Command-line interface documentation</li> <li>API Reference - Local netCDF file reading</li> <li>Examples - Jupyter notebook examples</li> </ul>"},{"location":"api_docs/read_silo/","title":"Read SILO","text":""},{"location":"api_docs/read_silo/#weather_tools.read_silo_xarray.read_silo_xarray","title":"<code>read_silo_xarray(variables='daily', silo_dir=None)</code>","text":"<p>Read SILO data from a directory containing the SILO netCDF files and return a merged xarray dataset.</p> <p>Parameters:</p> Name Type Description Default <code>variables</code> <code>VariableInput</code> <p>Variable preset (\"daily\", \"monthly\", \"temperature\", etc.),       variable name (\"daily_rain\", \"max_temp\", etc.),       or list of presets/variable names. Defaults to \"daily\".</p> <code>'daily'</code> <code>silo_dir</code> <code>Path | None</code> <p>Path to the directory containing variable subdirectories (each containing .nc files). If None, uses the directory from SILO_DATA_DIR environment variable or defaults to ~/DATA/silo_grids. Expects the following structure:     silo_dir/     \u251c\u2500\u2500 daily_rain     \u251c\u2500\u2500 evap_syn     \u251c\u2500\u2500 max_temp     \u251c\u2500\u2500 min_temp     \u2514\u2500\u2500 monthly_rain         \u251c\u2500\u2500 ...         \u251c\u2500\u2500 2023.monthly_rain.nc         \u2514\u2500\u2500 2024.monthly_rain.nc</p> <code>None</code> <p>Returns:</p> Type Description <code>Dataset</code> <p>xr.Dataset: merged xarray Dataset containing the requested variables concatenated along the</p> <code>Dataset</code> <p>'time' dimension. Coordinates typically include 'time', 'lat', and 'lon'.</p> Example <p>from pathlib import Path from weather_tools.read_silo_xarray import read_silo_xarray</p> Source code in <code>src/weather_tools/read_silo_xarray.py</code> <pre><code>def read_silo_xarray(\n    variables: VariableInput = \"daily\",\n    silo_dir: Path | None = None,\n) -&gt; xr.Dataset:\n    \"\"\"\n    Read SILO data from a directory containing the SILO netCDF files and return a merged xarray dataset.\n\n    Args:\n        variables: Variable preset (\"daily\", \"monthly\", \"temperature\", etc.),\n                  variable name (\"daily_rain\", \"max_temp\", etc.),\n                  or list of presets/variable names. Defaults to \"daily\".\n        silo_dir: Path to the directory containing variable subdirectories (each containing .nc files).\n            If None, uses the directory from SILO_DATA_DIR environment variable or\n            defaults to ~/DATA/silo_grids.\n            Expects the following structure:\n                silo_dir/\n                \u251c\u2500\u2500 daily_rain\n                \u251c\u2500\u2500 evap_syn\n                \u251c\u2500\u2500 max_temp\n                \u251c\u2500\u2500 min_temp\n                \u2514\u2500\u2500 monthly_rain\n                    \u251c\u2500\u2500 ...\n                    \u251c\u2500\u2500 2023.monthly_rain.nc\n                    \u2514\u2500\u2500 2024.monthly_rain.nc\n\n    Returns:\n        xr.Dataset: merged xarray Dataset containing the requested variables concatenated along the\n        'time' dimension. Coordinates typically include 'time', 'lat', and 'lon'.\n\n    Example:\n        &gt;&gt;&gt; from pathlib import Path\n        &gt;&gt;&gt; from weather_tools.read_silo_xarray import read_silo_xarray\n        &gt;&gt;&gt; # Read the daily variables from the default silo_dir\n        &gt;&gt;&gt; ds = read_silo_xarray(variables=\"daily\")\n        &gt;&gt;&gt; print(ds)\n        &gt;&gt;&gt; # Or specify variables explicitly and a custom directory\n        &gt;&gt;&gt; ds2 = read_silo_xarray(variables=[\"monthly_rain\"], silo_dir=Path(\"/data/silo_grids\"))\n        &gt;&gt;&gt; make a smaller subset to reduce size in memeory\n        &gt;&gt;&gt; ds3 = read_silo_xarray().sel(lat=slice(-39, -26), lon=slice(133, 154), time=slice(\"2020-01-01\", \"2025-01-01\")).compute()\n        &gt;&gt;&gt; print(ds3)\n\n    \"\"\"\n    # Use environment variable or default if silo_dir not provided\n    if silo_dir is None:\n        silo_dir = get_silo_data_dir()\n\n    # Use centralized variable preset expansion\n    variables = VARIABLES.expand_preset(variables)\n\n    dss = []\n    for variable in variables:\n        # Convert generator to sorted list of file paths\n        file_paths = sorted((silo_dir / variable).glob(\"*.nc\"))\n\n        # Use open_mfdataset to open all years for a single variable\n        ds = xr.open_mfdataset(\n            file_paths,\n            chunks={\"time\": \"auto\"},\n            combine=\"nested\",  # Use nested combining for files that share dimensions\n            concat_dim=\"time\",  # Dimension along which to concatenate\n            data_vars=\"minimal\",  # Only data variables in which concat_dim appears are included\n            compat=\"no_conflicts\",  # Values must be equal or have disjoint (non-overlapping) coordinates\n            join=\"outer\",  # Use outer join for combining coordinates\n            # parallel=True  # Enable parallel processing if needed\n        ).sortby(\"time\")  # Ensure the 'time' dimension is sorted\n        dss.append(ds)\n\n    # merge combines different variables with the same dimensions (eg. time, lat, lon)\n    merged = xr.merge(dss, compat=\"override\")\n    [ds.close() for ds in dss]\n    return merged\n</code></pre>"},{"location":"api_docs/read_silo/#weather_tools.read_silo_xarray.read_silo_xarray--read-the-daily-variables-from-the-default-silo_dir","title":"Read the daily variables from the default silo_dir","text":"<p>ds = read_silo_xarray(variables=\"daily\") print(ds)</p>"},{"location":"api_docs/read_silo/#weather_tools.read_silo_xarray.read_silo_xarray--or-specify-variables-explicitly-and-a-custom-directory","title":"Or specify variables explicitly and a custom directory","text":"<p>ds2 = read_silo_xarray(variables=[\"monthly_rain\"], silo_dir=Path(\"/data/silo_grids\")) make a smaller subset to reduce size in memeory ds3 = read_silo_xarray().sel(lat=slice(-39, -26), lon=slice(133, 154), time=slice(\"2020-01-01\", \"2025-01-01\")).compute() print(ds3)</p>"},{"location":"notebooks/example/","title":"Local NetCDF","text":"In\u00a0[1]: Copied! <pre>import matplotlib.pyplot as plt\nimport xarray as xr\n\nplt.style.use(\"seaborn-v0_8-bright\")\nfrom weather_tools.read_silo_xarray import read_silo_xarray\n\n# read a subset into memory to speed things up\n\nds = (\n    read_silo_xarray()\n    .sel(lat=slice(-39, -26), lon=slice(133, 154), time=slice(\"2020-01-01\", \"2025-01-01\"))\n    .compute()\n)\n</pre> import matplotlib.pyplot as plt import xarray as xr  plt.style.use(\"seaborn-v0_8-bright\") from weather_tools.read_silo_xarray import read_silo_xarray  # read a subset into memory to speed things up  ds = (     read_silo_xarray()     .sel(lat=slice(-39, -26), lon=slice(133, 154), time=slice(\"2020-01-01\", \"2025-01-01\"))     .compute() ) <p><code>read_silo_xarray</code> opens the netCDF files in the directory and merges them into a single xarray dataset.</p> <p>the dataset contains the following variables:</p> <ul> <li><p><code>min_temp</code>: minimum temperature in degrees Celsius</p> </li> <li><p><code>max_temp</code>: maximum temperature in degrees Celsius</p> </li> <li><p><code>daily_rain</code>: rainfall in mm</p> </li> <li><p><code>evap_syn</code>: evaporation in mm (synthetic estimate)</p> </li> </ul> <p>Others can be added by downloading the SILO data from the SILO website and adding them to the directory.</p> <p>the dataset object can then be subset to get the sepcific data you require.</p> In\u00a0[2]: Copied! <pre># plot raster of minimum temperature for a specific date\nds.sel(time=\"2021-07-28\").min_temp.plot.imshow()\n</pre> # plot raster of minimum temperature for a specific date ds.sel(time=\"2021-07-28\").min_temp.plot.imshow() Out[2]: <pre>&lt;matplotlib.image.AxesImage at 0x1445cc8f0&gt;</pre> <p>Data for a specific location can be extracted by providing the latitude and longitude of the location.</p> <p>convert to pandas dataframe</p> In\u00a0[3]: Copied! <pre># Data for a specific location can be extracted by providing the latitude and longitude of the location.\nlat, lon = -36.6844306, 142.1867521\nyear = \"2021\"\n\nds_site = ds.sel(lat=lat, lon=lon, method=\"nearest\").sel(time=year)\n\n# convert to pandas dataframe\ndf = ds_site.to_pandas().drop(columns=[\"lat\", \"lon\", \"crs\"])\ndf.head()\n</pre> # Data for a specific location can be extracted by providing the latitude and longitude of the location. lat, lon = -36.6844306, 142.1867521 year = \"2021\"  ds_site = ds.sel(lat=lat, lon=lon, method=\"nearest\").sel(time=year)  # convert to pandas dataframe df = ds_site.to_pandas().drop(columns=[\"lat\", \"lon\", \"crs\"]) df.head() Out[3]: daily_rain max_temp min_temp evap_syn time 2021-01-01 0.0 33.4 14.5 7.7 2021-01-02 5.3 30.5 18.0 6.4 2021-01-03 1.4 28.9 13.2 7.2 2021-01-04 2.6 23.0 13.8 6.1 2021-01-05 0.0 23.2 12.9 6.0 In\u00a0[\u00a0]: Copied! <pre>\n</pre>"},{"location":"notebooks/example/#work-with-local-netcdf-files","title":"Work with local NetCDF files.\u00b6","text":"<p>This package provides tools for working with SILO weather data.</p> <p>The function <code>read_silo_xarray</code> reads SILO data from a directory containing the SILO netCDF files and returns a merged xarray dataset.</p> <p>xarray uses lazy loading, so the data is not loaded into memory until you call a method that requires it.</p> <p>The <code>.compute()</code> method loads the data into memory.</p> <p>This can be faster than making multiple reads from disk, however it can also use a lot of memory.</p>"},{"location":"notebooks/example_plots/","title":"Plotting","text":"In\u00a0[3]: Copied! <pre>import matplotlib.pyplot as plt\nimport xarray as xr\n\nplt.style.use(\"seaborn-v0_8-bright\")\nfrom weather_tools.read_silo_xarray import read_silo_xarray\n\n# read a subset into memory to speed things up\n\nds = (\n    read_silo_xarray()\n    .sel(lat=slice(-39, -26), lon=slice(133, 154), time=slice(\"2020-01-01\", \"2024-01-01\"))\n    .compute()\n)\n</pre> import matplotlib.pyplot as plt import xarray as xr  plt.style.use(\"seaborn-v0_8-bright\") from weather_tools.read_silo_xarray import read_silo_xarray  # read a subset into memory to speed things up  ds = (     read_silo_xarray()     .sel(lat=slice(-39, -26), lon=slice(133, 154), time=slice(\"2020-01-01\", \"2024-01-01\"))     .compute() ) <p>Example 1: Simple time series plot of minimum temperature for a specific location</p> In\u00a0[4]: Copied! <pre>lat, lon = -36.6844306, 142.1867521\nyear = \"2021\"\n\nds_site = ds.sel(lat=lat, lon=lon, method=\"nearest\").sel(time=year)\n\nds_site.min_temp.plot(figsize=(10, 6), marker=\"o\", linestyle=\"-\", label=\"Minimum Temperature\")\n\n\nplt.title(\"Minimum Temperature Time Series\")\nplt.ylabel(\"Temperature (\u00b0C)\")\nplt.grid(True)\nplt.legend()\n</pre> lat, lon = -36.6844306, 142.1867521 year = \"2021\"  ds_site = ds.sel(lat=lat, lon=lon, method=\"nearest\").sel(time=year)  ds_site.min_temp.plot(figsize=(10, 6), marker=\"o\", linestyle=\"-\", label=\"Minimum Temperature\")   plt.title(\"Minimum Temperature Time Series\") plt.ylabel(\"Temperature (\u00b0C)\") plt.grid(True) plt.legend() Out[4]: <pre>&lt;matplotlib.legend.Legend at 0x16013a2a0&gt;</pre> <p>Example 2: Comparing multiple variables - min_temp and max_temp over time</p> In\u00a0[5]: Copied! <pre>fig, ax = plt.subplots(figsize=(12, 6))\nds_site.min_temp.plot(ax=ax, label=\"Min Temperature\")\nds_site.max_temp.plot(ax=ax, label=\"Max Temperature\")\nax.set_title(\"Temperature Range Over Time\")\nax.set_ylabel(\"Temperature (\u00b0C)\")\nax.grid(True)\nplt.legend()\n</pre> fig, ax = plt.subplots(figsize=(12, 6)) ds_site.min_temp.plot(ax=ax, label=\"Min Temperature\") ds_site.max_temp.plot(ax=ax, label=\"Max Temperature\") ax.set_title(\"Temperature Range Over Time\") ax.set_ylabel(\"Temperature (\u00b0C)\") ax.grid(True) plt.legend() Out[5]: <pre>&lt;matplotlib.legend.Legend at 0x16125f8c0&gt;</pre> <p>Example 3: Plotting a heatmap of maximum temperature for a month</p> In\u00a0[6]: Copied! <pre>ds.sel(time=\"2021-01-01\").max_temp.plot.pcolormesh(figsize=(10, 8), cmap=\"hot\", robust=True)\nplt.title(\"Maximum Temperature - January 2021\")\n</pre> ds.sel(time=\"2021-01-01\").max_temp.plot.pcolormesh(figsize=(10, 8), cmap=\"hot\", robust=True) plt.title(\"Maximum Temperature - January 2021\") Out[6]: <pre>Text(0.5, 1.0, 'Maximum Temperature - January 2021')</pre> <p>Example 4: Creating a contour plot of rainfall</p> In\u00a0[7]: Copied! <pre>(\n    ds.sel(time=slice(\"2021-06-01\", \"2021-07-01\"))\n    .daily_rain.sum(dim=[\"time\"])\n    .plot.contourf(figsize=(10, 8), levels=10, cmap=\"Blues\")\n)\nplt.title(\"Rainfall Contour Map - February 2021\")\n</pre> (     ds.sel(time=slice(\"2021-06-01\", \"2021-07-01\"))     .daily_rain.sum(dim=[\"time\"])     .plot.contourf(figsize=(10, 8), levels=10, cmap=\"Blues\") ) plt.title(\"Rainfall Contour Map - February 2021\") Out[7]: <pre>Text(0.5, 1.0, 'Rainfall Contour Map - February 2021')</pre> <p>Example 5: Seasonal average - create a multi-panel plot showing seasonal averages</p> In\u00a0[8]: Copied! <pre>seasons = {\"DJF\": [12, 1, 2], \"MAM\": [3, 4, 5], \"JJA\": [6, 7, 8], \"SON\": [9, 10, 11]}\nseasonal_data = {}\n\nif \"crs\" in ds:\n    ds = ds.drop_vars(\"crs\")\n\n# Filter and average by season\nfor season, months in seasons.items():\n    # For December, we need to use the previous year\n    if season == \"DJF\":\n        dec_data = ds.sel(time=((ds.time.dt.month == 12) &amp; (ds.time.dt.year == 2020)))\n        jan_feb_data = ds.sel(\n            time=(ds.time.dt.month == 1) | (ds.time.dt.month == 2) &amp; (ds.time.dt.year == 2021)\n        )\n        seasonal_data[season] = xr.concat([dec_data, jan_feb_data], dim=\"time\").mean(\"time\")\n    else:\n        month_data = ds.sel(time=ds.time.dt.month.isin(months) &amp; (ds.time.dt.year == 2021))\n        seasonal_data[season] = month_data.mean(\"time\")\n\n# Create multi-panel plot\nfig, axes = plt.subplots(2, 2, figsize=(15, 12))\naxes = axes.flatten()\n\nfor i, (season, data) in enumerate(seasonal_data.items()):\n    data.daily_rain.plot(ax=axes[i], cmap=\"Blues\", robust=True)\n    axes[i].set_title(f\"Average Daily Rain - {season} 2021\")\n\nplt.tight_layout()\n</pre> seasons = {\"DJF\": [12, 1, 2], \"MAM\": [3, 4, 5], \"JJA\": [6, 7, 8], \"SON\": [9, 10, 11]} seasonal_data = {}  if \"crs\" in ds:     ds = ds.drop_vars(\"crs\")  # Filter and average by season for season, months in seasons.items():     # For December, we need to use the previous year     if season == \"DJF\":         dec_data = ds.sel(time=((ds.time.dt.month == 12) &amp; (ds.time.dt.year == 2020)))         jan_feb_data = ds.sel(             time=(ds.time.dt.month == 1) | (ds.time.dt.month == 2) &amp; (ds.time.dt.year == 2021)         )         seasonal_data[season] = xr.concat([dec_data, jan_feb_data], dim=\"time\").mean(\"time\")     else:         month_data = ds.sel(time=ds.time.dt.month.isin(months) &amp; (ds.time.dt.year == 2021))         seasonal_data[season] = month_data.mean(\"time\")  # Create multi-panel plot fig, axes = plt.subplots(2, 2, figsize=(15, 12)) axes = axes.flatten()  for i, (season, data) in enumerate(seasonal_data.items()):     data.daily_rain.plot(ax=axes[i], cmap=\"Blues\", robust=True)     axes[i].set_title(f\"Average Daily Rain - {season} 2021\")  plt.tight_layout() <p>Example 6: Creating a histogram of annual rainfall distribution in each grid cell.</p> In\u00a0[9]: Copied! <pre>ds.sel(time=\"2021\").daily_rain.sum(dim=[\"time\"]).plot.hist(figsize=(10, 6), bins=20)\nplt.title(\"Rainfall Distribution - 2021\")\nplt.xlabel(\"Rainfall (mm)\")\nplt.ylabel(\"Frequency\")\n</pre> ds.sel(time=\"2021\").daily_rain.sum(dim=[\"time\"]).plot.hist(figsize=(10, 6), bins=20) plt.title(\"Rainfall Distribution - 2021\") plt.xlabel(\"Rainfall (mm)\") plt.ylabel(\"Frequency\") Out[9]: <pre>Text(0, 0.5, 'Frequency')</pre> <p>Example 7: hovmoller diagram (time vs. latitude)</p> In\u00a0[10]: Copied! <pre># Select a slice along a specific longitude\nhovmoller = ds.sel(lon=lon, method=\"nearest\").max_temp\nhovmoller.plot(x=\"time\", y=\"lat\", figsize=(12, 6), cmap=\"viridis\", robust=True)\nplt.title(f\"Hovmoller Diagram: Max Temperature across Latitudes (Longitude: {lon:.2f})\")\n</pre> # Select a slice along a specific longitude hovmoller = ds.sel(lon=lon, method=\"nearest\").max_temp hovmoller.plot(x=\"time\", y=\"lat\", figsize=(12, 6), cmap=\"viridis\", robust=True) plt.title(f\"Hovmoller Diagram: Max Temperature across Latitudes (Longitude: {lon:.2f})\") Out[10]: <pre>Text(0.5, 1.0, 'Hovmoller Diagram: Max Temperature across Latitudes (Longitude: 142.19)')</pre> <p>Example 9: Facet plot for different variables</p> In\u00a0[11]: Copied! <pre>variables = [\"min_temp\", \"max_temp\", \"daily_rain\", \"evap_syn\"]\nfig, axes = plt.subplots(2, 2, figsize=(15, 12))\naxes = axes.flatten()\n\nfor i, var in enumerate(variables):\n    ds.sel(time=\"2021-07-28\")[var].plot(ax=axes[i])\n    axes[i].set_title(f\"{var} - 2021-07-28\")\n\nplt.tight_layout()\n</pre> variables = [\"min_temp\", \"max_temp\", \"daily_rain\", \"evap_syn\"] fig, axes = plt.subplots(2, 2, figsize=(15, 12)) axes = axes.flatten()  for i, var in enumerate(variables):     ds.sel(time=\"2021-07-28\")[var].plot(ax=axes[i])     axes[i].set_title(f\"{var} - 2021-07-28\")  plt.tight_layout() <p>Example 10: Plot annual cycle using monthly averages for specific location</p> In\u00a0[12]: Copied! <pre># exclude the non-numeric 'crs' variable so mean() only applies to numeric data\nannual_cycle = ds_site.drop_vars(\"crs\").groupby(\"time.month\").mean()\nfig, ax = plt.subplots(figsize=(10, 6))\nannual_cycle.min_temp.plot(ax=ax, label=\"Min Temp\")\nannual_cycle.max_temp.plot(ax=ax, label=\"Max Temp\")\nannual_cycle.daily_rain.plot(ax=ax, label=\"Rainfall\", marker=\"o\", linestyle=\"-\")\nax.set_xticks(range(1, 13))\nax.set_xticklabels(\n    [\"Jan\", \"Feb\", \"Mar\", \"Apr\", \"May\", \"Jun\", \"Jul\", \"Aug\", \"Sep\", \"Oct\", \"Nov\", \"Dec\"]\n)\nax.set_title(f\"Annual Weather Cycle at ({lat:.2f}, {lon:.2f}) - 2021\")\nax.set_xlabel(\"\")\nax.legend()\nplt.grid(True)\n</pre> # exclude the non-numeric 'crs' variable so mean() only applies to numeric data annual_cycle = ds_site.drop_vars(\"crs\").groupby(\"time.month\").mean() fig, ax = plt.subplots(figsize=(10, 6)) annual_cycle.min_temp.plot(ax=ax, label=\"Min Temp\") annual_cycle.max_temp.plot(ax=ax, label=\"Max Temp\") annual_cycle.daily_rain.plot(ax=ax, label=\"Rainfall\", marker=\"o\", linestyle=\"-\") ax.set_xticks(range(1, 13)) ax.set_xticklabels(     [\"Jan\", \"Feb\", \"Mar\", \"Apr\", \"May\", \"Jun\", \"Jul\", \"Aug\", \"Sep\", \"Oct\", \"Nov\", \"Dec\"] ) ax.set_title(f\"Annual Weather Cycle at ({lat:.2f}, {lon:.2f}) - 2021\") ax.set_xlabel(\"\") ax.legend() plt.grid(True)"},{"location":"notebooks/example_plots/#plotting-with-xarray","title":"Plotting with xarray\u00b6","text":"<p>xarray provides plotting functionality built on matplotlib. Here are various examples:</p>"},{"location":"notebooks/geotiff_download_demo/","title":"Download COG Geotiff from S3","text":"In\u00a0[\u00a0]: Copied! <pre>from datetime import date, timedelta\n\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport pandas as pd\nfrom matplotlib import cm\nfrom shapely.geometry import Polygon\n\nfrom weather_tools.silo_geotiff import download_and_read_geotiffs\n</pre> from datetime import date, timedelta  import matplotlib.pyplot as plt import numpy as np import pandas as pd from matplotlib import cm from shapely.geometry import Polygon  from weather_tools.silo_geotiff import download_and_read_geotiffs In\u00a0[\u00a0]: Copied! <pre># Coordinates for the polygon (longitude, latitude)\ncoords = [\n    [136.0, -32.0],\n    [136.0, -36.2],\n    [140.0, -36.2],\n    [140.0, -32.0],\n    [136.0, -32.0],\n]\n\n# Create a Shapely Polygon object\nstudy_area = Polygon(coords)\n\nprint(f\"Study area bounds: {study_area.bounds}\")\n</pre> # Coordinates for the polygon (longitude, latitude) coords = [     [136.0, -32.0],     [136.0, -36.2],     [140.0, -36.2],     [140.0, -32.0],     [136.0, -32.0], ]  # Create a Shapely Polygon object study_area = Polygon(coords)  print(f\"Study area bounds: {study_area.bounds}\") <pre>Study area bounds: (136.0, -36.2, 140.0, -32.0)\n</pre> In\u00a0[\u00a0]: Copied! <pre># Calculate date range (past 9 days)\nend_date = date.today() - timedelta(days=1)  # Yesterday\nstart_date = end_date - timedelta(days=8)  # 9 days total\n\nprint(f\"Date range: {start_date} to {end_date}\")\nprint(f\"Number of days: {(end_date - start_date).days + 1}\")\n</pre> # Calculate date range (past 9 days) end_date = date.today() - timedelta(days=1)  # Yesterday start_date = end_date - timedelta(days=8)  # 9 days total  print(f\"Date range: {start_date} to {end_date}\") print(f\"Number of days: {(end_date - start_date).days + 1}\") <pre>Date range: 2025-11-12 to 2025-11-20\nNumber of days: 9\n</pre> In\u00a0[11]: Copied! <pre>data[\"daily_rain\"]\n</pre> data[\"daily_rain\"] Out[11]: <pre>(masked_array(\n   data=[[[ 0.0000e+00,  0.0000e+00,  0.0000e+00, ...,  0.0000e+00,\n            0.0000e+00,  0.0000e+00],\n          [ 0.0000e+00,  0.0000e+00,  0.0000e+00, ...,  0.0000e+00,\n            0.0000e+00,  0.0000e+00],\n          [ 0.0000e+00,  0.0000e+00,  0.0000e+00, ...,  0.0000e+00,\n            0.0000e+00,  0.0000e+00],\n          ...,\n          [-3.2767e+04, -3.2767e+04, -3.2767e+04, ...,  0.0000e+00,\n            0.0000e+00,  0.0000e+00],\n          [-3.2767e+04, -3.2767e+04, -3.2767e+04, ...,  0.0000e+00,\n            0.0000e+00,  0.0000e+00],\n          [-3.2767e+04, -3.2767e+04, -3.2767e+04, ...,  0.0000e+00,\n            0.0000e+00,  0.0000e+00]],\n \n         [[ 0.0000e+00,  0.0000e+00,  0.0000e+00, ...,  0.0000e+00,\n            0.0000e+00,  0.0000e+00],\n          [ 0.0000e+00,  0.0000e+00,  0.0000e+00, ...,  0.0000e+00,\n            0.0000e+00,  0.0000e+00],\n          [ 0.0000e+00,  0.0000e+00,  0.0000e+00, ...,  0.0000e+00,\n            0.0000e+00,  0.0000e+00],\n          ...,\n          [-3.2767e+04, -3.2767e+04, -3.2767e+04, ...,  0.0000e+00,\n            0.0000e+00,  0.0000e+00],\n          [-3.2767e+04, -3.2767e+04, -3.2767e+04, ...,  0.0000e+00,\n            0.0000e+00,  0.0000e+00],\n          [-3.2767e+04, -3.2767e+04, -3.2767e+04, ...,  0.0000e+00,\n            0.0000e+00,  0.0000e+00]],\n \n         [[ 2.0000e-01,  2.0000e-01,  2.0000e-01, ...,  0.0000e+00,\n            0.0000e+00,  0.0000e+00],\n          [ 2.0000e-01,  2.0000e-01,  2.0000e-01, ...,  0.0000e+00,\n            0.0000e+00,  0.0000e+00],\n          [ 3.0000e-01,  2.0000e-01,  2.0000e-01, ...,  0.0000e+00,\n            0.0000e+00,  0.0000e+00],\n          ...,\n          [-3.2767e+04, -3.2767e+04, -3.2767e+04, ...,  0.0000e+00,\n            0.0000e+00,  0.0000e+00],\n          [-3.2767e+04, -3.2767e+04, -3.2767e+04, ...,  0.0000e+00,\n            0.0000e+00,  0.0000e+00],\n          [-3.2767e+04, -3.2767e+04, -3.2767e+04, ...,  0.0000e+00,\n            0.0000e+00,  0.0000e+00]],\n \n         ...,\n \n         [[ 0.0000e+00,  0.0000e+00,  0.0000e+00, ...,  0.0000e+00,\n            0.0000e+00,  0.0000e+00],\n          [ 0.0000e+00,  0.0000e+00,  0.0000e+00, ...,  0.0000e+00,\n            0.0000e+00,  0.0000e+00],\n          [ 0.0000e+00,  0.0000e+00,  0.0000e+00, ...,  0.0000e+00,\n            0.0000e+00,  0.0000e+00],\n          ...,\n          [-3.2767e+04, -3.2767e+04, -3.2767e+04, ...,  3.0000e-01,\n            3.0000e-01,  4.0000e-01],\n          [-3.2767e+04, -3.2767e+04, -3.2767e+04, ...,  3.0000e-01,\n            3.0000e-01,  3.0000e-01],\n          [-3.2767e+04, -3.2767e+04, -3.2767e+04, ...,  3.0000e-01,\n            3.0000e-01,  3.0000e-01]],\n \n         [[ 0.0000e+00,  0.0000e+00,  0.0000e+00, ...,  0.0000e+00,\n            0.0000e+00,  0.0000e+00],\n          [ 0.0000e+00,  0.0000e+00,  0.0000e+00, ...,  0.0000e+00,\n            0.0000e+00,  0.0000e+00],\n          [ 0.0000e+00,  0.0000e+00,  0.0000e+00, ...,  0.0000e+00,\n            0.0000e+00,  0.0000e+00],\n          ...,\n          [-3.2767e+04, -3.2767e+04, -3.2767e+04, ...,  5.0000e-01,\n            5.0000e-01,  5.0000e-01],\n          [-3.2767e+04, -3.2767e+04, -3.2767e+04, ...,  5.0000e-01,\n            5.0000e-01,  4.0000e-01],\n          [-3.2767e+04, -3.2767e+04, -3.2767e+04, ...,  5.0000e-01,\n            4.0000e-01,  4.0000e-01]],\n \n         [[ 0.0000e+00,  0.0000e+00,  0.0000e+00, ...,  0.0000e+00,\n            0.0000e+00,  0.0000e+00],\n          [ 0.0000e+00,  0.0000e+00,  0.0000e+00, ...,  0.0000e+00,\n            0.0000e+00,  0.0000e+00],\n          [ 0.0000e+00,  0.0000e+00,  0.0000e+00, ...,  0.0000e+00,\n            0.0000e+00,  0.0000e+00],\n          ...,\n          [-3.2767e+04, -3.2767e+04, -3.2767e+04, ...,  1.0000e-01,\n            1.0000e-01,  1.0000e-01],\n          [-3.2767e+04, -3.2767e+04, -3.2767e+04, ...,  1.0000e-01,\n            1.0000e-01,  1.0000e-01],\n          [-3.2767e+04, -3.2767e+04, -3.2767e+04, ...,  2.0000e-01,\n            1.0000e-01,  2.0000e-01]]],\n   mask=False,\n   fill_value=np.float64(1e+20),\n   dtype=float32),\n {'driver': 'GTiff', 'dtype': 'float32', 'nodata': -32767.0, 'width': 40, 'height': 42, 'count': 9, 'crs': CRS.from_wkt('GEOGCS[\"WGS 84\",DATUM[\"WGS_1984\",SPHEROID[\"WGS 84\",6378137,298.257223563,AUTHORITY[\"EPSG\",\"7030\"]],AUTHORITY[\"EPSG\",\"6326\"]],PRIMEM[\"Greenwich\",0,AUTHORITY[\"EPSG\",\"8901\"]],UNIT[\"degree\",0.0174532925199433,AUTHORITY[\"EPSG\",\"9122\"]],AXIS[\"Latitude\",NORTH],AXIS[\"Longitude\",EAST],AUTHORITY[\"EPSG\",\"4326\"]]'), 'transform': Affine(0.10125, 0.0, 135.975,\n        0.0, -0.10119047619047619, -31.975), 'blockxsize': 40, 'blockysize': 2, 'tiled': False, 'compress': 'deflate', 'interleave': 'band'})</pre> In\u00a0[\u00a0]: Copied! <pre>print(\"Downloading rainfall data from SILO S3...\")\n\ndata = download_and_read_geotiffs(\n    variables=[\"daily_rain\"],\n    start_date=start_date,\n    end_date=end_date,\n    geometry=study_area,\n    save_to_disk=False,  # Stream from S3, don't cache\n    overview_level=1,  # 4\u00d7 reduced resolution\n)\n\nrainfall, profile = data[\"daily_rain\"]\nprint(f\"\\nDownloaded data shape: {rainfall.shape}\")\nprint(f\"  - Time steps: {rainfall.shape[0]}\")\nprint(f\"  - Height: {rainfall.shape[1]} pixels\")\nprint(f\"  - Width: {rainfall.shape[2]} pixels\")\n</pre> print(\"Downloading rainfall data from SILO S3...\")  data = download_and_read_geotiffs(     variables=[\"daily_rain\"],     start_date=start_date,     end_date=end_date,     geometry=study_area,     save_to_disk=False,  # Stream from S3, don't cache     overview_level=1,  # 4\u00d7 reduced resolution )  rainfall, profile = data[\"daily_rain\"] print(f\"\\nDownloaded data shape: {rainfall.shape}\") print(f\"  - Time steps: {rainfall.shape[0]}\") print(f\"  - Height: {rainfall.shape[1]} pixels\") print(f\"  - Width: {rainfall.shape[2]} pixels\") <pre>Downloading rainfall data from SILO S3...\n\nDownloaded data shape: (9, 42, 40)\n  - Time steps: 9\n  - Height: 42 pixels\n  - Width: 40 pixels\n</pre> In\u00a0[13]: Copied! <pre># Create 3x3 subplot grid\nfig, axes = plt.subplots(3, 3, figsize=(15, 15))\naxes = axes.flatten()\n\n# Generate date labels\ndate_list = [start_date + timedelta(days=i) for i in range(9)]\n\n# Calculate global min/max for shared colorbar scale\n# First, clean all the data and collect valid values\nall_valid_values = []\ncleaned_rainfall = []\n\nfor day_data in rainfall:\n    day_cleaned = day_data.copy()\n    day_cleaned[day_cleaned &lt; 0] = np.nan  # Set negative values to NaN\n    cleaned_rainfall.append(day_cleaned)\n\n    # Collect non-NaN values\n    valid = day_cleaned[~np.isnan(day_cleaned)]\n    if len(valid) &gt; 0:\n        all_valid_values.extend(valid.flatten())\n\n# Determine shared scale\nif all_valid_values:\n    vmin = 0  # Rainfall minimum is always 0\n    vmax = np.max(all_valid_values)\nelse:\n    vmin, vmax = 0, 1  # Fallback if no valid data\n\nprint(f\"Shared colorbar scale: 0 to {vmax:.2f} mm\")\n\n# Create custom colormap with grey background for NaN values\ncmap = cm.get_cmap(\"viridis\").copy()\ncmap.set_bad(color=\"#EAE9E9\")  # Grey for missing/NaN data\n\n# Plot each day with shared scale\nfor idx, (ax, day_data, day_date) in enumerate(zip(axes, cleaned_rainfall, date_list)):\n    # Create the plot with shared vmin/vmax and custom colormap\n    im = ax.imshow(day_data, cmap=cmap, interpolation=\"nearest\", vmin=vmin, vmax=vmax)\n    ax.set_title(f\"{day_date.strftime('%Y-%m-%d')}\", fontsize=12, fontweight=\"bold\")\n    ax.axis(\"off\")\n\n    # Add colorbar (all will show the same scale)\n    cbar = plt.colorbar(im, ax=ax, fraction=0.046, pad=0.04)\n    cbar.set_label(\"Rainfall (mm)\", fontsize=9)\n\nplt.suptitle(\n    f\"Daily Rainfall - South Australia\\n{start_date} to {end_date}\",\n    fontsize=16,\n    fontweight=\"bold\",\n    y=0.995,\n)\nplt.tight_layout()\nplt.show()\n</pre> # Create 3x3 subplot grid fig, axes = plt.subplots(3, 3, figsize=(15, 15)) axes = axes.flatten()  # Generate date labels date_list = [start_date + timedelta(days=i) for i in range(9)]  # Calculate global min/max for shared colorbar scale # First, clean all the data and collect valid values all_valid_values = [] cleaned_rainfall = []  for day_data in rainfall:     day_cleaned = day_data.copy()     day_cleaned[day_cleaned &lt; 0] = np.nan  # Set negative values to NaN     cleaned_rainfall.append(day_cleaned)      # Collect non-NaN values     valid = day_cleaned[~np.isnan(day_cleaned)]     if len(valid) &gt; 0:         all_valid_values.extend(valid.flatten())  # Determine shared scale if all_valid_values:     vmin = 0  # Rainfall minimum is always 0     vmax = np.max(all_valid_values) else:     vmin, vmax = 0, 1  # Fallback if no valid data  print(f\"Shared colorbar scale: 0 to {vmax:.2f} mm\")  # Create custom colormap with grey background for NaN values cmap = cm.get_cmap(\"viridis\").copy() cmap.set_bad(color=\"#EAE9E9\")  # Grey for missing/NaN data  # Plot each day with shared scale for idx, (ax, day_data, day_date) in enumerate(zip(axes, cleaned_rainfall, date_list)):     # Create the plot with shared vmin/vmax and custom colormap     im = ax.imshow(day_data, cmap=cmap, interpolation=\"nearest\", vmin=vmin, vmax=vmax)     ax.set_title(f\"{day_date.strftime('%Y-%m-%d')}\", fontsize=12, fontweight=\"bold\")     ax.axis(\"off\")      # Add colorbar (all will show the same scale)     cbar = plt.colorbar(im, ax=ax, fraction=0.046, pad=0.04)     cbar.set_label(\"Rainfall (mm)\", fontsize=9)  plt.suptitle(     f\"Daily Rainfall - South Australia\\n{start_date} to {end_date}\",     fontsize=16,     fontweight=\"bold\",     y=0.995, ) plt.tight_layout() plt.show() <pre>Shared colorbar scale: 0 to 24.40 mm\n</pre> <pre>/var/folders/b0/wq9x9vj13dv_75w41x6dmcyh0000gn/T/ipykernel_40328/80531725.py:33: MatplotlibDeprecationWarning: The get_cmap function was deprecated in Matplotlib 3.7 and will be removed in 3.11. Use ``matplotlib.colormaps[name]`` or ``matplotlib.colormaps.get_cmap()`` or ``pyplot.get_cmap()`` instead.\n  cmap = cm.get_cmap(\"viridis\").copy()\n</pre> In\u00a0[14]: Copied! <pre># Calculate statistics across the entire period\nstats_data = []\n\nfor idx, day_date in enumerate(date_list):\n    day_data = rainfall[idx]\n    day_data[day_data &lt; 0] = np.nan  # Clean negative values\n    valid_data = day_data[~np.isnan(day_data)]\n\n    if len(valid_data) &gt; 0:\n        stats_data.append(\n            {\n                \"Date\": day_date.strftime(\"%Y-%m-%d\"),\n                \"Mean (mm)\": np.mean(valid_data),\n                \"Median (mm)\": np.median(valid_data),\n                \"Max (mm)\": np.max(valid_data),\n                \"Min (mm)\": np.min(valid_data),\n            }\n        )\n    else:\n        stats_data.append(\n            {\n                \"Date\": day_date.strftime(\"%Y-%m-%d\"),\n                \"Mean (mm)\": np.nan,\n                \"Median (mm)\": np.nan,\n                \"Max (mm)\": np.nan,\n                \"Min (mm)\": np.nan,\n                \"Std Dev (mm)\": np.nan,\n                \"Total (mm)\": np.nan,\n            }\n        )\n\n# Create DataFrame and display\nstats_df = pd.DataFrame(stats_data)\nprint(\"\\nRainfall Statistics Summary:\")\nprint(stats_df.to_string(index=False, float_format=\"%.2f\"))\n</pre> # Calculate statistics across the entire period stats_data = []  for idx, day_date in enumerate(date_list):     day_data = rainfall[idx]     day_data[day_data &lt; 0] = np.nan  # Clean negative values     valid_data = day_data[~np.isnan(day_data)]      if len(valid_data) &gt; 0:         stats_data.append(             {                 \"Date\": day_date.strftime(\"%Y-%m-%d\"),                 \"Mean (mm)\": np.mean(valid_data),                 \"Median (mm)\": np.median(valid_data),                 \"Max (mm)\": np.max(valid_data),                 \"Min (mm)\": np.min(valid_data),             }         )     else:         stats_data.append(             {                 \"Date\": day_date.strftime(\"%Y-%m-%d\"),                 \"Mean (mm)\": np.nan,                 \"Median (mm)\": np.nan,                 \"Max (mm)\": np.nan,                 \"Min (mm)\": np.nan,                 \"Std Dev (mm)\": np.nan,                 \"Total (mm)\": np.nan,             }         )  # Create DataFrame and display stats_df = pd.DataFrame(stats_data) print(\"\\nRainfall Statistics Summary:\") print(stats_df.to_string(index=False, float_format=\"%.2f\")) <pre>\nRainfall Statistics Summary:\n      Date  Mean (mm)  Median (mm)  Max (mm)  Min (mm)\n2025-11-12       0.01         0.00      0.20      0.00\n2025-11-13       0.09         0.00      1.80      0.00\n2025-11-14       0.91         0.40      7.90      0.00\n2025-11-15       0.63         0.00     24.40      0.00\n2025-11-16       0.34         0.00      4.10      0.00\n2025-11-17       1.71         1.10     15.90      0.00\n2025-11-18       0.15         0.00      2.40      0.00\n2025-11-19       0.14         0.00      2.40      0.00\n2025-11-20       0.03         0.00      0.60      0.00\n</pre> <pre>/Users/hfsi/Developer/weather_tools/.venv/lib/python3.12/site-packages/numpy/_core/fromnumeric.py:867: UserWarning: Warning: 'partition' will ignore the 'mask' of the MaskedArray.\n  a.partition(kth, axis=axis, kind=kind, order=order)\n</pre>"},{"location":"notebooks/geotiff_download_demo/#silo-geotiff-download-and-visualization-demo","title":"SILO GeoTIFF Download and Visualization Demo\u00b6","text":"<p>This notebook demonstrates the Cloud-Optimized GeoTIFF (COG) functionality</p> <p>in the <code>weather_tools</code> package.</p> <p>We'll download rainfall data for a specific region in South Australia over</p> <p>the past 9 days using reduced resolution (overview level) and visualize</p> <p>the results.</p>"},{"location":"notebooks/geotiff_download_demo/#key-features-demonstrated","title":"Key Features Demonstrated\u00b6","text":"<ul> <li><p>Spatial subsetting: Download only data within a polygon boundary</p> </li> <li><p>Overview levels: Use pyramid overviews for reduced resolution (faster downloads)</p> </li> <li><p>Time series: Retrieve multiple days of data efficiently</p> </li> <li><p>HTTP range requests: COG files allow downloading only the pixels we need</p> </li> </ul>"},{"location":"notebooks/geotiff_download_demo/#setup-and-imports","title":"Setup and Imports\u00b6","text":""},{"location":"notebooks/geotiff_download_demo/#define-the-study-area","title":"Define the Study Area\u00b6","text":"<p>We'll use a polygon in South Australia as our area of interest.</p>"},{"location":"notebooks/geotiff_download_demo/#define-the-date-range","title":"Define the Date Range\u00b6","text":"<p>We'll download the past 9 days of rainfall data ending yesterday</p> <p>(today's data may not yet be available).</p>"},{"location":"notebooks/geotiff_download_demo/#download-rainfall-data","title":"Download Rainfall Data\u00b6","text":"<p>Using <code>read_geotiff_timeseries()</code>, we'll:</p> <ul> <li><p>Query only the <code>daily_rain</code> variable</p> </li> <li><p>Clip to our polygon geometry</p> </li> <li><p>Use <code>overview_level=2</code> for 4\u00d7 reduced resolution (faster, smaller file sizes)</p> </li> <li><p>Stream directly from S3 without caching to disk (<code>save_to_disk=False</code>)</p> </li> </ul> <p>Note: Overview levels work by powers of 2:</p> <ul> <li><p><code>overview_level=0</code>: 2\u00d7 reduced resolution</p> </li> <li><p><code>overview_level=1</code>: 4\u00d7 reduced resolution</p> </li> <li><p><code>overview_level=2</code>: 8\u00d7 reduced resolution</p> </li> </ul> <p>For this demo, we'll use level 1 (4\u00d7 reduction) to balance speed and detail.</p>"},{"location":"notebooks/geotiff_download_demo/#visualize-the-results","title":"Visualize the Results\u00b6","text":"<p>Plot each day's rainfall as a 3\u00d73 grid with a shared color scale.</p> <ul> <li>Grey background indicates no data or masked values (ocean areas)</li> </ul>"},{"location":"notebooks/geotiff_download_demo/#summary-statistics","title":"Summary Statistics\u00b6","text":""},{"location":"notebooks/geotiff_download_demo/#key-takeaways","title":"Key Takeaways\u00b6","text":"<ol> <li><p>Efficient Downloads: Using COG overview levels and spatial subsetting, we downloaded</p> <p>only the data we needed without retrieving full continental grids.</p> </li> <li><p>HTTP Range Requests: The entire operation used HTTP range requests to fetch only</p> <p>relevant pixels from S3, avoiding unnecessary data transfer.</p> </li> <li><p>No Local Storage: With <code>save_to_disk=False</code>, we streamed data directly into memory</p> <p>without creating local cache files.</p> </li> <li><p>Flexible Geometries: The same approach works with any Shapely geometry (Point, Polygon,</p> <p>MultiPolygon, etc.).</p> </li> </ol>"},{"location":"notebooks/geotiff_download_demo/#next-steps","title":"Next Steps\u00b6","text":"<ul> <li><p>Use <code>save_to_disk=True</code> with a <code>cache_dir</code> to cache files for reuse</p> </li> <li><p>Download multiple variables simultaneously (e.g., <code>[\"daily_rain\", \"max_temp\", \"min_temp\"]</code>)</p> </li> </ul>"},{"location":"notebooks/map_patchedPoint_sites/","title":"Map of SILO stations","text":"In\u00a0[1]: Copied! <pre># ## Setup and Imports\nimport geopandas as gpd\n\nfrom weather_tools.silo_api import SiloAPI\n</pre> # ## Setup and Imports import geopandas as gpd  from weather_tools.silo_api import SiloAPI In\u00a0[2]: Copied! <pre>silo_api = SiloAPI(log_level=\"INFO\")\nstation_meta = silo_api.search_stations(\"__\")\n\n# Convert to GeoDataFrame for spatial operations and mapping\ngdf = gpd.GeoDataFrame(\n    station_meta,\n    geometry=gpd.points_from_xy(station_meta.longitude, station_meta.latitude),\n    crs=4326,\n)\n\nprint(f\"Found {len(gdf)} weather stations in SILO database\")\n</pre> silo_api = SiloAPI(log_level=\"INFO\") station_meta = silo_api.search_stations(\"__\")  # Convert to GeoDataFrame for spatial operations and mapping gdf = gpd.GeoDataFrame(     station_meta,     geometry=gpd.points_from_xy(station_meta.longitude, station_meta.latitude),     crs=4326, )  print(f\"Found {len(gdf)} weather stations in SILO database\") <pre>Found 7995 weather stations in SILO database\n</pre> In\u00a0[3]: Copied! <pre>gdf.explore(\n    \"elevation\",  # use elevation column for color\n    cmap=\"terrain\",\n    marker_kwds=dict(radius=5, stroke=False, alpha=0.8),\n)\n</pre> gdf.explore(     \"elevation\",  # use elevation column for color     cmap=\"terrain\",     marker_kwds=dict(radius=5, stroke=False, alpha=0.8), ) Out[3]: Make this Notebook Trusted to load map: File -&gt; Trust Notebook"},{"location":"notebooks/map_patchedPoint_sites/#exploring-silo-patched-point-weather-stations","title":"Exploring SILO Patched Point Weather Stations\u00b6","text":"<p>This notebook demonstrates how to search and visualize all available weather stations in the SILO Patched Point dataset. The resulting interactive map shows station locations colored by elevation and includes station numbers that can be used for data queries.</p>"},{"location":"notebooks/map_patchedPoint_sites/#search-for-all-silo-weather-stations","title":"Search for All SILO Weather Stations\u00b6","text":"<p>The <code>search_stations()</code> method with the wildcard pattern \"__\" returns metadata for all available stations in the SILO Patched Point dataset. This includes:</p> <ul> <li>Station codes (used for data queries)</li> <li>Geographic coordinates (latitude/longitude)</li> <li>Elevation above sea level</li> <li>Station names and other metadata</li> </ul>"},{"location":"notebooks/map_patchedPoint_sites/#interactive-station-map","title":"Interactive Station Map\u00b6","text":"<p>This map displays all SILO weather stations colored by elevation (meters above sea level). Map Features:</p> <ul> <li>Color scale: Lower elevations (coastal) appear green, higher elevations (mountains) appear brown</li> <li>Click any marker to view station details including the station code</li> <li>Use station codes from the popup to query weather data via the CLI or API Example Query Using Station Code:</li> </ul> <pre>weather-tools silo patched-point --station 30043 \\\n --start-date 20230101 --end-date 20231231 --var R --var X\n</pre>"},{"location":"notebooks/metno_forecast_example/","title":"Forecast data","text":"In\u00a0[1]: Copied! <pre>import pandas as pd\n\nfrom weather_tools.merge_weather_data import get_merge_summary, merge_historical_and_forecast\nfrom weather_tools.metno_api import MetNoAPI\nfrom weather_tools.metno_models import MetNoFormat, MetNoQuery\nfrom weather_tools.silo_api import SiloAPI\nfrom weather_tools.silo_models import AustralianCoordinates\n</pre> import pandas as pd  from weather_tools.merge_weather_data import get_merge_summary, merge_historical_and_forecast from weather_tools.metno_api import MetNoAPI from weather_tools.metno_models import MetNoFormat, MetNoQuery from weather_tools.silo_api import SiloAPI from weather_tools.silo_models import AustralianCoordinates In\u00a0[2]: Copied! <pre># silo_api = SiloAPI(log_level=\"INFO\")\n# station_meta = silo_api.search_stations(\"Northam\").iloc[0]\n\nstation_meta = {\n    \"station_code\": 10111,\n    \"name\": \"NORTHAM\",\n    \"latitude\": -31.651,\n    \"longitude\": 116.659,\n    \"state\": \"WA\",\n    \"elevation\": 170.0,\n}\n</pre> # silo_api = SiloAPI(log_level=\"INFO\") # station_meta = silo_api.search_stations(\"Northam\").iloc[0]  station_meta = {     \"station_code\": 10111,     \"name\": \"NORTHAM\",     \"latitude\": -31.651,     \"longitude\": 116.659,     \"state\": \"WA\",     \"elevation\": 170.0, } In\u00a0[3]: Copied! <pre>api = MetNoAPI(\n    # user_agent=\"weather-tools-example/0.1 (contact: you@example.com)\",\n    enable_cache=True,\n    log_level=\"DEBUG\",\n)\n</pre> api = MetNoAPI(     # user_agent=\"weather-tools-example/0.1 (contact: you@example.com)\",     enable_cache=True,     log_level=\"DEBUG\", ) In\u00a0[4]: Copied! <pre>coordinates = AustralianCoordinates(\n    latitude=station_meta[\"latitude\"], longitude=station_meta[\"longitude\"]\n)  # Northam, WA\nquery = MetNoQuery(coordinates=coordinates, format=MetNoFormat.COMPACT)\n\nresponse = api.query_forecast(query)\nmetadata = response.get_meta()\n\nmetadata\n</pre> coordinates = AustralianCoordinates(     latitude=station_meta[\"latitude\"], longitude=station_meta[\"longitude\"] )  # Northam, WA query = MetNoQuery(coordinates=coordinates, format=MetNoFormat.COMPACT)  response = api.query_forecast(query) metadata = response.get_meta()  metadata <pre>[11/21/25 13:17:05] DEBUG    \ud83c\udf10 Constructed URL:                                                                   \n                             https://api.met.no/weatherapi/locationforecast/2.0/compact?lat=-31.651&amp;lon=116.659    \n</pre> <pre>                    DEBUG    \ud83d\udccb User-Agent: weather-tools/0.0.0 (Python 3.12)                                      \n</pre> <pre>                    DEBUG    Making request (attempt 1/3):                                                         \n                             https://api.met.no/weatherapi/locationforecast/2.0/compact                            \n</pre> <pre>[11/21/25 13:17:06] DEBUG    Cached response for: e9450af0091badb1a028399707618845                                 \n</pre> <pre>                    DEBUG    Request successful on attempt 1                                                       \n</pre> Out[4]: <pre>{'updated_at': '2025-11-21T01:18:54Z',\n 'units': {'air_pressure_at_sea_level': 'hPa',\n  'air_temperature': 'celsius',\n  'cloud_area_fraction': '%',\n  'precipitation_amount': 'mm',\n  'relative_humidity': '%',\n  'wind_from_direction': 'degrees',\n  'wind_speed': 'm/s'}}</pre> In\u00a0[5]: Copied! <pre>daily_forecasts = api.to_dataframe(response, frequency=\"daily\")\nhourly_forecasts = api.to_dataframe(response, frequency=\"hourly\")\n\ndaily_forecasts.head()\n</pre> daily_forecasts = api.to_dataframe(response, frequency=\"daily\") hourly_forecasts = api.to_dataframe(response, frequency=\"hourly\")  daily_forecasts.head() Out[5]: date min_temperature max_temperature total_precipitation avg_wind_speed max_wind_speed avg_relative_humidity avg_pressure avg_cloud_fraction dominant_weather_symbol 0 2025-11-21 17.1 29.3 0.0 3.426316 5.1 48.757895 1008.336842 41.810526 partlycloudy_night 1 2025-11-22 15.0 29.4 0.3 5.058333 7.9 65.912500 1006.600000 33.129167 rainshowers_day 2 2025-11-23 12.1 22.6 0.1 6.073684 8.8 50.389474 1010.536842 19.694737 partlycloudy_day 3 2025-11-24 12.8 21.7 0.1 4.850000 6.4 58.775000 1011.625000 49.600000 partlycloudy_day 4 2025-11-25 12.6 23.8 0.0 4.500000 5.2 50.475000 1013.075000 23.850000 partlycloudy_day In\u00a0[6]: Copied! <pre>hourly_forecasts.head()\n</pre> hourly_forecasts.head() Out[6]: time air_pressure_at_sea_level air_temperature cloud_area_fraction relative_humidity wind_from_direction wind_speed precipitation_amount symbol_code 0 2025-11-21 05:00:00 1009.2 28.4 7.0 31.8 131.4 3.2 0.0 clearsky_day 1 2025-11-21 06:00:00 1008.4 29.0 5.5 29.8 136.2 2.4 0.0 clearsky_day 2 2025-11-21 07:00:00 1007.8 29.3 11.7 28.9 165.1 1.7 0.0 clearsky_day 3 2025-11-21 08:00:00 1007.5 29.2 26.6 28.6 200.4 2.1 0.0 fair_day 4 2025-11-21 09:00:00 1007.5 28.5 10.9 29.6 200.5 2.1 0.0 clearsky_day In\u00a0[7]: Copied! <pre>daily_df = api.get_daily_forecast(\n    latitude=coordinates.latitude,\n    longitude=coordinates.longitude,\n    days=5,\n)\n\ndaily_df  # Already a DataFrame!\n</pre> daily_df = api.get_daily_forecast(     latitude=coordinates.latitude,     longitude=coordinates.longitude,     days=5, )  daily_df  # Already a DataFrame! <pre>                    DEBUG    \ud83c\udf10 Constructed URL:                                                                   \n                             https://api.met.no/weatherapi/locationforecast/2.0/compact?lat=-31.651&amp;lon=116.659    \n</pre> <pre>                    DEBUG    \ud83d\udccb User-Agent: weather-tools/0.0.0 (Python 3.12)                                      \n</pre> <pre>                    DEBUG    Cache hit for request: e9450af0091badb1a028399707618845                               \n</pre> Out[7]: date min_temperature max_temperature total_precipitation avg_wind_speed max_wind_speed avg_relative_humidity avg_pressure avg_cloud_fraction dominant_weather_symbol 0 2025-11-21 17.1 29.3 0.0 3.426316 5.1 48.757895 1008.336842 41.810526 partlycloudy_night 1 2025-11-22 15.0 29.4 0.3 5.058333 7.9 65.912500 1006.600000 33.129167 rainshowers_day 2 2025-11-23 12.1 22.6 0.1 6.073684 8.8 50.389474 1010.536842 19.694737 partlycloudy_day 3 2025-11-24 12.8 21.7 0.1 4.850000 6.4 58.775000 1011.625000 49.600000 partlycloudy_day 4 2025-11-25 12.6 23.8 0.0 4.500000 5.2 50.475000 1013.075000 23.850000 partlycloudy_day In\u00a0[9]: Copied! <pre>first_forecast_date = pd.to_datetime(daily_df[\"date\"]).min()\n# history_end = first_forecast_date - pd.Timedelta(days=1)\nhistory_start = first_forecast_date - pd.Timedelta(days=4)\nsilo_api = SiloAPI(log_level=\"INFO\")\nsilo_history = silo_api.get_data_drill(\n    latitude=coordinates.latitude,\n    longitude=coordinates.longitude,\n    start_date=history_start.strftime(\"%Y%m%d\"),\n    end_date=first_forecast_date.strftime(\"%Y%m%d\"),\n    variables=[\"daily_rain\", \"max_temp\", \"min_temp\", \"et_short_crop\"],\n)\n\n# silo_history = raw_silo.rename(columns={\"YYYY-MM-DD\": \"date\"}).copy()\n\n# silo_history[\"date\"] = pd.to_datetime(silo_history[\"date\"])\n\n# required_cols = [\"date\", \"min_temp\", \"max_temp\", \"daily_rain\"]\n# missing = [col for col in required_cols if col not in silo_history.columns]\n# if missing:\n#     raise ValueError(f\"Missing required columns from SILO response: {missing}\")\n\n# silo_data = silo_history[required_cols].sort_values(\"date\").reset_index(drop=True)\n\nmerged = merge_historical_and_forecast(\n    silo_data=silo_history,\n    metno_data=daily_df,\n    overlap_strategy=\"prefer_silo\",\n    return_cols=\"silo_only\",\n)\n\nmerged\n</pre> first_forecast_date = pd.to_datetime(daily_df[\"date\"]).min() # history_end = first_forecast_date - pd.Timedelta(days=1) history_start = first_forecast_date - pd.Timedelta(days=4) silo_api = SiloAPI(log_level=\"INFO\") silo_history = silo_api.get_data_drill(     latitude=coordinates.latitude,     longitude=coordinates.longitude,     start_date=history_start.strftime(\"%Y%m%d\"),     end_date=first_forecast_date.strftime(\"%Y%m%d\"),     variables=[\"daily_rain\", \"max_temp\", \"min_temp\", \"et_short_crop\"], )  # silo_history = raw_silo.rename(columns={\"YYYY-MM-DD\": \"date\"}).copy()  # silo_history[\"date\"] = pd.to_datetime(silo_history[\"date\"])  # required_cols = [\"date\", \"min_temp\", \"max_temp\", \"daily_rain\"] # missing = [col for col in required_cols if col not in silo_history.columns] # if missing: #     raise ValueError(f\"Missing required columns from SILO response: {missing}\")  # silo_data = silo_history[required_cols].sort_values(\"date\").reset_index(drop=True)  merged = merge_historical_and_forecast(     silo_data=silo_history,     metno_data=daily_df,     overlap_strategy=\"prefer_silo\",     return_cols=\"silo_only\", )  merged <pre>[11/21/25 13:17:16] INFO     Auto-detected transition date: 2025-11-21 00:00:00                                    \n</pre> <pre>                    INFO     Merged 4 SILO records with 5 met.no records. Total: 9 records                         \n</pre> Out[9]: latitude longitude daily_rain max_temp min_temp et_short_crop date data_source is_forecast 0 -31.651 116.659 0.0 35.6 13.2 7.3 2025-11-17 silo False 1 -31.651 116.659 0.4 31.3 16.4 4.8 2025-11-18 silo False 2 -31.651 116.659 0.6 28.5 16.5 4.9 2025-11-19 silo False 3 -31.651 116.659 0.0 28.4 16.2 5.1 2025-11-20 silo False 4 NaN NaN 0.0 29.3 17.1 NaN 2025-11-21 metno True 5 NaN NaN 0.3 29.4 15.0 NaN 2025-11-22 metno True 6 NaN NaN 0.1 22.6 12.1 NaN 2025-11-23 metno True 7 NaN NaN 0.1 21.7 12.8 NaN 2025-11-24 metno True 8 NaN NaN 0.0 23.8 12.6 NaN 2025-11-25 metno True In\u00a0[10]: Copied! <pre>merge_summary = get_merge_summary(merged)\nmerge_summary\n</pre> merge_summary = get_merge_summary(merged) merge_summary Out[10]: <pre>{'total_records': 9,\n 'silo_records': np.int64(4),\n 'metno_records': np.int64(5),\n 'date_range': {'start': Timestamp('2025-11-17 00:00:00'),\n  'end': Timestamp('2025-11-25 00:00:00'),\n  'days': 9},\n 'silo_period': {'start': Timestamp('2025-11-17 00:00:00'),\n  'end': Timestamp('2025-11-20 00:00:00')},\n 'metno_period': {'start': Timestamp('2025-11-21 00:00:00'),\n  'end': Timestamp('2025-11-25 00:00:00')},\n 'transition_date': Timestamp('2025-11-21 00:00:00')}</pre> In\u00a0[11]: Copied! <pre>first_forecast_date = pd.to_datetime(daily_forecasts[\"date\"]).min()\nhistory_end = first_forecast_date  # - pd.Timedelta(days=1) # Include day before forecast to check overlap handling\nhistory_start = history_end - pd.Timedelta(days=4)\n\n\nsilo_station_data = silo_api.get_patched_point(\n    station_code=str(station_meta[\"station_code\"]),\n    start_date=history_start.strftime(\"%Y%m%d\"),\n    end_date=history_end.strftime(\"%Y%m%d\"),\n    variables=[\"daily_rain\", \"max_temp\", \"min_temp\", \"et_short_crop\"],\n)\n\nmerge_historical_and_forecast(\n    silo_data=silo_station_data,\n    metno_data=daily_df,\n    return_cols=\"silo_only\",\n)\n</pre> first_forecast_date = pd.to_datetime(daily_forecasts[\"date\"]).min() history_end = first_forecast_date  # - pd.Timedelta(days=1) # Include day before forecast to check overlap handling history_start = history_end - pd.Timedelta(days=4)   silo_station_data = silo_api.get_patched_point(     station_code=str(station_meta[\"station_code\"]),     start_date=history_start.strftime(\"%Y%m%d\"),     end_date=history_end.strftime(\"%Y%m%d\"),     variables=[\"daily_rain\", \"max_temp\", \"min_temp\", \"et_short_crop\"], )  merge_historical_and_forecast(     silo_data=silo_station_data,     metno_data=daily_df,     return_cols=\"silo_only\", ) <pre>[11/21/25 13:17:45] INFO     Auto-detected transition date: 2025-11-21 00:00:00                                    \n</pre> <pre>                    INFO     Merged 4 SILO records with 5 met.no records. Total: 9 records                         \n</pre> Out[11]: station daily_rain max_temp min_temp et_short_crop date data_source is_forecast 0 10111.0 0.0 35.5 13.3 7.3 2025-11-17 silo False 1 10111.0 0.4 31.5 16.1 4.8 2025-11-18 silo False 2 10111.0 0.4 28.6 17.0 5.1 2025-11-19 silo False 3 10111.0 0.0 28.9 16.1 5.2 2025-11-20 silo False 4 NaN 0.0 29.3 17.1 NaN 2025-11-21 metno True 5 NaN 0.3 29.4 15.0 NaN 2025-11-22 metno True 6 NaN 0.1 22.6 12.1 NaN 2025-11-23 metno True 7 NaN 0.1 21.7 12.8 NaN 2025-11-24 metno True 8 NaN 0.0 23.8 12.6 NaN 2025-11-25 metno True"},{"location":"notebooks/metno_forecast_example/#using-metno-forecasts-with-weather-tools","title":"Using met.no forecasts with weather-tools\u00b6","text":"<p>This notebook-style script shows how to fetch met.no forecasts and combine them</p> <p>with SILO observations using the new <code>weather_tools</code> APIs. Open it directly in</p> <p>JupyterLab or VS Code with Jupytext to run the cells interactively.</p>"},{"location":"notebooks/metno_forecast_example/#prerequisites","title":"Prerequisites\u00b6","text":"<ul> <li><p>Network access to <code>https://api.met.no</code> and a valid contact e-mail for the User-Agent header.</p> </li> <li><p>Set <code>SILO_API_KEY</code> (your registered SILO e-mail) or pass <code>api_key=</code> directly to <code>SiloAPI</code>.</p> </li> <li><p>Install <code>weather-tools</code> in your environment (either via <code>pip install weather-tools</code> or the local checkout).</p> </li> <li><p>Optional: enable logging (e.g. <code>logging.basicConfig(level=logging.INFO)</code>) to inspect requests.</p> </li> </ul>"},{"location":"notebooks/metno_forecast_example/#1-configure-the-metno-api-client","title":"1. Configure the met.no API client\u00b6","text":"<p>met.no requires a descriptive User-Agent string that includes contact details.</p> <p>Replace the placeholder below with your own application name and e-mail.</p>"},{"location":"notebooks/metno_forecast_example/#2-build-a-forecast-query-for-your-location","title":"2. Build a forecast query for your location\u00b6","text":"<p>The <code>AustralianCoordinates</code> model validates that the latitude and longitude sit</p> <p>within the range supported by SILO (GDA94 datum). Adjust the coordinates to</p> <p>target your site of interest.</p>"},{"location":"notebooks/metno_forecast_example/#3-convert-forecasts-to-daily-and-hourly-tables","title":"3. Convert forecasts to daily and hourly tables\u00b6","text":"<p><code>MetNoAPI.to_dataframe</code> can aggregate the hourly GeoJSON payload to daily summaries</p> <p>or return hourly data. Use the <code>frequency</code> parameter to control aggregation:</p> <ul> <li><p><code>frequency='daily'</code> (default) - Daily aggregates</p> </li> <li><p><code>frequency='hourly'</code> - Raw hourly data</p> </li> <li><p><code>frequency='weekly'</code> or <code>frequency='monthly'</code> - Other time periods</p> </li> </ul>"},{"location":"notebooks/metno_forecast_example/#quick-helper-get_daily_forecast","title":"Quick helper: <code>get_daily_forecast</code>\u00b6","text":"<p><code>get_daily_forecast</code> returns a pandas DataFrame directly with daily summaries,</p>"},{"location":"notebooks/metno_forecast_example/#4-merge-metno-forecasts-with-silo-history","title":"4. Merge met.no forecasts with SILO history\u00b6","text":"<p>Pull the last five days from the SILO DataDrill API for the same coordinates,</p> <p>then merge that history with the met.no forecast. The helper automatically</p> <p>converts column names, fills optional variables (when enabled), and annotates</p> <p>the data source for each record.</p>"},{"location":"notebooks/metno_forecast_example/#4b-merge-forecast-with-silo-patchedpoint","title":"4b. Merge Forecast with SILO PatchedPoint\u00b6","text":"<p>Pull the last four days from the SILO Patch Point API for the same coordinates, using the station code.</p>"},{"location":"notebooks/silo_api_examples/","title":"SILO API","text":"In\u00a0[1]: Copied! <pre>import os\nfrom datetime import datetime, timedelta\n\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport pandas as pd\n\n# Import the SILO API client\nfrom weather_tools.silo_api import SiloAPI\n\n# Set up plotting style\nplt.style.use(\"default\")\nplt.rcParams[\"figure.figsize\"] = (12, 6)\n\nprint(\"Libraries imported successfully!\")\n</pre> import os from datetime import datetime, timedelta  import matplotlib.pyplot as plt import numpy as np import pandas as pd  # Import the SILO API client from weather_tools.silo_api import SiloAPI  # Set up plotting style plt.style.use(\"default\") plt.rcParams[\"figure.figsize\"] = (12, 6)  print(\"Libraries imported successfully!\") <pre>Libraries imported successfully!\n</pre> In\u00a0[2]: Copied! <pre># Initialize the API client\n# Note: You need to set your SILO_API_KEY environment variable or provide your email as api_key\n# For this example, we'll use a placeholder - replace with your actual email\n\ntry:\n    # Try to use environment variable first\n    api = SiloAPI()  # Uses SILO_API_KEY environment variable\n    print(\"\u2705 API client initialized using SILO_API_KEY environment variable\")\nexcept ValueError:\n    # If no environment variable, use a placeholder (you should replace this with your email)\n    api = SiloAPI(api_key=\"your_email@example.com\")  # Replace with your email\n    print(\"\u26a0\ufe0f  API client initialized with placeholder email - replace with your actual email\")\n    print(\"   Set SILO_API_KEY environment variable or update the api_key parameter above\")\n</pre> # Initialize the API client # Note: You need to set your SILO_API_KEY environment variable or provide your email as api_key # For this example, we'll use a placeholder - replace with your actual email  try:     # Try to use environment variable first     api = SiloAPI()  # Uses SILO_API_KEY environment variable     print(\"\u2705 API client initialized using SILO_API_KEY environment variable\") except ValueError:     # If no environment variable, use a placeholder (you should replace this with your email)     api = SiloAPI(api_key=\"your_email@example.com\")  # Replace with your email     print(\"\u26a0\ufe0f  API client initialized with placeholder email - replace with your actual email\")     print(\"   Set SILO_API_KEY environment variable or update the api_key parameter above\") <pre>\u2705 API client initialized using SILO_API_KEY environment variable\n</pre> In\u00a0[3]: Copied! <pre># Search for stations containing \"Brisbane\" in the name\nbrisbane_stations = api.search_stations(name_fragment=\"Brisbane\")\n\nprint(f\"Found {len(brisbane_stations)} stations with 'Brisbane' in the name:\")\nprint(\"\\nFirst 10 stations:\")\nprint(brisbane_stations.head(10).to_string(index=False))\n</pre> # Search for stations containing \"Brisbane\" in the name brisbane_stations = api.search_stations(name_fragment=\"Brisbane\")  print(f\"Found {len(brisbane_stations)} stations with 'Brisbane' in the name:\") print(\"\\nFirst 10 stations:\") print(brisbane_stations.head(10).to_string(index=False)) <pre>Found 7 stations with 'Brisbane' in the name:\n\nFirst 10 stations:\n station_code                       name  latitude  longitude state  elevation\n        40913                   BRISBANE   -27.481    153.039   QLD        8.1\n        40223              BRISBANE AERO   -27.418    153.114   QLD        4.0\n        40842              BRISBANE AERO   -27.392    153.129   QLD        4.5\n        40216      BRISBANE SHOW GROUNDS   -27.451    153.033   QLD       16.0\n        40214   BRISBANE REGIONAL OFFICE   -27.478    153.031   QLD       38.0\n        40215 BRISBANE BOTANICAL GARDENS   -27.483    153.033   QLD       15.0\n        40140                MT BRISBANE   -27.149    152.578   QLD      100.0\n</pre> In\u00a0[4]: Copied! <pre># Let's pick a specific Brisbane station for our examples\n# Brisbane Airport is station 30043 - a well-known station with good data coverage\nselected_station = \"30043\"\nstation_info = brisbane_stations.iloc[0]\n\nstation_name = station_info[\"name\"]\nstation_lat = station_info[\"latitude\"]\nstation_lon = station_info[\"longitude\"]\nprint(f\"Selected station: {station_name} (Code: {selected_station})\")\nprint(f\"Location: {station_lat}\u00b0S, {station_lon}\u00b0E\")\n</pre> # Let's pick a specific Brisbane station for our examples # Brisbane Airport is station 30043 - a well-known station with good data coverage selected_station = \"30043\" station_info = brisbane_stations.iloc[0]  station_name = station_info[\"name\"] station_lat = station_info[\"latitude\"] station_lon = station_info[\"longitude\"] print(f\"Selected station: {station_name} (Code: {selected_station})\") print(f\"Location: {station_lat}\u00b0S, {station_lon}\u00b0E\") <pre>Selected station: BRISBANE (Code: 30043)\nLocation: -27.481\u00b0S, 153.039\u00b0E\n</pre> In\u00a0[6]: Copied! <pre># Get weather data for January 2023\nstart_date = \"20230101\"\nend_date = \"20230131\"\nvariables = [\"daily_rain\", \"max_temp\", \"min_temp\"]\n\nprint(f\"Getting weather data for station {selected_station} ({station_name})\")\nprint(f\"Date range: {start_date} to {end_date}\")\nprint(f\"Variables: {variables}\")\n\n# Get the data\nstation_data = api.get_patched_point(\n    station_code=selected_station, start_date=start_date, end_date=end_date, variables=variables\n)\n\nprint(f\"\\n\ud83d\udcca Retrieved {len(station_data)} days of data\")\nprint(\"\\nFirst 5 rows:\")\nprint(station_data.head())\n</pre> # Get weather data for January 2023 start_date = \"20230101\" end_date = \"20230131\" variables = [\"daily_rain\", \"max_temp\", \"min_temp\"]  print(f\"Getting weather data for station {selected_station} ({station_name})\") print(f\"Date range: {start_date} to {end_date}\") print(f\"Variables: {variables}\")  # Get the data station_data = api.get_patched_point(     station_code=selected_station, start_date=start_date, end_date=end_date, variables=variables )  print(f\"\\n\ud83d\udcca Retrieved {len(station_data)} days of data\") print(\"\\nFirst 5 rows:\") print(station_data.head()) <pre>Getting weather data for station 30043 (BRISBANE)\nDate range: 20230101 to 20230131\nVariables: ['daily_rain', 'max_temp', 'min_temp']\n\n\ud83d\udcca Retrieved 31 days of data\n\nFirst 5 rows:\n   station  daily_rain  daily_rain_source  max_temp  max_temp_source  \\\n0    30043         0.0                 25      37.4               25   \n1    30043         3.2                 25      35.3               25   \n2    30043         9.3                 25      35.2               25   \n3    30043         0.8                 25      35.3               25   \n4    30043         4.4                 25      34.7               25   \n\n   min_temp  min_temp_source       date  \\\n0      24.7               25 2023-01-01   \n1      23.8               25 2023-01-02   \n2      23.8               25 2023-01-03   \n3      24.1               25 2023-01-04   \n4      24.2               25 2023-01-05   \n\n                                            metadata  \n0  {\"name\": \"PROA STATION\", \"latitude\": \"-20.8944...  \n1                                                NaN  \n2                                                NaN  \n3                                                NaN  \n4                                                NaN  \n</pre> In\u00a0[7]: Copied! <pre># Let's also get the data with metadata to see what information is included\nstation_data_with_meta, metadata = api.get_patched_point(\n    station_code=selected_station,\n    start_date=start_date,\n    end_date=end_date,\n    variables=variables,\n    return_metadata=True,\n)\n\nprint(\"Metadata information:\")\nfor key, value in metadata.items():\n    print(f\"  {key}: {value}\")\n</pre> # Let's also get the data with metadata to see what information is included station_data_with_meta, metadata = api.get_patched_point(     station_code=selected_station,     start_date=start_date,     end_date=end_date,     variables=variables,     return_metadata=True, )  print(\"Metadata information:\") for key, value in metadata.items():     print(f\"  {key}: {value}\") <pre>Metadata information:\n  station_code: 30043\n  date_range: {'start': '20230101', 'end': '20230131'}\n  variables: ['daily_rain', 'max_temp', 'min_temp']\n  format: csv\n  dataset: PatchedPoint\n</pre> In\u00a0[8]: Copied! <pre># Create plots for the station data\nfig, axes = plt.subplots(2, 1, figsize=(14, 10))\n\n# Convert date column to datetime if it's not already\nstation_data[\"date\"] = pd.to_datetime(station_data[\"date\"])\n\n\n# Plot 1: Temperature\n\naxes[0].plot(\n    station_data[\"date\"], station_data[\"max_temp\"], \"r-\", label=\"Max Temperature\", linewidth=2\n)\naxes[0].plot(\n    station_data[\"date\"], station_data[\"min_temp\"], \"b-\", label=\"Min Temperature\", linewidth=2\n)\n\naxes[0].set_title(\n    f\"Daily Temperature - {station_name} (January 2023)\", fontsize=14, fontweight=\"bold\"\n)\naxes[0].set_ylabel(\"Temperature (\u00b0C)\", fontsize=12)\naxes[0].legend()\naxes[0].grid(True, alpha=0.3)\n\n# Plot 2: Rainfall\nrain_cols = [col for col in station_data.columns if \"rain\" in col.lower() or \"R_\" in col]\nif rain_cols:\n    rain_col = rain_cols[0]\n    axes[1].bar(station_data[\"date\"], station_data[rain_col], color=\"skyblue\", alpha=0.7, width=0.8)\n    axes[1].set_title(\n        f\"Daily Rainfall - {station_name} (January 2023)\", fontsize=14, fontweight=\"bold\"\n    )\n    axes[1].set_ylabel(\"Rainfall (mm)\", fontsize=12)\n    axes[1].set_xlabel(\"Date\", fontsize=12)\n    axes[1].grid(True, alpha=0.3)\n\nplt.tight_layout()\nplt.show()\n\n# Print some basic statistics\nprint(\"\\n\ud83d\udcc8 Basic Statistics:\")\nprint(station_data.describe())\n</pre> # Create plots for the station data fig, axes = plt.subplots(2, 1, figsize=(14, 10))  # Convert date column to datetime if it's not already station_data[\"date\"] = pd.to_datetime(station_data[\"date\"])   # Plot 1: Temperature  axes[0].plot(     station_data[\"date\"], station_data[\"max_temp\"], \"r-\", label=\"Max Temperature\", linewidth=2 ) axes[0].plot(     station_data[\"date\"], station_data[\"min_temp\"], \"b-\", label=\"Min Temperature\", linewidth=2 )  axes[0].set_title(     f\"Daily Temperature - {station_name} (January 2023)\", fontsize=14, fontweight=\"bold\" ) axes[0].set_ylabel(\"Temperature (\u00b0C)\", fontsize=12) axes[0].legend() axes[0].grid(True, alpha=0.3)  # Plot 2: Rainfall rain_cols = [col for col in station_data.columns if \"rain\" in col.lower() or \"R_\" in col] if rain_cols:     rain_col = rain_cols[0]     axes[1].bar(station_data[\"date\"], station_data[rain_col], color=\"skyblue\", alpha=0.7, width=0.8)     axes[1].set_title(         f\"Daily Rainfall - {station_name} (January 2023)\", fontsize=14, fontweight=\"bold\"     )     axes[1].set_ylabel(\"Rainfall (mm)\", fontsize=12)     axes[1].set_xlabel(\"Date\", fontsize=12)     axes[1].grid(True, alpha=0.3)  plt.tight_layout() plt.show()  # Print some basic statistics print(\"\\n\ud83d\udcc8 Basic Statistics:\") print(station_data.describe()) <pre>\n\ud83d\udcc8 Basic Statistics:\n       station  daily_rain  daily_rain_source   max_temp  max_temp_source  \\\ncount     31.0   31.000000               31.0  31.000000             31.0   \nmean   30043.0    2.906452               25.0  35.990323             25.0   \nmin    30043.0    0.000000               25.0  31.400000             25.0   \n25%    30043.0    0.250000               25.0  34.450000             25.0   \n50%    30043.0    1.300000               25.0  36.600000             25.0   \n75%    30043.0    4.350000               25.0  38.300000             25.0   \nmax    30043.0   19.200000               25.0  39.300000             25.0   \nstd        0.0    4.026325                0.0   2.530264              0.0   \n\n        min_temp  min_temp_source                 date  \ncount  31.000000             31.0                   31  \nmean   23.783871             25.0  2023-01-16 00:00:00  \nmin    20.500000             25.0  2023-01-01 00:00:00  \n25%    22.950000             25.0  2023-01-08 12:00:00  \n50%    23.800000             25.0  2023-01-16 00:00:00  \n75%    24.500000             25.0  2023-01-23 12:00:00  \nmax    26.700000             25.0  2023-01-31 00:00:00  \nstd     1.376734              0.0                  NaN  \n</pre> In\u00a0[9]: Copied! <pre># Let's get gridded data for a location near our station\n# Using coordinates close to Brisbane Airport but slightly different\ntarget_lat = -27.5\ntarget_lon = 153.0\n\nprint(f\"Getting gridded climate data for coordinates: {target_lat}\u00b0S, {target_lon}\u00b0E\")\nprint(f\"Date range: {start_date} to {end_date}\")\nprint(f\"Variables: {variables}\")\n\n# Get gridded data\ngridded_data = api.get_data_drill(\n    latitude=target_lat,\n    longitude=target_lon,\n    start_date=start_date,\n    end_date=end_date,\n    variables=variables,\n)\n\nprint(f\"\\n\ud83d\udcca Retrieved {len(gridded_data)} days of gridded data\")\nprint(\"\\nFirst 5 rows:\")\nprint(gridded_data.head())\n</pre> # Let's get gridded data for a location near our station # Using coordinates close to Brisbane Airport but slightly different target_lat = -27.5 target_lon = 153.0  print(f\"Getting gridded climate data for coordinates: {target_lat}\u00b0S, {target_lon}\u00b0E\") print(f\"Date range: {start_date} to {end_date}\") print(f\"Variables: {variables}\")  # Get gridded data gridded_data = api.get_data_drill(     latitude=target_lat,     longitude=target_lon,     start_date=start_date,     end_date=end_date,     variables=variables, )  print(f\"\\n\ud83d\udcca Retrieved {len(gridded_data)} days of gridded data\") print(\"\\nFirst 5 rows:\") print(gridded_data.head()) <pre>Getting gridded climate data for coordinates: -27.5\u00b0S, 153.0\u00b0E\nDate range: 20230101 to 20230131\nVariables: ['daily_rain', 'max_temp', 'min_temp']\n\n\ud83d\udcca Retrieved 31 days of gridded data\n\nFirst 5 rows:\n   latitude  longitude  daily_rain  daily_rain_source  max_temp  \\\n0     -27.5      153.0         0.2                 25      29.1   \n1     -27.5      153.0         0.0                 25      29.5   \n2     -27.5      153.0         0.0                 25      31.7   \n3     -27.5      153.0         0.0                 25      32.7   \n4     -27.5      153.0        37.3                 25      27.7   \n\n   max_temp_source  min_temp  min_temp_source       date  \\\n0               25      19.4               25 2023-01-01   \n1               25      18.2               25 2023-01-02   \n2               25      17.3               25 2023-01-03   \n3               25      19.8               25 2023-01-04   \n4               25      21.8               25 2023-01-05   \n\n                                            metadata  \n0  {\"elevation\": \"18.6 m\", \"reference\": \"RXN\", \"e...  \n1                                                NaN  \n2                                                NaN  \n3                                                NaN  \n4                                                NaN  \n</pre> In\u00a0[10]: Copied! <pre># Compare station data vs gridded data\nfig, axes = plt.subplots(2, 2, figsize=(16, 10))\n\n\n# Helper function to find temperature and rainfall columns\ndef find_columns(df, pattern):\n    return [col for col in df.columns if any(p in col.lower() for p in pattern)]\n\n\n# Find date columns for both datasets\ndate_col = \"date\"\nmax_temp = \"max_temp\"\nmin_temp = \"min_temp\"\n\n# Ensure dates are datetime\nstation_data[date_col] = pd.to_datetime(station_data[date_col])\ngridded_data[date_col] = pd.to_datetime(gridded_data[date_col])\n\n\n# Plot max temperature comparison\naxes[0, 0].plot(\n    station_data[date_col], station_data[max_temp], \"r-\", label=\"Station Data\", linewidth=2\n)\naxes[0, 0].plot(\n    gridded_data[date_col], gridded_data[max_temp], \"b--\", label=\"Gridded Data\", linewidth=2\n)\naxes[0, 0].set_title(\"Max Temperature Comparison\", fontweight=\"bold\")\naxes[0, 0].set_ylabel(\"Temperature (\u00b0C)\")\naxes[0, 0].legend()\naxes[0, 0].grid(True, alpha=0.3)\n\n# Plot min temperature comparison\naxes[0, 1].plot(\n    station_data[date_col], station_data[min_temp], \"r-\", label=\"Station Data\", linewidth=2\n)\naxes[0, 1].plot(\n    gridded_data[date_col], gridded_data[min_temp], \"b--\", label=\"Gridded Data\", linewidth=2\n)\naxes[0, 1].set_title(\"Min Temperature Comparison\", fontweight=\"bold\")\naxes[0, 1].set_ylabel(\"Temperature (\u00b0C)\")\naxes[0, 1].legend()\naxes[0, 1].grid(True, alpha=0.3)\n\n\nwidth = 0.35\nx = np.arange(len(station_data))\n\naxes[1, 0].bar(\n    x - width / 2, station_data[\"daily_rain\"], width, label=\"Station Data\", color=\"red\", alpha=0.7\n)\naxes[1, 0].bar(\n    x + width / 2, gridded_data[\"daily_rain\"], width, label=\"Gridded Data\", color=\"blue\", alpha=0.7\n)\naxes[1, 0].set_title(\"Rainfall Comparison\", fontweight=\"bold\")\naxes[1, 0].set_ylabel(\"Rainfall (mm)\")\naxes[1, 0].set_xlabel(\"Day of Month\")\naxes[1, 0].legend()\naxes[1, 0].grid(True, alpha=0.3)\n\n# Scatter plot showing correlation\naxes[1, 1].scatter(\n    station_data[max_temp], gridded_data[max_temp], alpha=0.6, color=\"red\", label=\"Max Temp\"\n)\naxes[1, 1].scatter(\n    station_data[min_temp], gridded_data[min_temp], alpha=0.6, color=\"blue\", label=\"Min Temp\"\n)\n\n# Add diagonal line for perfect correlation\nmin_temp = min(station_data[min_temp].min(), gridded_data[min_temp].min())\nmax_temp = max(station_data[max_temp].max(), gridded_data[max_temp].max())\naxes[1, 1].plot(\n    [min_temp, max_temp], [min_temp, max_temp], \"k--\", alpha=0.5, label=\"Perfect Correlation\"\n)\naxes[1, 1].set_title(\"Station vs Gridded Data Correlation\", fontweight=\"bold\")\naxes[1, 1].set_xlabel(\"Station Data (\u00b0C)\")\naxes[1, 1].set_ylabel(\"Gridded Data (\u00b0C)\")\naxes[1, 1].legend()\naxes[1, 1].grid(True, alpha=0.3)\n\nplt.tight_layout()\nplt.show()\n\nprint(\"\\n\ud83d\udcca Data source comparison completed!\")\nprint(f\"Station location: {station_lat}\u00b0S, {station_lon}\u00b0E\")\nprint(f\"Gridded location: {target_lat}\u00b0S, {target_lon}\u00b0E\")\nprint(\n    f\"Distance: ~{((station_lat - target_lat) ** 2 + (station_lon - target_lon) ** 2) ** 0.5 * 111:.1f} km\"\n)\n</pre> # Compare station data vs gridded data fig, axes = plt.subplots(2, 2, figsize=(16, 10))   # Helper function to find temperature and rainfall columns def find_columns(df, pattern):     return [col for col in df.columns if any(p in col.lower() for p in pattern)]   # Find date columns for both datasets date_col = \"date\" max_temp = \"max_temp\" min_temp = \"min_temp\"  # Ensure dates are datetime station_data[date_col] = pd.to_datetime(station_data[date_col]) gridded_data[date_col] = pd.to_datetime(gridded_data[date_col])   # Plot max temperature comparison axes[0, 0].plot(     station_data[date_col], station_data[max_temp], \"r-\", label=\"Station Data\", linewidth=2 ) axes[0, 0].plot(     gridded_data[date_col], gridded_data[max_temp], \"b--\", label=\"Gridded Data\", linewidth=2 ) axes[0, 0].set_title(\"Max Temperature Comparison\", fontweight=\"bold\") axes[0, 0].set_ylabel(\"Temperature (\u00b0C)\") axes[0, 0].legend() axes[0, 0].grid(True, alpha=0.3)  # Plot min temperature comparison axes[0, 1].plot(     station_data[date_col], station_data[min_temp], \"r-\", label=\"Station Data\", linewidth=2 ) axes[0, 1].plot(     gridded_data[date_col], gridded_data[min_temp], \"b--\", label=\"Gridded Data\", linewidth=2 ) axes[0, 1].set_title(\"Min Temperature Comparison\", fontweight=\"bold\") axes[0, 1].set_ylabel(\"Temperature (\u00b0C)\") axes[0, 1].legend() axes[0, 1].grid(True, alpha=0.3)   width = 0.35 x = np.arange(len(station_data))  axes[1, 0].bar(     x - width / 2, station_data[\"daily_rain\"], width, label=\"Station Data\", color=\"red\", alpha=0.7 ) axes[1, 0].bar(     x + width / 2, gridded_data[\"daily_rain\"], width, label=\"Gridded Data\", color=\"blue\", alpha=0.7 ) axes[1, 0].set_title(\"Rainfall Comparison\", fontweight=\"bold\") axes[1, 0].set_ylabel(\"Rainfall (mm)\") axes[1, 0].set_xlabel(\"Day of Month\") axes[1, 0].legend() axes[1, 0].grid(True, alpha=0.3)  # Scatter plot showing correlation axes[1, 1].scatter(     station_data[max_temp], gridded_data[max_temp], alpha=0.6, color=\"red\", label=\"Max Temp\" ) axes[1, 1].scatter(     station_data[min_temp], gridded_data[min_temp], alpha=0.6, color=\"blue\", label=\"Min Temp\" )  # Add diagonal line for perfect correlation min_temp = min(station_data[min_temp].min(), gridded_data[min_temp].min()) max_temp = max(station_data[max_temp].max(), gridded_data[max_temp].max()) axes[1, 1].plot(     [min_temp, max_temp], [min_temp, max_temp], \"k--\", alpha=0.5, label=\"Perfect Correlation\" ) axes[1, 1].set_title(\"Station vs Gridded Data Correlation\", fontweight=\"bold\") axes[1, 1].set_xlabel(\"Station Data (\u00b0C)\") axes[1, 1].set_ylabel(\"Gridded Data (\u00b0C)\") axes[1, 1].legend() axes[1, 1].grid(True, alpha=0.3)  plt.tight_layout() plt.show()  print(\"\\n\ud83d\udcca Data source comparison completed!\") print(f\"Station location: {station_lat}\u00b0S, {station_lon}\u00b0E\") print(f\"Gridded location: {target_lat}\u00b0S, {target_lon}\u00b0E\") print(     f\"Distance: ~{((station_lat - target_lat) ** 2 + (station_lon - target_lon) ** 2) ** 0.5 * 111:.1f} km\" ) <pre>\n\ud83d\udcca Data source comparison completed!\nStation location: -27.481\u00b0S, 153.039\u00b0E\nGridded location: -27.5\u00b0S, 153.0\u00b0E\nDistance: ~4.8 km\n</pre> In\u00a0[11]: Copied! <pre># Get recent data for our selected station (last 7 days)\nprint(f\"Getting recent data (last 7 days) for station {selected_station}\")\nrecent_station_data = api.get_recent_data(\n    station_code=selected_station, days=7, variables=[\"rainfall\", \"max_temp\", \"min_temp\"]\n)\n\nprint(f\"\ud83d\udcca Retrieved {len(recent_station_data)} days of recent station data\")\nprint(\"\\nRecent station data:\")\nprint(recent_station_data.head(10))\n</pre> # Get recent data for our selected station (last 7 days) print(f\"Getting recent data (last 7 days) for station {selected_station}\") recent_station_data = api.get_recent_data(     station_code=selected_station, days=7, variables=[\"rainfall\", \"max_temp\", \"min_temp\"] )  print(f\"\ud83d\udcca Retrieved {len(recent_station_data)} days of recent station data\") print(\"\\nRecent station data:\") print(recent_station_data.head(10)) <pre>Getting recent data (last 7 days) for station 30043\n</pre> <pre>\n---------------------------------------------------------------------------\nValueError                                Traceback (most recent call last)\nCell In[11], line 3\n      1 # Get recent data for our selected station (last 7 days)\n      2 print(f\"Getting recent data (last 7 days) for station {selected_station}\")\n----&gt; 3 recent_station_data = api.get_recent_data(\n      4     station_code=selected_station, days=7, variables=[\"rainfall\", \"max_temp\", \"min_temp\"]\n      5 )\n      7 print(f\"\ud83d\udcca Retrieved {len(recent_station_data)} days of recent station data\")\n      8 print(\"\\nRecent station data:\")\n\nFile ~/Developer/weather_tools/src/weather_tools/silo_api.py:661, in SiloAPI.get_recent_data(self, station_code, latitude, longitude, days, variables)\n    658 end_str = end_date.strftime(\"%Y%m%d\")\n    660 if station_code:\n--&gt; 661     return self.get_patched_point(station_code, start_str, end_str, variables)\n    662 elif latitude is not None and longitude is not None:\n    663     return self.get_data_drill(latitude, longitude, start_str, end_str, variables)\n\nFile ~/Developer/weather_tools/src/weather_tools/silo_api.py:415, in SiloAPI.get_patched_point(self, station_code, start_date, end_date, variables, format, return_metadata)\n    413 if invalid:\n    414     valid_names = \", \".join(sorted(VARIABLES.keys()))\n--&gt; 415     raise ValueError(f\"Unknown variables: {invalid}. Valid names: {valid_names}\")\n    417 # Convert format string to SiloFormat enum\n    418 format_mapping = {\n    419     \"csv\": SiloFormat.CSV,\n    420     \"apsim\": SiloFormat.APSIM,\n    421     \"standard\": SiloFormat.STANDARD,\n    422 }\n\nValueError: Unknown variables: ['rainfall']. Valid names: cloud_fraction, daily_rain, et_morton_actual, et_morton_potential, et_morton_wet, et_short_crop, et_tall_crop, evap_comb, evap_morton_lake, evap_pan, evap_syn, max_temp, min_temp, monthly_rain, mslp, radiation, rh_tmax, rh_tmin, vp, vp_deficit, weather_symbol, wind_speed, wind_speed_max</pre> In\u00a0[13]: Copied! <pre># Get recent gridded data for our coordinates\nprint(f\"\\nGetting recent gridded data (last 7 days) for {target_lat}\u00b0S, {target_lon}\u00b0E\")\nrecent_gridded_data = api.get_recent_data(\n    latitude=target_lat,\n    longitude=target_lon,\n    days=7,\n    variables=[\"daily_rain\", \"max_temp\", \"min_temp\"],\n)\n\nprint(f\"\ud83d\udcca Retrieved {len(recent_gridded_data)} days of recent gridded data\")\nprint(\"\\nRecent gridded data:\")\nprint(recent_gridded_data.head(10))\n</pre> # Get recent gridded data for our coordinates print(f\"\\nGetting recent gridded data (last 7 days) for {target_lat}\u00b0S, {target_lon}\u00b0E\") recent_gridded_data = api.get_recent_data(     latitude=target_lat,     longitude=target_lon,     days=7,     variables=[\"daily_rain\", \"max_temp\", \"min_temp\"], )  print(f\"\ud83d\udcca Retrieved {len(recent_gridded_data)} days of recent gridded data\") print(\"\\nRecent gridded data:\") print(recent_gridded_data.head(10)) <pre>\nGetting recent gridded data (last 7 days) for -27.5\u00b0S, 153.0\u00b0E\n\ud83d\udcca Retrieved 7 days of recent gridded data\n\nRecent gridded data:\n   latitude  longitude  daily_rain  daily_rain_source  max_temp  \\\n0     -27.5      153.0         2.9                 25      28.3   \n1     -27.5      153.0        21.9                 25      30.7   \n2     -27.5      153.0        14.7                 25      28.0   \n3     -27.5      153.0         1.4                 25      33.4   \n4     -27.5      153.0         0.0                 25      27.5   \n5     -27.5      153.0         0.0                 25      28.9   \n6     -27.5      153.0         0.0                 25      28.0   \n\n   max_temp_source  min_temp  min_temp_source       date  \\\n0               25      18.8               25 2025-11-14   \n1               25      18.9               25 2025-11-15   \n2               25      20.9               25 2025-11-16   \n3               25      20.2               25 2025-11-17   \n4               25      15.9               25 2025-11-18   \n5               25      16.5               25 2025-11-19   \n6               75      18.6               25 2025-11-20   \n\n                                            metadata  \n0  {\"elevation\": \"18.6 m\", \"reference\": \"RXN\", \"e...  \n1                                                NaN  \n2                                                NaN  \n3                                                NaN  \n4                                                NaN  \n5                                                NaN  \n6                                                NaN  \n</pre> In\u00a0[14]: Copied! <pre># Tip 1: Getting all available variables\nprint(\"\ud83d\udca1 TIP 1: Getting all available climate variables\")\nprint(\"=\" * 50)\n\n# When variables=None, all available variables are retrieved\nall_vars_data = api.get_patched_point(\n    station_code=selected_station,\n    start_date=\"20230101\",\n    end_date=\"20230105\",  # Just a few days to keep output manageable\n    variables=None,  # This gets ALL available variables\n)\n\nprint(f\"Available columns when variables=None:\")\nfor i, col in enumerate(all_vars_data.columns, 1):\n    print(f\"  {i:2d}. {col}\")\n\nprint(f\"\\nDataFrame shape: {all_vars_data.shape[0]} rows \u00d7 {all_vars_data.shape[1]} columns\")\n</pre> # Tip 1: Getting all available variables print(\"\ud83d\udca1 TIP 1: Getting all available climate variables\") print(\"=\" * 50)  # When variables=None, all available variables are retrieved all_vars_data = api.get_patched_point(     station_code=selected_station,     start_date=\"20230101\",     end_date=\"20230105\",  # Just a few days to keep output manageable     variables=None,  # This gets ALL available variables )  print(f\"Available columns when variables=None:\") for i, col in enumerate(all_vars_data.columns, 1):     print(f\"  {i:2d}. {col}\")  print(f\"\\nDataFrame shape: {all_vars_data.shape[0]} rows \u00d7 {all_vars_data.shape[1]} columns\") <pre>\ud83d\udca1 TIP 1: Getting all available climate variables\n==================================================\nAvailable columns when variables=None:\n   1. station\n   2. daily_rain\n   3. daily_rain_source\n   4. max_temp\n   5. max_temp_source\n   6. min_temp\n   7. min_temp_source\n   8. evap_pan\n   9. evap_pan_source\n  10. radiation\n  11. radiation_source\n  12. vp\n  13. vp_source\n  14. date\n  15. metadata\n\nDataFrame shape: 5 rows \u00d7 15 columns\n</pre> In\u00a0[15]: Copied! <pre># Tip 2: Working with different time periods\nprint(\"\\n\ud83d\udca1 TIP 2: Working with different time periods\")\nprint(\"=\" * 50)\n\n# Get data for different months to compare\nmonths_data = {}\nmonths = [(\"January\", \"20230101\", \"20230131\"), (\"July\", \"20230701\", \"20230731\")]\n\nfor month_name, start, end in months:\n    try:\n        month_data = api.get_patched_point(\n            station_code=selected_station,\n            start_date=start,\n            end_date=end,\n            variables=[\"max_temp\", \"min_temp\", \"rainfall\"],\n        )\n        months_data[month_name] = month_data\n        print(f\"{month_name} 2023: {len(month_data)} days of data retrieved\")\n    except Exception as e:\n        print(f\"Error getting {month_name} data: {e}\")\n\n# Compare the months\nif len(months_data) == 2:\n    jan_data = months_data[\"January\"]\n    jul_data = months_data[\"July\"]\n\n    jan_max_col = (\n        find_columns(jan_data, [\"max\", \"T_max\"])[0]\n        if find_columns(jan_data, [\"max\", \"T_max\"])\n        else None\n    )\n    jul_max_col = (\n        find_columns(jul_data, [\"max\", \"T_max\"])[0]\n        if find_columns(jul_data, [\"max\", \"T_max\"])\n        else None\n    )\n\n    if jan_max_col and jul_max_col:\n        print(f\"\\nSeasonal comparison:\")\n        print(f\"  January average max temp: {jan_data[jan_max_col].mean():.1f}\u00b0C\")\n        print(f\"  July average max temp: {jul_data[jul_max_col].mean():.1f}\u00b0C\")\n        print(\n            f\"  Seasonal difference: {jan_data[jan_max_col].mean() - jul_data[jul_max_col].mean():.1f}\u00b0C\"\n        )\n</pre> # Tip 2: Working with different time periods print(\"\\n\ud83d\udca1 TIP 2: Working with different time periods\") print(\"=\" * 50)  # Get data for different months to compare months_data = {} months = [(\"January\", \"20230101\", \"20230131\"), (\"July\", \"20230701\", \"20230731\")]  for month_name, start, end in months:     try:         month_data = api.get_patched_point(             station_code=selected_station,             start_date=start,             end_date=end,             variables=[\"max_temp\", \"min_temp\", \"rainfall\"],         )         months_data[month_name] = month_data         print(f\"{month_name} 2023: {len(month_data)} days of data retrieved\")     except Exception as e:         print(f\"Error getting {month_name} data: {e}\")  # Compare the months if len(months_data) == 2:     jan_data = months_data[\"January\"]     jul_data = months_data[\"July\"]      jan_max_col = (         find_columns(jan_data, [\"max\", \"T_max\"])[0]         if find_columns(jan_data, [\"max\", \"T_max\"])         else None     )     jul_max_col = (         find_columns(jul_data, [\"max\", \"T_max\"])[0]         if find_columns(jul_data, [\"max\", \"T_max\"])         else None     )      if jan_max_col and jul_max_col:         print(f\"\\nSeasonal comparison:\")         print(f\"  January average max temp: {jan_data[jan_max_col].mean():.1f}\u00b0C\")         print(f\"  July average max temp: {jul_data[jul_max_col].mean():.1f}\u00b0C\")         print(             f\"  Seasonal difference: {jan_data[jan_max_col].mean() - jul_data[jul_max_col].mean():.1f}\u00b0C\"         ) <pre>\n\ud83d\udca1 TIP 2: Working with different time periods\n==================================================\nError getting January data: Unknown variables: ['rainfall']. Valid names: cloud_fraction, daily_rain, et_morton_actual, et_morton_potential, et_morton_wet, et_short_crop, et_tall_crop, evap_comb, evap_morton_lake, evap_pan, evap_syn, max_temp, min_temp, monthly_rain, mslp, radiation, rh_tmax, rh_tmin, vp, vp_deficit, weather_symbol, wind_speed, wind_speed_max\nError getting July data: Unknown variables: ['rainfall']. Valid names: cloud_fraction, daily_rain, et_morton_actual, et_morton_potential, et_morton_wet, et_short_crop, et_tall_crop, evap_comb, evap_morton_lake, evap_pan, evap_syn, max_temp, min_temp, monthly_rain, mslp, radiation, rh_tmax, rh_tmin, vp, vp_deficit, weather_symbol, wind_speed, wind_speed_max\n</pre> In\u00a0[16]: Copied! <pre># Tip 3: Error handling and data validation\nprint(\"\\n\ud83d\udca1 TIP 3: Error handling and data validation\")\nprint(\"=\" * 50)\n\n\ndef safe_get_patched_point(api, station_code, start_date, end_date, variables=None):\n    \"\"\"\n    Safely get PatchedPoint station data with error handling and validation.\n    \"\"\"\n    try:\n        data = api.get_patched_point(\n            station_code=station_code, start_date=start_date, end_date=end_date, variables=variables\n        )\n\n        # Validate the data\n        if data.empty:\n            print(f\"\u26a0\ufe0f Warning: No data returned for station {station_code}\")\n            return None\n\n        # Check for missing values\n        missing_data = safe_data.drop(columns=\"metadata\").isnull().sum()\n        if missing_data.any():\n            print(f\"\ud83d\udcca Data quality report for station {station_code}:\")\n            for col, missing_count in missing_data.items():\n                if missing_count &gt; 0:\n                    percentage = (missing_count / len(data)) * 100\n                    print(f\"   {col}: {missing_count} missing values ({percentage:.1f}%)\")\n        else:\n            print(f\"\u2705 Data quality: No missing values found\")\n\n        return data\n\n    except Exception as e:\n        print(f\"\u274c Error getting data for station {station_code}: {e}\")\n        return None\n\n\n# Test the safe function\nsafe_data = safe_get_patched_point(\n    api, selected_station, \"20230101\", \"20230131\", [\"rainfall\", \"max_temp\"]\n)\n\nif safe_data is not None:\n    print(f\"Successfully retrieved {len(safe_data)} days of data\")\n</pre> # Tip 3: Error handling and data validation print(\"\\n\ud83d\udca1 TIP 3: Error handling and data validation\") print(\"=\" * 50)   def safe_get_patched_point(api, station_code, start_date, end_date, variables=None):     \"\"\"     Safely get PatchedPoint station data with error handling and validation.     \"\"\"     try:         data = api.get_patched_point(             station_code=station_code, start_date=start_date, end_date=end_date, variables=variables         )          # Validate the data         if data.empty:             print(f\"\u26a0\ufe0f Warning: No data returned for station {station_code}\")             return None          # Check for missing values         missing_data = safe_data.drop(columns=\"metadata\").isnull().sum()         if missing_data.any():             print(f\"\ud83d\udcca Data quality report for station {station_code}:\")             for col, missing_count in missing_data.items():                 if missing_count &gt; 0:                     percentage = (missing_count / len(data)) * 100                     print(f\"   {col}: {missing_count} missing values ({percentage:.1f}%)\")         else:             print(f\"\u2705 Data quality: No missing values found\")          return data      except Exception as e:         print(f\"\u274c Error getting data for station {station_code}: {e}\")         return None   # Test the safe function safe_data = safe_get_patched_point(     api, selected_station, \"20230101\", \"20230131\", [\"rainfall\", \"max_temp\"] )  if safe_data is not None:     print(f\"Successfully retrieved {len(safe_data)} days of data\") <pre>\n\ud83d\udca1 TIP 3: Error handling and data validation\n==================================================\n\u274c Error getting data for station 30043: Unknown variables: ['rainfall']. Valid names: cloud_fraction, daily_rain, et_morton_actual, et_morton_potential, et_morton_wet, et_short_crop, et_tall_crop, evap_comb, evap_morton_lake, evap_pan, evap_syn, max_temp, min_temp, monthly_rain, mslp, radiation, rh_tmax, rh_tmin, vp, vp_deficit, weather_symbol, wind_speed, wind_speed_max\n</pre>"},{"location":"notebooks/silo_api_examples/#silo-api-simple-interface-examples","title":"SILO API Simple Interface Examples\u00b6","text":"<p>This notebook demonstrates the simple, high-level interface methods in the SILO API client. These methods provide an easy way to access Australian climate data without needing to work with complex Pydantic models.</p>"},{"location":"notebooks/silo_api_examples/#available-simple-methods","title":"Available Simple Methods\u00b6","text":"<ul> <li><code>get_patched_point()</code> - Get PatchedPoint data (weather station data with infilled gaps)</li> <li><code>get_data_drill()</code> - Get DataDrill data (interpolated gridded data for any coordinates)</li> <li><code>search_stations()</code> - Search for weather stations by name or state</li> <li><code>get_recent_data()</code> - Quick access to recent data (last N days)</li> </ul> <p>Dataset Terminology:</p> <ul> <li>PatchedPoint: Weather station observational data with missing values interpolated from nearby stations</li> <li>DataDrill: Gridded data at 0.05\u00b0 \u00d7 0.05\u00b0 resolution (~5km) interpolated across Australia</li> </ul>"},{"location":"notebooks/silo_api_examples/#setup","title":"Setup\u00b6","text":"<p>First, let's import the required libraries and set up our API client.</p>"},{"location":"notebooks/silo_api_examples/#1-searching-for-weather-stations","title":"1. Searching for Weather Stations\u00b6","text":"<p>Let's start by finding weather stations. The <code>search_stations()</code> method makes it easy to find stations by name or state.</p>"},{"location":"notebooks/silo_api_examples/#2-getting-weather-station-data-patchedpoint","title":"2. Getting Weather Station Data (PatchedPoint)\u00b6","text":"<p>Now let's get some historical weather station data for our selected station using the <code>get_patched_point()</code> method.</p>"},{"location":"notebooks/silo_api_examples/#3-visualizing-station-data","title":"3. Visualizing Station Data\u00b6","text":"<p>Let's create some plots to visualize the weather data we retrieved.</p>"},{"location":"notebooks/silo_api_examples/#4-getting-datadrill-data-for-any-coordinates","title":"4. Getting DataDrill Data for Any Coordinates\u00b6","text":"<p>The <code>get_data_drill()</code> method allows you to get interpolated climate data for any latitude/longitude coordinates, even where there's no weather station. This uses SILO's DataDrill dataset.</p>"},{"location":"notebooks/silo_api_examples/#5-getting-recent-data","title":"5. Getting Recent Data\u00b6","text":"<p>The <code>get_recent_data()</code> method provides a quick way to get recent weather data for the last N days.</p>"},{"location":"notebooks/silo_api_examples/#6-data-processing-and-analysis","title":"6. Data Processing and Analysis\u00b6","text":"<p>Let's perform some basic analysis on our data to show how easy it is to work with the DataFrames returned by the API.</p>"},{"location":"notebooks/silo_api_examples/#7-advanced-usage-tips","title":"7. Advanced Usage Tips\u00b6","text":"<p>Here are some advanced tips for using the SILO API simple interface methods effectively.</p>"}]}