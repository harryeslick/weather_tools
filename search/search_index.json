{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Welcome to weather tools","text":"<p>A Python package and command-line interface for working with weather data operations.</p> <p>This package provides both a Python API and a powerful CLI for loading and using SILO weather data from local netCDF files.</p>"},{"location":"#features","title":"Features","text":"<ul> <li>Dual Mode Access: Query SILO API directly or work with local NetCDF files</li> <li>Command-Line Interface: Simple commands for both online API and offline data</li> <li>Python API: Programmatic access to SILO data using xarray</li> <li>Multiple Data Sources: PatchedPoint (station) and DataDrill (gridded) datasets</li> <li>Flexible Output: Export data to CSV, JSON, APSIM, or standard formats</li> <li>Station Search: Find weather stations by name or proximity</li> <li>Easy Installation: Use with <code>uvx</code> for zero-installation usage</li> </ul>"},{"location":"#quick-start","title":"Quick Start","text":""},{"location":"#cli-usage","title":"CLI Usage","text":"<p>SILO API (Online - requires API key):</p> <pre><code># Query station data\nuvx git+https://github.com/harryeslick/weather_tools.git silo patched-point \\\n  --station 30043 --start-date 2023-01-01 --end-date 2023-01-31 \\\n  --output station_data.csv\n\n# Query gridded data  \nuvx git+https://github.com/harryeslick/weather_tools.git silo data-drill \\\n  --lat -27.5 --lon 153.0 --start-date 2023-01-01 --end-date 2023-01-31 \\\n  --output brisbane_2023.csv\n</code></pre> <p>Local NetCDF files (Offline):</p> <pre><code># Extract weather data for Brisbane from local files\nuvx git+https://github.com/harryeslick/weather_tools.git local extract \\\n  --lat -27.5 --lon 153.0 \\\n  --start-date 2020-01-01 --end-date 2020-12-31 \\\n  --output brisbane_2020.csv\n</code></pre>"},{"location":"#python-api","title":"Python API","text":"<pre><code>from weather_tools import read_silo_xarray\n\n# Load daily weather variables\nds = read_silo_xarray(variables=\"daily\")\n\n# Extract data for a specific location and date range\ndf = ds.sel(lat=-27.5, lon=153.0, method=\"nearest\").sel(\n    time=slice(\"2020-01-01\", \"2020-12-31\")\n).to_dataframe().reset_index()\n</code></pre>"},{"location":"#documentation-sections","title":"Documentation Sections","text":"<ul> <li>CLI Reference: Complete command-line interface documentation</li> <li>API Reference: Python API documentation  </li> <li>Examples: Jupyter notebook examples</li> </ul>"},{"location":"#data-requirements","title":"Data Requirements","text":"<p>To use this package you will need to download the netCDF files which you require from SILO:</p> <ul> <li>Data Source: SILO Gridded Data</li> <li>AWS S3 Index: Complete file list</li> </ul>"},{"location":"CHANGELOG/","title":"Changelog","text":"<p>All notable changes to this project will be documented in this file.</p> <p>The format is based on Keep a Changelog,</p>"},{"location":"CHANGELOG/#002-2025-05-05","title":"[0.0.2] - 2025-05-05","text":""},{"location":"CHANGELOG/#added","title":"Added","text":"<ul> <li>Read silo data from local netCDF files using Xarray</li> </ul>"},{"location":"cli/","title":"Command Line Interface (CLI)","text":"<p>The weather-tools package provides a powerful command-line interface for working with SILO weather data. You can query data directly from the SILO API or extract data from local netCDF files.</p>"},{"location":"cli/#installation","title":"Installation","text":""},{"location":"cli/#using-uv-recommended","title":"Using uv (Recommended)","text":"<pre><code># Install with uv\nuv pip install weather-tools\n\n# Or run directly with uvx (no installation)\nuvx weather-tools --help\n</code></pre>"},{"location":"cli/#using-pip","title":"Using pip","text":"<pre><code># Install from local directory\npip install -e .\n\n# Or install from GitHub\npip install git+https://github.com/harryeslick/weather_tools.git\n</code></pre> <p>After installation, the <code>weather-tools</code> command will be available.</p>"},{"location":"cli/#commands-overview","title":"Commands Overview","text":"<p>The CLI provides two command groups:</p>"},{"location":"cli/#silo-api-commands-online","title":"SILO API Commands (Online)","text":"<ul> <li><code>silo patched-point</code> - Query SILO PatchedPoint dataset (station-based data)</li> <li><code>silo data-drill</code> - Query SILO DataDrill dataset (gridded data)</li> <li><code>silo search</code> - Search for SILO stations by name or find nearby stations</li> </ul>"},{"location":"cli/#local-netcdf-commands-offline","title":"Local NetCDF Commands (Offline)","text":"<ul> <li><code>local info</code> - Display information about available local SILO data</li> <li><code>local extract</code> - Extract weather data from local netCDF files</li> </ul>"},{"location":"cli/#quick-start-examples","title":"Quick Start Examples","text":""},{"location":"cli/#query-silo-api-no-downloads-required","title":"Query SILO API (No Downloads Required)","text":"<pre><code># Set your API key\nexport SILO_API_KEY=\"your_api_key_here\"\n\n# Query station data (PatchedPoint)\nweather-tools silo patched-point --station 30043 \\\n  --start-date 2023-01-01 --end-date 2023-01-31 --output data.csv\n\n# Query gridded data (DataDrill)\nweather-tools silo data-drill --lat -27.5 --lon 151.0 \\\n  --start-date 2023-01-01 --end-date 2023-01-31 --output gridded_data.csv\n\n# Search for stations\nweather-tools silo search --name \"Brisbane\"\nweather-tools silo search --station 30043 --radius 50\n</code></pre>"},{"location":"cli/#use-local-netcdf-files","title":"Use Local NetCDF Files","text":"<pre><code># Display available local SILO data\nweather-tools local info\n\n# Extract data from local files\nweather-tools local extract --lat -27.5 --lon 153.0 \\\n  --start-date 2020-01-01 --end-date 2020-12-31 \\\n  --output brisbane_2020.csv\n</code></pre>"},{"location":"cli/#command-reference","title":"Command Reference","text":""},{"location":"cli/#global-options","title":"Global Options","text":"<pre><code>Usage: weather-tools [OPTIONS] COMMAND [ARGS]...\n\nCommands:\n  silo      Query SILO API directly (requires API key)\n  info      Display information about available local SILO data\n  extract   Extract weather data from local netCDF files\n\nOptions:\n  --install-completion    Install completion for the current shell\n  --show-completion      Show completion for the current shell\n  --help                 Show this message and exit\n</code></pre>"},{"location":"cli/#silo-api-commands","title":"SILO API Commands","text":"<p>These commands query the SILO API directly - no local files required!</p>"},{"location":"cli/#silo-patched-point-command","title":"<code>silo patched-point</code> Command","text":"<p>Query the SILO PatchedPoint dataset for station-based weather data.</p> <pre><code>weather-tools silo patched-point [OPTIONS]\n</code></pre>"},{"location":"cli/#required-options","title":"Required Options","text":"Option Type Description <code>--station</code> TEXT Station code (e.g., 30043) <code>--start-date</code> TEXT Start date in YYYYMMDD format <code>--end-date</code> TEXT End date in YYYYMMDD format"},{"location":"cli/#optional-parameters","title":"Optional Parameters","text":"Option Type Description Default <code>--format</code> TEXT Output format: 'csv', 'json', 'apsim', 'standard' Auto-detected from output filename <code>--variables</code> TEXT Weather variables (can be used multiple times) All available <code>--output</code> PATH Output filename Required <code>--api-key</code> TEXT SILO API key (or set SILO_API_KEY env var)"},{"location":"cli/#examples","title":"Examples","text":"<pre><code># Basic station data query\nweather-tools silo patched-point --station 30043 \\\n    --start-date 20230101 --end-date 20230131 \\\n    --output data.csv\n\n# Query with specific variables\nweather-tools silo patched-point --station 30043 \\\n    --start-date 20230101 --end-date 20230131 \\\n    --variables R --variables X --variables N \\\n    --output station_data.csv\n\n# Auto-detect format from extension\nweather-tools silo patched-point --station 30043 \\\n    --start-date 20230101 --end-date 20230131 \\\n    --output data.json  # Automatically uses JSON format\n</code></pre>"},{"location":"cli/#silo-data-drill-command","title":"<code>silo data-drill</code> Command","text":"<p>Query the SILO DataDrill dataset for gridded weather data.</p> <pre><code>weather-tools silo data-drill [OPTIONS]\n</code></pre>"},{"location":"cli/#required-options_1","title":"Required Options","text":"Option Type Description <code>--lat</code> FLOAT Latitude coordinate <code>--lon</code> FLOAT Longitude coordinate <code>--start-date</code> TEXT Start date in YYYYMMDD format <code>--end-date</code> TEXT End date in YYYYMMDD format"},{"location":"cli/#optional-parameters_1","title":"Optional Parameters","text":"Option Type Description Default <code>--format</code> TEXT Output format: 'csv', 'json', 'apsim', 'standard' Auto-detected from output filename <code>--variables</code> TEXT Weather variables (can be used multiple times) All available <code>--output</code> PATH Output filename Required <code>--api-key</code> TEXT SILO API key (or set SILO_API_KEY env var)"},{"location":"cli/#examples_1","title":"Examples","text":"<pre><code># Query gridded data for Brisbane\nweather-tools silo data-drill --lat -27.5 --lon 153.0 \\\n    --start-date 20230101 --end-date 20230131 \\\n    --output brisbane_weather.csv\n\n# Query with APSIM format\nweather-tools silo data-drill --lat -27.5 --lon 153.0 \\\n    --start-date 20230101 --end-date 20230131 \\\n    --output weather.apsim  # Auto-detects APSIM format\n</code></pre>"},{"location":"cli/#silo-search-command","title":"<code>silo search</code> Command","text":"<p>Search for SILO weather stations by name or find stations near a location.</p> <pre><code>weather-tools silo search [OPTIONS]\n</code></pre>"},{"location":"cli/#search-options-choose-one","title":"Search Options (choose one)","text":"Option Type Description <code>--name</code> TEXT Search stations by name <code>--station</code> TEXT Find stations near this station code <code>--lat</code> FLOAT Latitude for proximity search (requires --lon) <code>--lon</code> FLOAT Longitude for proximity search (requires --lat)"},{"location":"cli/#optional-parameters_2","title":"Optional Parameters","text":"Option Type Description Default <code>--radius</code> FLOAT Search radius in km <code>50.0</code> <code>--api-key</code> TEXT SILO API key (or set SILO_API_KEY env var) <code>--output</code> TEXT Output filename (optional)"},{"location":"cli/#examples_2","title":"Examples","text":"<pre><code># Search by station name\nweather-tools silo search --name \"Brisbane\"\n\n# Find stations near a specific station\nweather-tools silo search --station 30043 --radius 50\n\n# Find stations near coordinates\nweather-tools silo search --lat -27.5 --lon 153.0 --radius 100\n\n# Save results to file\nweather-tools silo search --name \"Sydney\" --output sydney_stations.txt\n</code></pre>"},{"location":"cli/#setting-your-api-key","title":"Setting Your API Key","text":"<p>For security, it's best to set your API key as an environment variable:</p> <pre><code># In your terminal or .bashrc/.zshrc\nexport SILO_API_KEY=\"your_api_key_here\"\n\n# Then you can use commands without --api-key option\nweather-tools silo patched-point --station 30043 ...\n</code></pre> <p>Or create a <code>.env</code> file in your project:</p> <pre><code># .env file\nSILO_API_KEY=your_api_key_here\n</code></pre>"},{"location":"cli/#local-netcdf-commands","title":"Local NetCDF Commands","text":"<p>These commands work with downloaded SILO gridded data files.</p>"},{"location":"cli/#local-info-command","title":"<code>local info</code> Command","text":"<p>Display information about available SILO data directories and files.</p> <pre><code>weather-tools local info [OPTIONS]\n</code></pre>"},{"location":"cli/#options","title":"Options","text":"Option Type Description Default <code>--silo-dir</code> PATH Path to SILO data directory <code>~/Developer/DATA/silo_grids</code> <code>--help</code> Show help message and exit"},{"location":"cli/#example-usage","title":"Example Usage","text":"<pre><code># Show info for default SILO directory\nweather-tools local info\n\n# Show info for custom SILO directory\nweather-tools local info --silo-dir /path/to/my/silo/data\n</code></pre>"},{"location":"cli/#sample-output","title":"Sample Output","text":"<pre><code>SILO data directory: /Users/user/Developer/DATA/silo_grids\n\n\ud83d\udcc1 Available variable directories:\n  \ud83d\udcc2 daily_rain: 25 files\n    \ud83d\udcc5 Years: 2000-2024\n  \ud83d\udcc2 evap_syn: 25 files\n    \ud83d\udcc5 Years: 2000-2024\n  \ud83d\udcc2 max_temp: 25 files\n    \ud83d\udcc5 Years: 2000-2024\n  \ud83d\udcc2 min_temp: 25 files\n    \ud83d\udcc5 Years: 2000-2024\n  \ud83d\udcc2 monthly_rain: 136 files\n    \ud83d\udcc5 Years: 1889-2024\n</code></pre>"},{"location":"cli/#local-extract-command","title":"<code>local extract</code> Command","text":"<p>Extract weather data for a specific location and date range, saving results to CSV.</p> <pre><code>weather-tools local extract [OPTIONS]\n</code></pre>"},{"location":"cli/#required-options_2","title":"Required Options","text":"Option Type Description <code>--lat</code> FLOAT Latitude coordinate (required) <code>--lon</code> FLOAT Longitude coordinate (required) <code>--start-date</code> TEXT Start date in YYYY-MM-DD format (required) <code>--end-date</code> TEXT End date in YYYY-MM-DD format (required)"},{"location":"cli/#optional-options","title":"Optional Options","text":"Option Type Description Default <code>--output</code> TEXT Output CSV filename <code>weather_data.csv</code> <code>--variables</code> TEXT Weather variables to extract (see below) <code>daily</code> <code>--silo-dir</code> PATH Path to SILO data directory <code>~/Developer/DATA/silo_grids</code> <code>--tolerance</code> FLOAT Maximum distance (in degrees) for nearest neighbor selection <code>0.1</code> <code>--keep-location</code> BOOLEAN Keep location columns (crs, lat, lon) in output CSV <code>False</code> (columns are dropped by default) <code>--help</code> Show help message and exit"},{"location":"cli/#variable-options","title":"Variable Options","text":"<p>The <code>--variables</code> option accepts the following values:</p> Value Variables Included Description <code>daily</code> max_temp, min_temp, daily_rain, evap_syn Daily weather variables (default) <code>monthly</code> monthly_rain Monthly rainfall data Individual variables Any combination of: <code>max_temp</code>, <code>min_temp</code>, <code>daily_rain</code>, <code>evap_syn</code>, <code>monthly_rain</code> Specify individual variables"},{"location":"cli/#example-usage_1","title":"Example Usage","text":""},{"location":"cli/#basic-extraction","title":"Basic Extraction","text":"<pre><code># Extract daily variables for Brisbane in 2020\nweather-tools local extract --lat -27.5 --lon 153.0 --start-date 2020-01-01 --end-date 2020-12-31\n</code></pre>"},{"location":"cli/#monthly-data","title":"Monthly Data","text":"<pre><code># Extract monthly rainfall data\nweather-tools local extract \\\n  --lat -27.5 --lon 153.0 \\\n  --start-date 2020-01-01 --end-date 2020-12-31 \\\n  --variables monthly \\\n  --output monthly_rainfall.csv\n</code></pre>"},{"location":"cli/#specific-variables","title":"Specific Variables","text":"<pre><code># Extract only temperature data\nweather-tools local extract \\\n  --lat -27.5 --lon 153.0 \\\n  --start-date 2020-01-01 --end-date 2020-12-31 \\\n  --variables max_temp --variables min_temp \\\n  --output temperatures.csv\n</code></pre>"},{"location":"cli/#custom-directory-and-output","title":"Custom Directory and Output","text":"<pre><code># Use custom SILO directory and output file\nweather-tools local extract \\\n  --lat -27.5 --lon 153.0 \\\n  --start-date 2020-01-01 --end-date 2020-12-31 \\\n  --silo-dir /path/to/my/silo/data \\\n  --output custom_weather_data.csv\n</code></pre>"},{"location":"cli/#using-custom-tolerance","title":"Using Custom Tolerance","text":"<pre><code># Use stricter tolerance (0.01 degrees \u2248 1.1 km)\nweather-tools local extract \\\n  --lat -27.5 --lon 153.0 \\\n  --start-date 2020-01-01 --end-date 2020-12-31 \\\n  --tolerance 0.01\n\n# Use more permissive tolerance (0.5 degrees \u2248 55 km)\nweather-tools local extract \\\n  --lat -27.5 --lon 153.0 \\\n  --start-date 2020-01-01 --end-date 2020-12-31 \\\n  --tolerance 0.5\n</code></pre>"},{"location":"cli/#keeping-location-columns","title":"Keeping Location Columns","text":"<p>By default, location columns (crs, lat, lon) are dropped from the output CSV. Use <code>--keep-location</code> to retain them:</p> <pre><code># Keep location columns in output\nweather-tools local extract \\\n  --lat -27.5 --lon 153.0 \\\n  --start-date 2020-01-01 --end-date 2020-12-31 \\\n  --keep-location \\\n  --output data_with_coords.csv\n</code></pre>"},{"location":"cli/#sample-output_1","title":"Sample Output","text":"<pre><code>Loading SILO data from: /Users/user/Developer/DATA/silo_grids\nVariables: daily\nLoading SILO dataset...  [####################################]  100%\nExtracting data for location: lat=-27.5, lon=153.0\nDate range: 2020-01-01 to 2020-12-31\n\u2705 Data extracted successfully!\n\ud83d\udcca Shape: 366 rows, 5 columns\n\ud83d\udcbe Saved to: /path/to/weather_data.csv\n\n\ud83d\udccb Preview (first 5 rows):\n        time  max_temp  min_temp  daily_rain  evap_syn\n0 2020-01-01      30.5      21.7         0.1       7.6\n1 2020-01-02      31.0      21.0         0.0       7.2\n2 2020-01-03      31.1      20.2         0.0       7.7\n3 2020-01-04      31.7      20.4         0.0       8.1\n4 2020-01-05      32.1      19.8         0.0       8.1\n</code></pre>"},{"location":"cli/#output-format","title":"Output Format","text":"<p>The CLI generates CSV files with the following structure:</p> Column Description <code>time</code> Date/time index (YYYY-MM-DD format) <code>lat</code> Latitude (nearest grid point to your coordinates) - dropped by default <code>lon</code> Longitude (nearest grid point to your coordinates) - dropped by default <code>crs</code> Coordinate reference system information - dropped by default Weather variables Columns for each requested variable (e.g., <code>max_temp</code>, <code>min_temp</code>, <code>daily_rain</code>, <code>evap_syn</code>) <p>Location Columns</p> <p>By default, the <code>crs</code>, <code>lat</code>, and <code>lon</code> columns are dropped from the output CSV to reduce file size. Use the <code>--keep-location</code> flag if you need these columns in your output.</p>"},{"location":"cli/#units","title":"Units","text":"Variable Units Description <code>max_temp</code> \u00b0C Maximum temperature <code>min_temp</code> \u00b0C Minimum temperature <code>daily_rain</code> mm Daily rainfall <code>evap_syn</code> mm Synthetic evaporation <code>monthly_rain</code> mm Monthly rainfall"},{"location":"cli/#data-requirements","title":"Data Requirements","text":""},{"location":"cli/#expected-directory-structure","title":"Expected Directory Structure","text":"<p>The CLI expects SILO data to be organized as follows:</p> <pre><code>~/Developer/DATA/silo_grids/\n\u251c\u2500\u2500 daily_rain/\n\u2502   \u251c\u2500\u2500 2020.daily_rain.nc\n\u2502   \u251c\u2500\u2500 2021.daily_rain.nc\n\u2502   \u2514\u2500\u2500 ...\n\u251c\u2500\u2500 evap_syn/\n\u2502   \u251c\u2500\u2500 2020.evap_syn.nc\n\u2502   \u251c\u2500\u2500 2021.evap_syn.nc\n\u2502   \u2514\u2500\u2500 ...\n\u251c\u2500\u2500 max_temp/\n\u2502   \u251c\u2500\u2500 2020.max_temp.nc\n\u2502   \u251c\u2500\u2500 2021.max_temp.nc\n\u2502   \u2514\u2500\u2500 ...\n\u251c\u2500\u2500 min_temp/\n\u2502   \u251c\u2500\u2500 2020.min_temp.nc\n\u2502   \u251c\u2500\u2500 2021.min_temp.nc\n\u2502   \u2514\u2500\u2500 ...\n\u2514\u2500\u2500 monthly_rain/\n    \u251c\u2500\u2500 2020.monthly_rain.nc\n    \u251c\u2500\u2500 2021.monthly_rain.nc\n    \u2514\u2500\u2500 ...\n</code></pre>"},{"location":"cli/#downloading-silo-data","title":"Downloading SILO Data","text":"<p>To use this package, you need to download the netCDF files from SILO:</p> <ul> <li>Data Source: SILO Gridded Data</li> <li>AWS S3 Index: Complete file list</li> </ul>"},{"location":"cli/#tips-and-best-practices","title":"Tips and Best Practices","text":""},{"location":"cli/#performance","title":"Performance","text":"<ul> <li>Start small: Test with short date ranges first (e.g., 1 month) before extracting large datasets</li> <li>Use specific variables: Only extract the variables you need to reduce processing time</li> <li>Monitor disk space: Large date ranges can generate substantial CSV files</li> </ul>"},{"location":"cli/#date-formats","title":"Date Formats","text":"<ul> <li>Always use YYYY-MM-DD format for dates</li> <li>Ensure your date range falls within the available data years</li> <li>Use the <code>info</code> command to check available years for each variable</li> </ul>"},{"location":"cli/#coordinate-selection","title":"Coordinate Selection","text":"<ul> <li>The CLI automatically selects the nearest grid point to your coordinates</li> <li>SILO data has approximately 5km resolution</li> <li>Coordinates are returned in the output to show the actual grid point used</li> </ul>"},{"location":"cli/#tolerance-parameter","title":"Tolerance Parameter","text":"<p>The <code>--tolerance</code> parameter controls the maximum distance (in degrees) for nearest neighbor selection:</p> <ul> <li>Default value: 0.1 degrees (approximately 11 km)</li> <li>Purpose: Prevents selection of grid points that are too far from your requested coordinates</li> <li>When to adjust:</li> <li>Use smaller values (e.g., 0.01) when you need strict spatial accuracy</li> <li>Use larger values (e.g., 0.5) when working near data boundaries or with sparse grids</li> <li>The selection will fail if no grid point exists within the tolerance distance</li> </ul> <p>Distance reference (at mid-latitudes): - 0.01 degrees \u2248 1.1 km - 0.1 degrees \u2248 11 km (default) - 0.5 degrees \u2248 55 km - 1.0 degrees \u2248 111 km</p> <p>Example scenarios:</p> <pre><code># Strict tolerance for urban planning (must be very close)\nweather-tools local extract --lat -27.5 --lon 153.0 \\\n  --start-date 2020-01-01 --end-date 2020-12-31 \\\n  --tolerance 0.01\n\n# Permissive tolerance for regional analysis\nweather-tools local extract --lat -27.5 --lon 153.0 \\\n  --start-date 2020-01-01 --end-date 2020-12-31 \\\n  --tolerance 0.5\n</code></pre>"},{"location":"cli/#error-handling","title":"Error Handling","text":"<p>The CLI provides informative error messages for common issues:</p> <ul> <li>Invalid date formats</li> <li>Missing SILO data directories</li> <li>Coordinates outside the data extent</li> <li>Network connectivity issues (when using uvx with GitHub)</li> </ul>"},{"location":"cli/#advanced-usage","title":"Advanced Usage","text":""},{"location":"cli/#shell-completion","title":"Shell Completion","text":"<p>Install shell completion for better command-line experience:</p> <pre><code>weather-tools --install-completion\n</code></pre>"},{"location":"cli/#batch-processing","title":"Batch Processing","text":"<p>Use shell scripting for batch processing multiple locations:</p> <pre><code>#!/bin/bash\nlocations=(\n  \"-27.5,153.0,brisbane\"\n  \"-33.9,151.2,sydney\"\n  \"-37.8,144.9,melbourne\"\n)\n\nfor location in \"${locations[@]}\"; do\n  IFS=',' read -r lat lon name &lt;&lt;&lt; \"$location\"\n  weather-tools local extract --lat \"$lat\" --lon \"$lon\" \\\n    --start-date 2020-01-01 --end-date 2020-12-31 \\\n    --output \"${name}_2020.csv\"\ndone\n</code></pre>"},{"location":"cli/#integration-with-python","title":"Integration with Python","text":"<p>Combine CLI output with Python analysis:</p> <pre><code>import pandas as pd\nimport subprocess\n\n# Extract data using CLI\nsubprocess.run([\n    \"weather-tools\", \"extract\",\n    \"--lat\", \"-27.5\", \"--lon\", \"153.0\",\n    \"--start-date\", \"2020-01-01\", \"--end-date\", \"2020-12-31\",\n    \"--output\", \"analysis_data.csv\"\n])\n\n# Load and analyze with pandas\ndf = pd.read_csv(\"analysis_data.csv\")\ndf['time'] = pd.to_datetime(df['time'])\nprint(df.describe())\n</code></pre>"},{"location":"merge_weather_data/","title":"Merge Weather Data","text":"<p>The <code>merge_weather_data</code> module bridges SILO historical observations and met.no forecasts. It ensures the datasets align, handles overlaps, and produces a combined time series ready for downstream analytics.</p>"},{"location":"merge_weather_data/#primary-workflow","title":"Primary Workflow","text":"<pre><code>from weather_tools.merge_weather_data import merge_historical_and_forecast, get_merge_summary\n\nmerged = merge_historical_and_forecast(\n    silo_data=silo_dataframe,\n    metno_data=metno_dataframe,\n    transition_date=None,           # auto (last SILO date + 1 day)\n    validate=True,\n    fill_missing=True,\n    overlap_strategy=\"prefer_silo\", # or 'prefer_metno' / 'error'\n)\n\nsummary = get_merge_summary(merged)\n</code></pre>"},{"location":"merge_weather_data/#merge_historical_and_forecast","title":"merge_historical_and_forecast(...)","text":"<p>Orchestrates the entire merge process:</p> <ol> <li>Normalises date columns and sorts both inputs.</li> <li>Optionally validates continuity and critical columns.</li> <li>Applies the requested overlap strategy:</li> <li><code>prefer_silo</code> (default): keep SILO records when dates collide.</li> <li><code>prefer_metno</code>: prefer met.no records for overlaps.</li> <li><code>error</code>: raise <code>MergeValidationError</code> if overlap exists.</li> <li>Converts met.no columns (e.g., <code>min_temperature</code>) into SILO-style columns (<code>min_temp</code>) via <code>prepare_metno_for_merge</code>.</li> <li>Adds metadata columns (<code>data_source</code>, <code>is_forecast</code>, <code>forecast_generated_at</code>).</li> <li>Concatenates, aligns columns, and returns a chronological DataFrame.</li> </ol>"},{"location":"merge_weather_data/#important-flags","title":"Important Flags","text":"<ul> <li><code>transition_date</code>: force the hand-over date if you do not want the automatic transition.</li> <li><code>fill_missing</code>: backfill SILO-only variables in the forecast (radiation, vapour pressure, etc.) using <code>fill_missing_silo_variables</code>.</li> </ul>"},{"location":"merge_weather_data/#validation-utilities","title":"Validation Utilities","text":""},{"location":"merge_weather_data/#validate_merge_compatibility","title":"validate_merge_compatibility(...)","text":"<p>Runs checks before merging:</p> <ul> <li>Ensures <code>date</code> columns exist.</li> <li>Detects gaps or overlaps depending on <code>overlap_strategy</code>.</li> <li>Confirms SILO has <code>min_temp</code>, <code>max_temp</code>, <code>daily_rain</code>.</li> <li>Accepts met.no data in either native (<code>min_temperature</code>) or SILO (<code>min_temp</code>) naming schemes.</li> </ul> <p>Returns <code>(is_valid: bool, issues: List[str])</code>. The merge function raises <code>MergeValidationError</code> when validation fails and <code>validate=True</code>.</p>"},{"location":"merge_weather_data/#validate_date_continuity","title":"validate_date_continuity(...)","text":"<p>Lower-level helper that inspects two DataFrames for gaps or overlaps relative to a maximum allowed gap (default: 1 day).</p>"},{"location":"merge_weather_data/#preparing-metno-data","title":"Preparing met.no Data","text":""},{"location":"merge_weather_data/#prepare_metno_for_merge","title":"prepare_metno_for_merge(...)","text":"<pre><code>from weather_tools.merge_weather_data import prepare_metno_for_merge\n\nprepared = prepare_metno_for_merge(metno_daily_df, silo_history_df, fill_missing=True)\n</code></pre> <ul> <li>Renames met.no columns to their SILO equivalents using <code>convert_metno_to_silo_columns</code>.</li> <li>Adds SILO-specific date columns (<code>day</code>, <code>year</code>) when missing.</li> <li>Optionally fills SILO-only variables by calling <code>fill_missing_silo_variables</code>.</li> </ul>"},{"location":"merge_weather_data/#fill_missing_silo_variables","title":"fill_missing_silo_variables(...)","text":"<p>Supports three strategies when met.no data lacks SILO-only columns:</p> Strategy Behaviour <code>\"default\"</code> Inserts conservative defaults (e.g., <code>radiation=20.0</code>, <code>evap_syn=5.0</code>). <code>\"last_known\"</code> Reuses the last available SILO value when possible. <code>\"median\"</code> Fills using the median from the SILO history. <p>This allows downstream systems expecting complete SILO schema to continue operating.</p>"},{"location":"merge_weather_data/#summaries-and-diagnostics","title":"Summaries and Diagnostics","text":""},{"location":"merge_weather_data/#get_merge_summary","title":"get_merge_summary(...)","text":"<p>Produces quick stats about the merged dataset:</p> <ul> <li>Total record count and per-source counts.</li> <li>Date ranges for SILO and met.no segments.</li> <li>Computed transition date.</li> </ul> <p>Useful for sanity checks or logging after a merge.</p>"},{"location":"merge_weather_data/#exceptions","title":"Exceptions","text":"<ul> <li><code>MergeValidationError</code> \u2014 raised when a merge cannot proceed safely.</li> <li><code>DateGapError</code> \u2014 specialised for gaps between SILO and met.no periods.</li> <li><code>ColumnMismatchError</code> \u2014 raised when required columns are missing.</li> </ul> <p>Handle exceptions to alert users or prompt data remediation.</p>"},{"location":"merge_weather_data/#typical-pipeline","title":"Typical Pipeline","text":"<ol> <li>Fetch SILO history using <code>SiloAPI.get_gridded_data</code> or local NetCDF extracts.</li> <li>Retrieve met.no forecasts with <code>MetNoAPI.to_dataframe(aggregate_to_daily=True)</code>.</li> <li>Call <code>merge_historical_and_forecast</code> and inspect <code>get_merge_summary</code>.</li> <li>Persist or visualise as required.</li> </ol> <p>Check the Forecast example notebook for a live demonstration of this workflow.</p>"},{"location":"metno_api/","title":"Met.no API Client","text":"<p>The <code>metno_api</code> module provides a typed Python client for the met.no locationforecast v2.0 API, making it easy to fetch short-range weather forecasts for any global coordinate. It integrates tightly with the rest of <code>weather_tools</code>, returning Pydantic models and ready-to-use pandas DataFrames.</p>"},{"location":"metno_api/#highlights","title":"Highlights","text":"<ul> <li>\u2705 Pydantic-powered queries via <code>MetNoQuery</code> for validated coordinates and formats.</li> <li>\u2705 Automatic retries, caching, and backoff to keep requests resilient and efficient.</li> <li>\u2705 Convenience helpers to aggregate hourly forecasts into daily summaries.</li> <li>\u2705 DataFrame conversion for both hourly and daily views.</li> <li>\u2705 Seamless hand-off to <code>merge_weather_data.merge_historical_and_forecast</code> for blending with SILO archives.</li> </ul>"},{"location":"metno_api/#requirements","title":"Requirements","text":"<ul> <li>met.no requires a descriptive <code>User-Agent</code> header containing a contact address. The client generates a sensible default (<code>weather-tools/&lt;version&gt; (Python &lt;major&gt;.&lt;minor&gt;)</code>), but you should provide your own identifier in production.</li> <li>Forecast requests do not require authentication, but met.no enforces rate limits\u2014respect their usage policy and cache responses where possible.</li> </ul>"},{"location":"metno_api/#quick-start","title":"Quick Start","text":"<pre><code>from weather_tools.metno_api import MetNoAPI\nfrom weather_tools.metno_models import MetNoFormat, MetNoQuery\nfrom weather_tools.silo_models import AustralianCoordinates\n\n# Configure the client (always include your contact details!)\napi = MetNoAPI(user_agent=\"my-app/1.0 (contact: you@example.com)\")\n\n# Build a query for a location near Sydney Airport\nquery = MetNoQuery(\n    coordinates=AustralianCoordinates(latitude=-33.94, longitude=151.18),\n    format=MetNoFormat.COMPACT,\n)\n\n# Execute and inspect the response metadata\nresponse = api.query_forecast(query)\nprint(response.get_meta())\n</code></pre>"},{"location":"metno_api/#aggregating-to-daily-data","title":"Aggregating to Daily Data","text":"<p>The API returns hourly forecasts in GeoJSON format. Use <code>MetNoAPI.to_dataframe</code> to convert the payload into either daily summaries or the raw hourly table:</p> <pre><code>daily_df = api.to_dataframe(response, aggregate_to_daily=True)\nhourly_df = api.to_dataframe(response, aggregate_to_daily=False)\n</code></pre> <ul> <li>Daily data mirrors the <code>DailyWeatherSummary</code> model, providing min/max temperature, total precipitation, wind statistics, humidity, pressure, cloud cover, and the dominant weather symbol.</li> <li>Hourly data preserves the original timestamps alongside instantaneous variables and precipitation totals for the next 1/6/12 hours.</li> </ul>"},{"location":"metno_api/#convenience-helper-get_daily_forecast","title":"Convenience Helper: <code>get_daily_forecast</code>","text":"<p>For common use cases you can skip manual query construction:</p> <pre><code>daily = api.get_daily_forecast(latitude=-33.94, longitude=151.18, days=7)\n</code></pre> <p>This method returns a list of <code>DailyWeatherSummary</code> models and automatically truncates the forecast horizon (met.no serves up to 9 days).</p>"},{"location":"metno_api/#configuration-options","title":"Configuration Options","text":"<p>Instantiate <code>MetNoAPI</code> with custom behaviour when needed:</p> <pre><code>api = MetNoAPI(\n    user_agent=\"my-app/1.0 (contact: you@example.com)\",\n    timeout=45,\n    max_retries=4,\n    retry_delay=1.5,\n    enable_cache=True,\n    cache_expiry_hours=2,\n    log_level=\"DEBUG\",\n)\n</code></pre> Parameter Type Default Description <code>user_agent</code> str auto Identifies your application to met.no <code>timeout</code> int 30 HTTP timeout in seconds <code>max_retries</code> int 3 Attempts for transient failures <code>retry_delay</code> float 1.0 Base delay for exponential backoff <code>enable_cache</code> bool True In-memory response cache toggle <code>cache_expiry_hours</code> int 1 Lifetime for cached responses <code>log_level</code> str/int INFO Logging level for diagnostics <p>Use <code>clear_cache()</code> and <code>get_cache_size()</code> to manage cached responses explicitly.</p>"},{"location":"metno_api/#error-handling","title":"Error Handling","text":"<p>The client surfaces clear exceptions:</p> <ul> <li><code>MetNoUserAgentError</code> \u2014 missing/invalid User-Agent (met.no returns HTTP 403).</li> <li><code>MetNoRateLimitError</code> \u2014 too many requests (HTTP 429).</li> <li><code>MetNoAPIError</code> \u2014 other HTTP failures or JSON parsing issues.</li> </ul> <p>Wrap network calls accordingly:</p> <pre><code>try:\n    response = api.query_forecast(query)\nexcept MetNoRateLimitError:\n    logger.warning(\"Slow down\u2014met.no rate limit hit\")\nexcept MetNoUserAgentError as e:\n    raise RuntimeError(\"Update your User-Agent\") from e\n</code></pre>"},{"location":"metno_api/#integration-with-silo-data","title":"Integration with SILO Data","text":"<p>Daily summaries pair naturally with SILO history:</p> <pre><code>from weather_tools.merge_weather_data import merge_historical_and_forecast\n\nmerged = merge_historical_and_forecast(\n    silo_data=silo_history_dataframe,\n    metno_data=daily_df,\n    fill_missing=True,\n    overlap_strategy=\"prefer_silo\",\n)\n</code></pre> <p>See Merge Weather Data for a deeper dive into the blending workflow.</p>"},{"location":"metno_api/#additional-resources","title":"Additional Resources","text":"<ul> <li>Met.no API documentation</li> <li>Met.no Models \u2014 Pydantic types used by the client.</li> <li>Forecast example notebook \u2014 end-to-end usage with SILO integration.</li> </ul>"},{"location":"metno_models/","title":"Met.no Data Models","text":"<p>The <code>metno_models</code> module defines the Pydantic models that underpin the met.no integration. They provide validation, serialization helpers, and consistent data structures for both API requests and responses.</p>"},{"location":"metno_models/#metnoformat","title":"MetNoFormat","text":"<pre><code>from weather_tools.metno_models import MetNoFormat\n\nMetNoFormat.COMPACT   # default 9-day forecast with core variables\nMetNoFormat.COMPLETE  # extended payload with percentiles and extra fields\n</code></pre> <p>Use the enum when constructing <code>MetNoQuery</code> or when you need to select the endpoint manually.</p>"},{"location":"metno_models/#metnoquery","title":"MetNoQuery","text":"<p>Represents a validated met.no request:</p> <pre><code>from weather_tools.metno_models import MetNoQuery\nfrom weather_tools.silo_models import AustralianCoordinates\n\nquery = MetNoQuery(\n    coordinates=AustralianCoordinates(latitude=-33.86, longitude=151.21),\n    format=MetNoFormat.COMPACT,\n)\n\nparams = query.to_api_params()\n# {'lat': -33.86, 'lon': 151.21}\n</code></pre>"},{"location":"metno_models/#key-fields","title":"Key Fields","text":"Field Type Description <code>coordinates</code> Any (typically <code>AustralianCoordinates</code>) Validated latitude/longitude pair <code>format</code> <code>MetNoFormat</code> Forecast format (defaults to <code>COMPACT</code>) <p><code>to_api_params()</code> converts the model to the <code>lat</code>, <code>lon</code>, and optional <code>altitude</code> parameters required by met.no.</p>"},{"location":"metno_models/#metnoresponse","title":"MetNoResponse","text":"<p>Wraps the GeoJSON payload returned by met.no and tracks metadata:</p> <pre><code>from weather_tools.metno_models import MetNoResponse\n\nresponse = MetNoResponse(raw_data=payload, format=MetNoFormat.COMPACT, coordinates=query.coordinates)\n\ntimestamps = response.get_timeseries()\nmeta = response.get_meta()\n</code></pre>"},{"location":"metno_models/#fields","title":"Fields","text":"Field Type Description <code>raw_data</code> <code>Dict[str, Any]</code> GeoJSON response <code>format</code> <code>MetNoFormat</code> Format used for the request <code>coordinates</code> Any Coordinates associated with the forecast <code>generated_at</code> <code>datetime</code> Timestamp when the forecast was retrieved (<code>UTC</code>) <p>Utility methods: - <code>get_timeseries()</code> extracts the list of hourly forecast entries. - <code>get_meta()</code> returns the metadata embedded in the GeoJSON properties.</p>"},{"location":"metno_models/#forecasttimestamp","title":"ForecastTimestamp","text":"<p>Describes the data available for a single forecast time step. This model is mostly used internally when constructing daily summaries, but it can help with type hints if you build custom parsers.</p> <p>Important fields include: - <code>time</code> (<code>datetime</code>) \u2014 forecast timestamp (UTC). - Instantaneous variables: <code>air_temperature</code>, <code>relative_humidity</code>, <code>wind_speed</code>, <code>cloud_area_fraction</code>, <code>air_pressure_at_sea_level</code>. - Period values: <code>precipitation_amount</code>, <code>precipitation_period_hours</code>. - <code>weather_symbol</code> \u2014 the symbol code supplied by met.no summaries.</p>"},{"location":"metno_models/#dailyweathersummary","title":"DailyWeatherSummary","text":"<p>Aggregates hourly data into a daily rollup compatible with SILO daily schemata:</p> <pre><code>from weather_tools.metno_models import DailyWeatherSummary\n\nsummary = DailyWeatherSummary(\n    date=date(2024, 10, 12),\n    min_temperature=12.4,\n    max_temperature=23.1,\n    total_precipitation=5.8,\n)\n</code></pre> <p>Fields closely align with the columns produced by <code>MetNoAPI.to_dataframe(aggregate_to_daily=True)</code>:</p> Field Description <code>date</code> Python <code>date</code> for the summary <code>min_temperature</code> / <code>max_temperature</code> Daily temperature extremes (\u00b0C) <code>total_precipitation</code> Total rainfall (mm) <code>avg_wind_speed</code> / <code>max_wind_speed</code> Wind statistics (m/s) <code>avg_relative_humidity</code> Average humidity (%) <code>avg_pressure</code> Sea level pressure (hPa) <code>avg_cloud_fraction</code> Cloud cover (%) <code>dominant_weather_symbol</code> Most common or severe symbol code for the day <p>Use <code>.model_dump()</code> to serialize the summaries for DataFrame construction or downstream storage.</p>"},{"location":"metno_models/#error-hierarchy","title":"Error Hierarchy","text":"<p>The module also declares the exception hierarchy used by the API client:</p> <ul> <li><code>MetNoAPIError</code> \u2014 base exception for request failures.</li> <li><code>MetNoUserAgentError</code> \u2014 raised on HTTP 403 due to missing/invalid User-Agent.</li> <li><code>MetNoRateLimitError</code> \u2014 raised on HTTP 429 when rate limits are exceeded.</li> </ul> <p>Catch these to implement robust retry or messaging logic in your applications.</p>"},{"location":"metno_models/#next-steps","title":"Next Steps","text":"<ul> <li>Read the Met.no API Client guide for request patterns.</li> <li>Combine forecasts with historical data in Merge Weather Data.</li> <li>Explore the Forecast example notebook for an end-to-end workflow.</li> </ul>"},{"location":"silo_api/","title":"SILO API Module","text":"<p>The <code>silo_api</code> module provides a Python interface for querying the SILO (Scientific Information for Land Owners) API directly, allowing you to fetch weather data without downloading large netCDF files.</p>"},{"location":"silo_api/#features","title":"Features","text":"<ul> <li>\u2705 Two dataset types: PatchedPoint (station-based) and DataDrill (gridded)</li> <li>\u2705 Multiple formats: CSV, APSIM, and near-station search</li> <li>\u2705 Automatic retry logic with exponential backoff</li> <li>\u2705 Response caching to reduce redundant API calls</li> <li>\u2705 Date validation ensures correct YYYYMMDD format</li> <li>\u2705 Configurable timeouts and retry behavior</li> <li>\u2705 Comprehensive logging for debugging and monitoring</li> </ul>"},{"location":"silo_api/#installation","title":"Installation","text":"<p>The SILO API module is included with the weather_tools package:</p> <pre><code>pip install weather-tools\n</code></pre>"},{"location":"silo_api/#quick-start","title":"Quick Start","text":""},{"location":"silo_api/#basic-usage","title":"Basic Usage","text":"<pre><code>from weather_tools.silo_api import SiloAPI, SiloAPIError\n\n# Initialize the API client\napi = SiloAPI(api_key=\"your_silo_api_key\")\n\ntry:\n    # Query PatchedPoint data for a station\n    result = api.query(\n        dataset=\"PatchedPoint\",\n        format=\"csv\",\n        station_code=\"30043\",\n        start_date=\"20230101\",\n        end_date=\"20230131\",\n        values=[\"rain\", \"maxtemp\", \"mintemp\"]\n    )\n    print(result)\nexcept SiloAPIError as e:\n    print(f\"API Error: {e}\")\n</code></pre>"},{"location":"silo_api/#datadrill-gridded-data","title":"DataDrill (Gridded Data)","text":"<pre><code># Query DataDrill data for specific coordinates\nresult = api.query(\n    dataset=\"DataDrill\",\n    format=\"csv\",\n    longitude=151.0,\n    latitude=-27.5,\n    start_date=\"20230101\",\n    end_date=\"20230131\",\n    values=[\"rain\", \"maxtemp\", \"mintemp\"]\n)\n</code></pre>"},{"location":"silo_api/#configuration-options","title":"Configuration Options","text":""},{"location":"silo_api/#initialize-with-custom-settings","title":"Initialize with Custom Settings","text":"<pre><code>from weather_tools.silo_api import SiloAPI\n\napi = SiloAPI(\n    api_key=\"your_api_key\",\n    timeout=60,              # Request timeout in seconds (default: 30)\n    max_retries=5,           # Maximum retry attempts (default: 3)\n    retry_delay=2.0,         # Base delay between retries (default: 1.0)\n    enable_cache=True        # Enable response caching (default: False)\n)\n</code></pre>"},{"location":"silo_api/#configuration-parameters","title":"Configuration Parameters","text":"Parameter Type Default Description <code>api_key</code> str Required Your SILO API key <code>timeout</code> float 30 Request timeout in seconds <code>max_retries</code> int 3 Maximum number of retry attempts <code>retry_delay</code> float 1.0 Base delay between retries (exponential backoff) <code>enable_cache</code> bool False Enable response caching"},{"location":"silo_api/#api-methods","title":"API Methods","text":""},{"location":"silo_api/#query","title":"query()","text":"<p>Main method for querying the SILO API.</p> <pre><code>result = api.query(\n    dataset: str,\n    format: str = \"csv\",\n    station_code: Optional[str] = None,\n    longitude: Optional[float] = None,\n    latitude: Optional[float] = None,\n    start_date: Optional[str] = None,\n    end_date: Optional[str] = None,\n    values: Optional[List[str]] = None,\n    radius: Optional[float] = None\n) -&gt; Union[str, Dict[str, Any]]\n</code></pre> <p>Parameters:</p> <ul> <li><code>dataset</code>: 'PatchedPoint' or 'DataDrill'</li> <li><code>format</code>: 'csv', 'apsim', or 'near'</li> <li><code>station_code</code>: SILO station code (required for PatchedPoint)</li> <li><code>longitude</code>, <code>latitude</code>: Location coordinates (required for DataDrill)</li> <li><code>start_date</code>, <code>end_date</code>: Date range in YYYYMMDD format</li> <li><code>values</code>: List of weather variables to request</li> <li><code>radius</code>: Search radius for 'near' format</li> </ul> <p>Returns: - CSV/APSIM data as string - JSON data as dictionary (for non-standard formats)</p> <p>Raises: - <code>ValueError</code>: For invalid parameters - <code>SiloAPIError</code>: For API request failures</p>"},{"location":"silo_api/#cache-management","title":"Cache Management","text":"<pre><code># Get number of cached responses\ncache_size = api.get_cache_size()\n\n# Clear the cache\napi.clear_cache()\n</code></pre>"},{"location":"silo_api/#datasets-and-formats","title":"Datasets and Formats","text":""},{"location":"silo_api/#patchedpoint-dataset","title":"PatchedPoint Dataset","text":"<p>Station-based data with quality-controlled observations.</p> <p>Supported Formats: - <code>csv</code>: Comma-separated values - <code>apsim</code>: APSIM format - <code>near</code>: Find nearby stations</p> <p>Example:</p> <pre><code># CSV format\nresult = api.query(\n    dataset=\"PatchedPoint\",\n    format=\"csv\",\n    station_code=\"30043\",\n    start_date=\"20230101\",\n    end_date=\"20230131\",\n    values=[\"rain\", \"maxtemp\", \"mintemp\"]\n)\n\n# APSIM format\nresult = api.query(\n    dataset=\"PatchedPoint\",\n    format=\"apsim\",\n    station_code=\"30043\",\n    start_date=\"20230101\",\n    end_date=\"20230131\"\n)\n\n# Find nearby stations\nresult = api.query(\n    dataset=\"PatchedPoint\",\n    format=\"near\",\n    station_code=\"30043\",\n    radius=50.0  # Search radius in km\n)\n</code></pre>"},{"location":"silo_api/#datadrill-dataset","title":"DataDrill Dataset","text":"<p>Gridded data interpolated to specific coordinates.</p> <p>Supported Formats: - <code>csv</code>: Comma-separated values - <code>apsim</code>: APSIM format</p> <p>Example:</p> <pre><code>result = api.query(\n    dataset=\"DataDrill\",\n    format=\"csv\",\n    longitude=151.0,\n    latitude=-27.5,\n    start_date=\"20230101\",\n    end_date=\"20230131\",\n    values=[\"rain\", \"maxtemp\", \"mintemp\"]\n)\n</code></pre>"},{"location":"silo_api/#weather-variables","title":"Weather Variables","text":"<p>Common weather variables available from SILO:</p> <ul> <li><code>rain</code>: Daily rainfall (mm)</li> <li><code>maxtemp</code>: Maximum temperature (\u00b0C)</li> <li><code>mintemp</code>: Minimum temperature (\u00b0C)</li> <li><code>vp</code>: Vapor pressure (hPa)</li> <li><code>evap_pan</code>: Class A pan evaporation (mm)</li> <li><code>evap_syn</code>: Synthetic estimate of evaporation (mm)</li> <li><code>evap_comb</code>: Combination of measured and synthetic evaporation (mm)</li> <li><code>radiation</code>: Solar radiation (MJ/m\u00b2)</li> <li><code>rh_tmax</code>: Relative humidity at time of maximum temperature (%)</li> <li><code>rh_tmin</code>: Relative humidity at time of minimum temperature (%)</li> </ul>"},{"location":"silo_api/#error-handling","title":"Error Handling","text":""},{"location":"silo_api/#exception-types","title":"Exception Types","text":"<p>SiloAPIError: Raised for API-related errors</p> <pre><code>from weather_tools.silo_api import SiloAPI, SiloAPIError\n\ntry:\n    result = api.query(...)\nexcept SiloAPIError as e:\n    print(f\"API Error: {e}\")\n</code></pre> <p>ValueError: Raised for invalid input parameters</p> <pre><code>try:\n    result = api.query(\n        dataset=\"InvalidDataset\",\n        format=\"csv\"\n    )\nexcept ValueError as e:\n    print(f\"Invalid parameter: {e}\")\n</code></pre>"},{"location":"silo_api/#common-errors","title":"Common Errors","text":"<p>HTTP Errors (4xx, 5xx):</p> <pre><code>SiloAPIError: HTTP 404: Not Found\n</code></pre> <p>SILO-Specific Errors:</p> <pre><code>SiloAPIError: Sorry, your request was rejected\n</code></pre> <p>Timeout Errors (after retries):</p> <pre><code>SiloAPIError: Request failed after 3 attempts: Connection timeout\n</code></pre> <p>Invalid Dataset:</p> <pre><code>ValueError: Unknown dataset: InvalidDataset. Valid datasets: ['PatchedPoint', 'DataDrill']\n</code></pre> <p>Invalid Date Format:</p> <pre><code>ValueError: start_date must be in YYYYMMDD format (e.g., '20230101'), got: 2023-01-01\n</code></pre> <p>Missing Required Parameters:</p> <pre><code>ValueError: station_code is required for PatchedPoint queries\nValueError: longitude and latitude are required for DataDrill queries\n</code></pre>"},{"location":"silo_api/#advanced-features","title":"Advanced Features","text":""},{"location":"silo_api/#response-caching","title":"Response Caching","text":"<p>Enable caching to avoid redundant API calls:</p> <pre><code>import logging\n\n# Configure logging to see cache activity\nlogging.basicConfig(level=logging.INFO)\n\n# Create API with caching enabled\napi = SiloAPI(api_key=\"your_key\", enable_cache=True)\n\n# First query - hits the API\nresult1 = api.query(\n    dataset=\"PatchedPoint\",\n    station_code=\"30043\",\n    start_date=\"20230101\",\n    end_date=\"20230131\",\n    values=[\"rain\"]\n)\n\n# Second identical query - uses cache\nresult2 = api.query(\n    dataset=\"PatchedPoint\",\n    station_code=\"30043\",\n    start_date=\"20230101\",\n    end_date=\"20230131\",\n    values=[\"rain\"]\n)\n\nprint(f\"Cache size: {api.get_cache_size()}\")  # Output: 1\nprint(f\"Results identical: {result1 == result2}\")  # Output: True\n\n# Clear cache when done\napi.clear_cache()\n</code></pre>"},{"location":"silo_api/#automatic-retries","title":"Automatic Retries","text":"<p>The API automatically retries on transient failures:</p> <pre><code>api = SiloAPI(\n    api_key=\"your_key\",\n    max_retries=5,      # Retry up to 5 times\n    retry_delay=2.0     # 2 second base delay (with exponential backoff)\n)\n\n# API will automatically retry on:\n# - Connection timeouts\n# - Connection errors\n# But NOT on:\n# - HTTP 4xx/5xx errors\n# - SILO-specific rejection messages\n</code></pre>"},{"location":"silo_api/#logging-and-debugging","title":"Logging and Debugging","text":"<p>Enable detailed logging to monitor API activity:</p> <pre><code>import logging\n\n# Configure logging\nlogging.basicConfig(\n    level=logging.DEBUG,  # Show all logs\n    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'\n)\n\napi = SiloAPI(api_key=\"your_key\")\n\n# You'll see detailed logs:\n# - Request attempts\n# - Cache hits/misses\n# - Retry attempts\n# - Success/failure messages\n</code></pre>"},{"location":"silo_api/#production-configuration","title":"Production Configuration","text":"<p>Recommended settings for production use:</p> <pre><code>import os\nimport logging\n\n# Configure logging for production\nlogging.basicConfig(\n    level=logging.INFO,  # Only info and above\n    format='%(asctime)s - %(levelname)s - %(message)s'\n)\n\n# Load API key from environment variable\napi_key = os.getenv(\"SILO_API_KEY\")\n\nif not api_key:\n    raise ValueError(\"SILO_API_KEY environment variable not set\")\n\n# Create production-ready API client\napi = SiloAPI(\n    api_key=api_key,\n    timeout=60,              # Generous timeout\n    max_retries=5,           # More retries for reliability\n    retry_delay=2.0,         # Longer delays between retries\n    enable_cache=True        # Enable caching\n)\n\ntry:\n    result = api.query(...)\n    logging.info(f\"Query successful, cache size: {api.get_cache_size()}\")\nexcept SiloAPIError as e:\n    logging.error(f\"API error: {e}\")\n    # Handle error appropriately\n</code></pre>"},{"location":"silo_api/#cli-usage","title":"CLI Usage","text":"<p>The SILO API functionality is also available via the command-line interface:</p> <pre><code># Query PatchedPoint data\nweather-tools silo query --dataset PatchedPoint --station 30043 \\\n    --start-date 20230101 --end-date 20230131 \\\n    --variables rain,maxtemp,mintemp --output silo_data.csv\n\n# Query DataDrill data\nweather-tools silo query --dataset DataDrill --lat -27.5 --lon 151.0 \\\n    --start-date 20230101 --end-date 20230131 \\\n    --variables rain,maxtemp --output silo_data.csv\n\n# Find nearby stations\nweather-tools silo nearby --station 30043 --radius 50\n</code></pre> <p>See the CLI Reference for more details.</p>"},{"location":"silo_api/#getting-your-api-key","title":"Getting Your API Key","text":"<p>To use the SILO API, you need to obtain an API key:</p> <ol> <li>Visit the SILO website</li> <li>Register for API access</li> <li>Store your API key securely (use environment variables)</li> </ol> <p>Security Note: Never hardcode your API key in your source code. Use environment variables or secure configuration files:</p> <pre><code>import os\n\n# Load from environment variable\napi_key = os.getenv(\"SILO_API_KEY\")\n\n# Or use python-dotenv\nfrom dotenv import load_dotenv\nload_dotenv()\napi_key = os.getenv(\"SILO_API_KEY\")\n</code></pre>"},{"location":"silo_api/#best-practices","title":"Best Practices","text":"<ol> <li> <p>Use environment variables for API keys <code>python    api_key = os.getenv(\"SILO_API_KEY\")</code></p> </li> <li> <p>Enable caching for repeated queries <code>python    api = SiloAPI(api_key=key, enable_cache=True)</code></p> </li> <li> <p>Set appropriate timeouts    ```python    # Short timeout for quick checks    api = SiloAPI(api_key=key, timeout=10)</p> </li> </ol> <p># Longer timeout for large data downloads    api = SiloAPI(api_key=key, timeout=120)    ```</p> <ol> <li> <p>Handle exceptions appropriately <code>python    try:        result = api.query(...)    except ValueError as e:        # Handle input validation errors        logger.error(f\"Invalid input: {e}\")    except SiloAPIError as e:        # Handle API errors        logger.error(f\"API error: {e}\")</code></p> </li> <li> <p>Use logging in production <code>python    import logging    logging.basicConfig(        level=logging.WARNING,  # Only warnings and errors        format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'    )</code></p> </li> </ol>"},{"location":"silo_api/#data-models","title":"Data Models","text":"<p>The weather_tools package provides Pydantic models for structured API queries:</p>"},{"location":"silo_api/#patchedpointquery","title":"PatchedPointQuery","text":"<p>Model for PatchedPoint dataset queries:</p> <pre><code>from weather_tools import PatchedPointQuery\n\nquery = PatchedPointQuery(\n    station=\"30043\",\n    start_date=\"20230101\",\n    end_date=\"20230131\",\n    variables=[\"R\", \"X\", \"N\"],  # Rain, Max temp, Min temp\n    format=\"csv\"\n)\n</code></pre>"},{"location":"silo_api/#datadrillquery","title":"DataDrillQuery","text":"<p>Model for DataDrill dataset queries:</p> <pre><code>from weather_tools import DataDrillQuery\n\nquery = DataDrillQuery(\n    lat=-27.5,\n    lon=153.0,\n    start_date=\"20230101\", \n    end_date=\"20230131\",\n    variables=[\"R\", \"X\", \"N\"],\n    format=\"csv\"\n)\n</code></pre>"},{"location":"silo_api/#other-models","title":"Other Models","text":"<ul> <li><code>ClimateVariable</code>: Enum for valid climate variable codes</li> <li><code>SiloFormat</code>: Enum for output formats (csv, json, apsim, standard)</li> <li><code>SiloDataset</code>: Enum for dataset types (PatchedPoint, DataDrill)</li> <li><code>AustralianCoordinates</code>: Validator for Australian lat/lon coordinates</li> <li><code>SiloDateRange</code>: Validator for SILO date format (YYYYMMDD)</li> <li><code>SiloResponse</code>: Response wrapper with metadata</li> </ul> <p>These models provide validation, type hints, and automatic parameter generation for SILO API requests.</p>"},{"location":"silo_api/#see-also","title":"See Also","text":"<ul> <li>CLI Reference - Command-line interface documentation</li> <li>API Reference - Local netCDF file reading</li> <li>Examples - Jupyter notebook examples</li> </ul>"},{"location":"api_docs/read_silo/","title":"Read SILO","text":""},{"location":"api_docs/read_silo/#weather_tools.read_silo_xarray.read_silo_xarray","title":"<code>read_silo_xarray(variables='daily', silo_dir=Path.home() / 'Developer/DATA/silo_grids')</code>","text":"<p>Read SILO data from a directory containing the SILO netCDF files and return a merged xarray dataset.</p> <p>Parameters:</p> Name Type Description Default <code>variables</code> <code>list | str</code> <p>list of silo variable names matching the directory names, or a literal \"daily\"/\"monthly\". Defaults to \"daily\".</p> <code>'daily'</code> <code>silo_dir</code> <code>Path</code> <p>Path to the directory containing variable subdirectories (each containing .nc files). Defaults to Path.home()/\"Developer/DATA/silo_grids\". Expects the following structure:     ~/Developer/DATA/silo_grids     \u251c\u2500\u2500 daily_rain     \u251c\u2500\u2500 evap_syn     \u251c\u2500\u2500 max_temp     \u251c\u2500\u2500 min_temp     \u2514\u2500\u2500 monthly_rain         \u251c\u2500\u2500 ...         \u251c\u2500\u2500 2023.monthly_rain.nc         \u2514\u2500\u2500 2024.monthly_rain.nc</p> <code>home() / 'Developer/DATA/silo_grids'</code> <p>Returns:</p> Type Description <code>Dataset</code> <p>xr.Dataset: merged xarray Dataset containing the requested variables concatenated along the</p> <code>Dataset</code> <p>'time' dimension. Coordinates typically include 'time', 'lat', and 'lon'.</p> Example <p>from pathlib import Path from weather_tools.read_silo_xarray import read_silo_xarray</p> Source code in <code>src/weather_tools/read_silo_xarray.py</code> <pre><code>def read_silo_xarray(\n    variables: list | str = \"daily\",\n    silo_dir: Path = Path.home() / \"Developer/DATA/silo_grids\",\n) -&gt; xr.Dataset:\n    \"\"\"\n    Read SILO data from a directory containing the SILO netCDF files and return a merged xarray dataset.\n\n    Args:\n        variables: list of silo variable names matching the directory names, or a literal \"daily\"/\"monthly\".\n            Defaults to \"daily\".\n        silo_dir: Path to the directory containing variable subdirectories (each containing .nc files).\n            Defaults to Path.home()/\"Developer/DATA/silo_grids\".\n            Expects the following structure:\n                ~/Developer/DATA/silo_grids\n                \u251c\u2500\u2500 daily_rain\n                \u251c\u2500\u2500 evap_syn\n                \u251c\u2500\u2500 max_temp\n                \u251c\u2500\u2500 min_temp\n                \u2514\u2500\u2500 monthly_rain\n                    \u251c\u2500\u2500 ...\n                    \u251c\u2500\u2500 2023.monthly_rain.nc\n                    \u2514\u2500\u2500 2024.monthly_rain.nc\n\n    Returns:\n        xr.Dataset: merged xarray Dataset containing the requested variables concatenated along the\n        'time' dimension. Coordinates typically include 'time', 'lat', and 'lon'.\n\n    Example:\n        &gt;&gt;&gt; from pathlib import Path\n        &gt;&gt;&gt; from weather_tools.read_silo_xarray import read_silo_xarray\n        &gt;&gt;&gt; # Read the daily variables from the default silo_dir\n        &gt;&gt;&gt; ds = read_silo_xarray(variables=\"daily\")\n        &gt;&gt;&gt; print(ds)\n        &gt;&gt;&gt; # Or specify variables explicitly and a custom directory\n        &gt;&gt;&gt; ds2 = read_silo_xarray(variables=[\"monthly_rain\"], silo_dir=Path(\"/data/silo_grids\"))\n        &gt;&gt;&gt; make a smaller subset to reduce size in memeory\n        &gt;&gt;&gt; ds3 = read_silo_xarray().sel(lat=slice(-39, -26), lon=slice(133, 154), time=slice(\"2020-01-01\", \"2025-01-01\")).compute()\n        &gt;&gt;&gt; print(ds3)\n\n    \"\"\"\n    # Use centralized variable preset expansion\n    variables = expand_variable_preset(variables)\n\n    dss = []\n    for variable in variables:\n        # Convert generator to sorted list of file paths\n        file_paths = sorted((silo_dir / variable).glob(\"*.nc\"))\n\n        # Use open_mfdataset to open all years for a single variable\n        ds = xr.open_mfdataset(\n            file_paths,\n            chunks={\"time\": \"auto\"},\n            combine=\"nested\",  # Use nested combining for files that share dimensions\n            concat_dim=\"time\",  # Dimension along which to concatenate\n            data_vars=\"minimal\",  # Only data variables in which concat_dim appears are included\n            compat=\"no_conflicts\",  # Values must be equal or have disjoint (non-overlapping) coordinates\n            join=\"outer\",  # Use outer join for combining coordinates\n            # parallel=True  # Enable parallel processing if needed\n        ).sortby(\"time\")  # Ensure the 'time' dimension is sorted\n        dss.append(ds)\n\n    # merge combines different variables with the same dimensions (eg. time, lat, lon)\n    merged = xr.merge(dss, compat=\"override\")\n    [ds.close() for ds in dss]\n    return merged\n</code></pre>"},{"location":"api_docs/read_silo/#weather_tools.read_silo_xarray.read_silo_xarray--read-the-daily-variables-from-the-default-silo_dir","title":"Read the daily variables from the default silo_dir","text":"<p>ds = read_silo_xarray(variables=\"daily\") print(ds)</p>"},{"location":"api_docs/read_silo/#weather_tools.read_silo_xarray.read_silo_xarray--or-specify-variables-explicitly-and-a-custom-directory","title":"Or specify variables explicitly and a custom directory","text":"<p>ds2 = read_silo_xarray(variables=[\"monthly_rain\"], silo_dir=Path(\"/data/silo_grids\")) make a smaller subset to reduce size in memeory ds3 = read_silo_xarray().sel(lat=slice(-39, -26), lon=slice(133, 154), time=slice(\"2020-01-01\", \"2025-01-01\")).compute() print(ds3)</p>"},{"location":"notebooks/example/","title":"Local NetCDF","text":"In\u00a0[1]: Copied! <pre>import xarray as xr\nimport matplotlib.pyplot as plt\nplt.style.use('seaborn-v0_8-bright')\nfrom weather_tools.read_silo_xarray import read_silo_xarray\n\n# read a subset into memory to speed things up\n\nds = read_silo_xarray().sel(lat=slice(-39, -26), lon=slice(133, 154), time=slice(\"2020-01-01\", \"2025-01-01\")).compute()\n</pre> import xarray as xr import matplotlib.pyplot as plt plt.style.use('seaborn-v0_8-bright') from weather_tools.read_silo_xarray import read_silo_xarray  # read a subset into memory to speed things up  ds = read_silo_xarray().sel(lat=slice(-39, -26), lon=slice(133, 154), time=slice(\"2020-01-01\", \"2025-01-01\")).compute()  <p><code>read_silo_xarray</code> opens the netCDF files in the directory and merges them into a single xarray dataset.</p> <p>the dataset contains the following variables:</p> <ul> <li><p><code>min_temp</code>: minimum temperature in degrees Celsius</p> </li> <li><p><code>max_temp</code>: maximum temperature in degrees Celsius</p> </li> <li><p><code>daily_rain</code>: rainfall in mm</p> </li> <li><p><code>evap_syn</code>: evaporation in mm (synthetic estimate)</p> </li> </ul> <p>Others can be added by downloading the SILO data from the SILO website and adding them to the directory.</p> <p>the dataset object can then be subset to get the sepcific data you require.</p> In\u00a0[2]: Copied! <pre># plot raster of minimum temperature for a specific date\nds.sel(time=\"2021-07-28\").min_temp.plot.imshow()\n</pre> # plot raster of minimum temperature for a specific date ds.sel(time=\"2021-07-28\").min_temp.plot.imshow()  Out[2]: <pre>&lt;matplotlib.image.AxesImage at 0x1390b0230&gt;</pre> <p>Data for a specific location can be extracted by providing the latitude and longitude of the location.</p> <p>convert to pandas dataframe</p> In\u00a0[3]: Copied! <pre># Data for a specific location can be extracted by providing the latitude and longitude of the location.\nlat, lon = -36.6844306, 142.1867521\nyear = \"2021\"\n\nds_site = ds.sel(lat=lat, lon=lon, method=\"nearest\").sel(time=year)\n\n# convert to pandas dataframe\ndf = ds_site.to_pandas().drop(columns=[\"lat\", \"lon\", \"crs\"])\ndf.head()\n</pre> # Data for a specific location can be extracted by providing the latitude and longitude of the location. lat, lon = -36.6844306, 142.1867521 year = \"2021\"  ds_site = ds.sel(lat=lat, lon=lon, method=\"nearest\").sel(time=year)  # convert to pandas dataframe df = ds_site.to_pandas().drop(columns=[\"lat\", \"lon\", \"crs\"]) df.head() Out[3]: daily_rain max_temp min_temp evap_syn time 2021-01-01 0.0 33.4 14.5 7.7 2021-01-02 5.3 30.5 18.0 6.4 2021-01-03 1.4 28.9 13.2 7.2 2021-01-04 2.6 23.0 13.8 6.1 2021-01-05 0.0 23.2 12.9 6.0"},{"location":"notebooks/example/#example-notebook","title":"Example Notebook\u00b6","text":"<p>This package provides tools for working with SILO weather data.</p> <p>The function <code>read_silo_xarray</code> reads SILO data from a directory containing the SILO netCDF files and returns a merged xarray dataset.</p> <p>xarray uses lazy loading, so the data is not loaded into memory until you call a method that requires it.</p> <p>The <code>.compute()</code> method loads the data into memory.</p> <p>This can be faster than making multiple reads from disk, however it can also use a lot of memory.</p>"},{"location":"notebooks/example_plots/","title":"Plotting","text":"In\u00a0[3]: Copied! <pre>import xarray as xr\nimport matplotlib.pyplot as plt\nplt.style.use('seaborn-v0_8-bright')\nfrom weather_tools.read_silo_xarray import read_silo_xarray\n\n# read a subset into memory to speed things up\n\nds = read_silo_xarray().sel(lat=slice(-39, -26), lon=slice(133, 154), time=slice(\"2020-01-01\", \"2024-01-01\")).compute()\n</pre> import xarray as xr import matplotlib.pyplot as plt plt.style.use('seaborn-v0_8-bright') from weather_tools.read_silo_xarray import read_silo_xarray  # read a subset into memory to speed things up  ds = read_silo_xarray().sel(lat=slice(-39, -26), lon=slice(133, 154), time=slice(\"2020-01-01\", \"2024-01-01\")).compute()  <p>Example 1: Simple time series plot of minimum temperature for a specific location</p> In\u00a0[4]: Copied! <pre>lat, lon = -36.6844306, 142.1867521\nyear = \"2021\"\n\nds_site = ds.sel(lat=lat, lon=lon, method=\"nearest\").sel(time=year)\n\nds_site.min_temp.plot(figsize=(10, 6), marker=\"o\", linestyle=\"-\", label=\"Minimum Temperature\")\n\n\nplt.title(\"Minimum Temperature Time Series\")\nplt.ylabel(\"Temperature (\u00b0C)\")\nplt.grid(True)\nplt.legend()\n</pre> lat, lon = -36.6844306, 142.1867521 year = \"2021\"  ds_site = ds.sel(lat=lat, lon=lon, method=\"nearest\").sel(time=year)  ds_site.min_temp.plot(figsize=(10, 6), marker=\"o\", linestyle=\"-\", label=\"Minimum Temperature\")   plt.title(\"Minimum Temperature Time Series\") plt.ylabel(\"Temperature (\u00b0C)\") plt.grid(True) plt.legend()  Out[4]: <pre>&lt;matplotlib.legend.Legend at 0x12e477ad0&gt;</pre> <p>Example 2: Comparing multiple variables - min_temp and max_temp over time</p> In\u00a0[5]: Copied! <pre>fig, ax = plt.subplots(figsize=(12, 6))\nds_site.min_temp.plot(ax=ax, label=\"Min Temperature\")\nds_site.max_temp.plot(ax=ax, label=\"Max Temperature\")\nax.set_title(\"Temperature Range Over Time\")\nax.set_ylabel(\"Temperature (\u00b0C)\")\nax.grid(True)\nplt.legend()\n</pre> fig, ax = plt.subplots(figsize=(12, 6)) ds_site.min_temp.plot(ax=ax, label=\"Min Temperature\") ds_site.max_temp.plot(ax=ax, label=\"Max Temperature\") ax.set_title(\"Temperature Range Over Time\") ax.set_ylabel(\"Temperature (\u00b0C)\") ax.grid(True) plt.legend()  Out[5]: <pre>&lt;matplotlib.legend.Legend at 0x12abb7860&gt;</pre> <p>Example 3: Plotting a heatmap of maximum temperature for a month</p> In\u00a0[6]: Copied! <pre>ds.sel(time=\"2021-01-01\").max_temp.plot.pcolormesh(figsize=(10, 8), cmap=\"hot\", robust=True)\nplt.title(\"Maximum Temperature - January 2021\")\n</pre> ds.sel(time=\"2021-01-01\").max_temp.plot.pcolormesh(figsize=(10, 8), cmap=\"hot\", robust=True) plt.title(\"Maximum Temperature - January 2021\")  Out[6]: <pre>Text(0.5, 1.0, 'Maximum Temperature - January 2021')</pre> <p>Example 4: Creating a contour plot of rainfall</p> In\u00a0[7]: Copied! <pre>(\n    ds.sel(time=slice(\"2021-06-01\", \"2021-07-01\"))\n    .daily_rain.sum(dim=[\"time\"])\n    .plot.contourf(figsize=(10, 8), levels=10, cmap=\"Blues\")\n)\nplt.title(\"Rainfall Contour Map - February 2021\")\n</pre> (     ds.sel(time=slice(\"2021-06-01\", \"2021-07-01\"))     .daily_rain.sum(dim=[\"time\"])     .plot.contourf(figsize=(10, 8), levels=10, cmap=\"Blues\") ) plt.title(\"Rainfall Contour Map - February 2021\")  Out[7]: <pre>Text(0.5, 1.0, 'Rainfall Contour Map - February 2021')</pre> <p>Example 5: Seasonal average - create a multi-panel plot showing seasonal averages</p> In\u00a0[8]: Copied! <pre>seasons = {\"DJF\": [12, 1, 2], \"MAM\": [3, 4, 5], \"JJA\": [6, 7, 8], \"SON\": [9, 10, 11]}\nseasonal_data = {}\n\n# Filter and average by season\nfor season, months in seasons.items():\n    # For December, we need to use the previous year\n    if season == \"DJF\":\n        dec_data = ds.sel(time=((ds.time.dt.month == 12) &amp; (ds.time.dt.year == 2020)))\n        jan_feb_data = ds.sel(time=(ds.time.dt.month == 1) | (ds.time.dt.month == 2) &amp; (ds.time.dt.year == 2021))\n        seasonal_data[season] = xr.concat([dec_data, jan_feb_data], dim=\"time\").mean(\"time\")\n    else:\n        month_data = ds.sel(time=ds.time.dt.month.isin(months) &amp; (ds.time.dt.year == 2021))\n        seasonal_data[season] = month_data.mean(\"time\")\n\n# Create multi-panel plot\nfig, axes = plt.subplots(2, 2, figsize=(15, 12))\naxes = axes.flatten()\n\nfor i, (season, data) in enumerate(seasonal_data.items()):\n    data.daily_rain.plot(ax=axes[i], cmap=\"Blues\", robust=True)\n    axes[i].set_title(f\"Average Daily Rain - {season} 2021\")\n\nplt.tight_layout()\n</pre> seasons = {\"DJF\": [12, 1, 2], \"MAM\": [3, 4, 5], \"JJA\": [6, 7, 8], \"SON\": [9, 10, 11]} seasonal_data = {}  # Filter and average by season for season, months in seasons.items():     # For December, we need to use the previous year     if season == \"DJF\":         dec_data = ds.sel(time=((ds.time.dt.month == 12) &amp; (ds.time.dt.year == 2020)))         jan_feb_data = ds.sel(time=(ds.time.dt.month == 1) | (ds.time.dt.month == 2) &amp; (ds.time.dt.year == 2021))         seasonal_data[season] = xr.concat([dec_data, jan_feb_data], dim=\"time\").mean(\"time\")     else:         month_data = ds.sel(time=ds.time.dt.month.isin(months) &amp; (ds.time.dt.year == 2021))         seasonal_data[season] = month_data.mean(\"time\")  # Create multi-panel plot fig, axes = plt.subplots(2, 2, figsize=(15, 12)) axes = axes.flatten()  for i, (season, data) in enumerate(seasonal_data.items()):     data.daily_rain.plot(ax=axes[i], cmap=\"Blues\", robust=True)     axes[i].set_title(f\"Average Daily Rain - {season} 2021\")  plt.tight_layout()  <pre>/var/folders/b0/wq9x9vj13dv_75w41x6dmcyh0000gn/T/ipykernel_55348/806496851.py:10: FutureWarning: In a future version of xarray the default value for data_vars will change from data_vars='all' to data_vars=None. This is likely to lead to different results when multiple datasets have matching variables with overlapping values. To opt in to new defaults and get rid of these warnings now use `set_options(use_new_combine_kwarg_defaults=True) or set data_vars explicitly.\n  seasonal_data[season] = xr.concat([dec_data, jan_feb_data], dim=\"time\").mean(\"time\")\n</pre> <pre>\n---------------------------------------------------------------------------\nTypeError                                 Traceback (most recent call last)\nCell In[8], line 13\n     11     else:\n     12         month_data = ds.sel(time=ds.time.dt.month.isin(months) &amp; (ds.time.dt.year == 2021))\n---&gt; 13         seasonal_data[season] = month_data.mean(\"time\")\n     15 # Create multi-panel plot\n     16 fig, axes = plt.subplots(2, 2, figsize=(15, 12))\n\nFile ~/Developer/weather_tools/.venv/lib/python3.12/site-packages/xarray/core/_aggregations.py:1813, in DatasetAggregations.mean(self, dim, skipna, keep_attrs, **kwargs)\n   1735 def mean(\n   1736     self,\n   1737     dim: Dims = None,\n   (...)   1741     **kwargs: Any,\n   1742 ) -&gt; Self:\n   1743     \"\"\"\n   1744     Reduce this Dataset's data by applying ``mean`` along some dimension(s).\n   1745 \n   (...)   1811         da       float64 8B nan\n   1812     \"\"\"\n-&gt; 1813     return self.reduce(\n   1814         duck_array_ops.mean,\n   1815         dim=dim,\n   1816         skipna=skipna,\n   1817         numeric_only=True,\n   1818         keep_attrs=keep_attrs,\n   1819         **kwargs,\n   1820     )\n\nFile ~/Developer/weather_tools/.venv/lib/python3.12/site-packages/xarray/core/dataset.py:6869, in Dataset.reduce(self, func, dim, keep_attrs, keepdims, numeric_only, **kwargs)\n   6850     elif (\n   6851         # Some reduction functions (e.g. std, var) need to run on variables\n   6852         # that don't have the reduce dims: PR5393\n   (...)   6862         # the former is often more efficient\n   6863         # keep single-element dims as list, to support Hashables\n   6864         reduce_maybe_single = (\n   6865             None\n   6866             if len(reduce_dims) == var.ndim and var.ndim != 1\n   6867             else reduce_dims\n   6868         )\n-&gt; 6869         variables[name] = var.reduce(\n   6870             func,\n   6871             dim=reduce_maybe_single,\n   6872             keep_attrs=keep_attrs,\n   6873             keepdims=keepdims,\n   6874             **kwargs,\n   6875         )\n   6877 coord_names = {k for k in self.coords if k in variables}\n   6878 indexes = {k: v for k, v in self._indexes.items() if k in variables}\n\nFile ~/Developer/weather_tools/.venv/lib/python3.12/site-packages/xarray/core/variable.py:1766, in Variable.reduce(self, func, dim, axis, keep_attrs, keepdims, **kwargs)\n   1759 keep_attrs_ = (\n   1760     _get_keep_attrs(default=False) if keep_attrs is None else keep_attrs\n   1761 )\n   1763 # Note that the call order for Variable.mean is\n   1764 #    Variable.mean -&gt; NamedArray.mean -&gt; Variable.reduce\n   1765 #    -&gt; NamedArray.reduce\n-&gt; 1766 result = super().reduce(\n   1767     func=func, dim=dim, axis=axis, keepdims=keepdims, **kwargs\n   1768 )\n   1770 # return Variable always to support IndexVariable\n   1771 return Variable(\n   1772     result.dims, result._data, attrs=result._attrs if keep_attrs_ else None\n   1773 )\n\nFile ~/Developer/weather_tools/.venv/lib/python3.12/site-packages/xarray/namedarray/core.py:919, in NamedArray.reduce(self, func, dim, axis, keepdims, **kwargs)\n    917         data = func(self.data, axis=axis, **kwargs)\n    918     else:\n--&gt; 919         data = func(self.data, **kwargs)\n    921 if getattr(data, \"shape\", ()) == self.shape:\n    922     dims = self.dims\n\nFile ~/Developer/weather_tools/.venv/lib/python3.12/site-packages/xarray/core/duck_array_ops.py:777, in mean(array, axis, skipna, **kwargs)\n    775     return _to_pytimedelta(mean_timedeltas, unit=\"us\") + offset\n    776 else:\n--&gt; 777     return _mean(array, axis=axis, skipna=skipna, **kwargs)\n\nFile ~/Developer/weather_tools/.venv/lib/python3.12/site-packages/xarray/core/duck_array_ops.py:532, in _create_nan_agg_method.&lt;locals&gt;.f(values, axis, skipna, **kwargs)\n    530     with warnings.catch_warnings():\n    531         warnings.filterwarnings(\"ignore\", \"All-NaN slice encountered\")\n--&gt; 532         return func(values, axis=axis, **kwargs)\n    533 except AttributeError:\n    534     if not is_duck_dask_array(values):\n\nFile ~/Developer/weather_tools/.venv/lib/python3.12/site-packages/numpy/_core/fromnumeric.py:3860, in mean(a, axis, dtype, out, keepdims, where)\n   3857     else:\n   3858         return mean(axis=axis, dtype=dtype, out=out, **kwargs)\n-&gt; 3860 return _methods._mean(a, axis=axis, dtype=dtype,\n   3861                       out=out, **kwargs)\n\nFile ~/Developer/weather_tools/.venv/lib/python3.12/site-packages/numpy/_core/_methods.py:134, in _mean(a, axis, dtype, out, keepdims, where)\n    131         dtype = mu.dtype('f4')\n    132         is_float16_result = True\n--&gt; 134 ret = umr_sum(arr, axis, dtype, out, keepdims, where=where)\n    135 if isinstance(ret, mu.ndarray):\n    136     ret = um.true_divide(\n    137             ret, rcount, out=ret, casting='unsafe', subok=False)\n\nTypeError: the resolved dtypes are not compatible with add.reduce. Resolved (dtype('S1'), dtype('S1'), dtype('S2'))</pre> <p>Example 6: Creating a histogram of annual rainfall distribution in each grid cell.</p> In\u00a0[9]: Copied! <pre>ds.sel(time=\"2021\").daily_rain.sum(dim=[\"time\"]).plot.hist(figsize=(10, 6), bins=20)\nplt.title(\"Rainfall Distribution - 2021\")\nplt.xlabel(\"Rainfall (mm)\")\nplt.ylabel(\"Frequency\")\n</pre> ds.sel(time=\"2021\").daily_rain.sum(dim=[\"time\"]).plot.hist(figsize=(10, 6), bins=20) plt.title(\"Rainfall Distribution - 2021\") plt.xlabel(\"Rainfall (mm)\") plt.ylabel(\"Frequency\")  Out[9]: <pre>Text(0, 0.5, 'Frequency')</pre> <p>Example 7: hovmoller diagram (time vs. latitude)</p> In\u00a0[10]: Copied! <pre># Select a slice along a specific longitude\nhovmoller = ds.sel(lon=lon, method=\"nearest\").max_temp\nhovmoller.plot(x=\"time\", y=\"lat\", figsize=(12, 6), cmap=\"viridis\", robust=True)\nplt.title(f\"Hovmoller Diagram: Max Temperature across Latitudes (Longitude: {lon:.2f})\")\n</pre> # Select a slice along a specific longitude hovmoller = ds.sel(lon=lon, method=\"nearest\").max_temp hovmoller.plot(x=\"time\", y=\"lat\", figsize=(12, 6), cmap=\"viridis\", robust=True) plt.title(f\"Hovmoller Diagram: Max Temperature across Latitudes (Longitude: {lon:.2f})\")   Out[10]: <pre>Text(0.5, 1.0, 'Hovmoller Diagram: Max Temperature across Latitudes (Longitude: 142.19)')</pre> <p>Example 9: Facet plot for different variables</p> In\u00a0[11]: Copied! <pre>variables = [\"min_temp\", \"max_temp\", \"daily_rain\", \"evap_syn\"]\nfig, axes = plt.subplots(2, 2, figsize=(15, 12))\naxes = axes.flatten()\n\nfor i, var in enumerate(variables):\n    ds.sel(time=\"2021-07-28\")[var].plot(ax=axes[i])\n    axes[i].set_title(f\"{var} - 2021-07-28\")\n\nplt.tight_layout()\n</pre> variables = [\"min_temp\", \"max_temp\", \"daily_rain\", \"evap_syn\"] fig, axes = plt.subplots(2, 2, figsize=(15, 12)) axes = axes.flatten()  for i, var in enumerate(variables):     ds.sel(time=\"2021-07-28\")[var].plot(ax=axes[i])     axes[i].set_title(f\"{var} - 2021-07-28\")  plt.tight_layout()  <p>Example 10: Plot annual cycle using monthly averages for specific location</p> In\u00a0[16]: Copied! <pre># exclude the non-numeric 'crs' variable so mean() only applies to numeric data\nannual_cycle = ds_site.drop_vars(\"crs\").groupby(\"time.month\").mean()\nfig, ax = plt.subplots(figsize=(10, 6))\nannual_cycle.min_temp.plot(ax=ax, label=\"Min Temp\")\nannual_cycle.max_temp.plot(ax=ax, label=\"Max Temp\")\nannual_cycle.daily_rain.plot(ax=ax, label=\"Rainfall\", marker=\"o\", linestyle=\"-\")\nax.set_xticks(range(1, 13))\nax.set_xticklabels([\"Jan\", \"Feb\", \"Mar\", \"Apr\", \"May\", \"Jun\", \"Jul\", \"Aug\", \"Sep\", \"Oct\", \"Nov\", \"Dec\"])\nax.set_title(f\"Annual Weather Cycle at ({lat:.2f}, {lon:.2f}) - 2021\")\nax.set_xlabel(\"\")\nax.legend()\nplt.grid(True)\n</pre> # exclude the non-numeric 'crs' variable so mean() only applies to numeric data annual_cycle = ds_site.drop_vars(\"crs\").groupby(\"time.month\").mean() fig, ax = plt.subplots(figsize=(10, 6)) annual_cycle.min_temp.plot(ax=ax, label=\"Min Temp\") annual_cycle.max_temp.plot(ax=ax, label=\"Max Temp\") annual_cycle.daily_rain.plot(ax=ax, label=\"Rainfall\", marker=\"o\", linestyle=\"-\") ax.set_xticks(range(1, 13)) ax.set_xticklabels([\"Jan\", \"Feb\", \"Mar\", \"Apr\", \"May\", \"Jun\", \"Jul\", \"Aug\", \"Sep\", \"Oct\", \"Nov\", \"Dec\"]) ax.set_title(f\"Annual Weather Cycle at ({lat:.2f}, {lon:.2f}) - 2021\") ax.set_xlabel(\"\") ax.legend() plt.grid(True)  In\u00a0[\u00a0]: Copied! <pre>\n</pre>"},{"location":"notebooks/example_plots/#plotting-with-xarray","title":"Plotting with xarray\u00b6","text":"<p>xarray provides plotting functionality built on matplotlib. Here are various examples:</p>"},{"location":"notebooks/metno_forecast_example/","title":"Forecast data","text":"In\u00a0[1]: Copied! <pre>import pandas as pd\n\nfrom weather_tools.merge_weather_data import get_merge_summary, merge_historical_and_forecast\nfrom weather_tools.metno_api import MetNoAPI\nfrom weather_tools.metno_models import MetNoFormat, MetNoQuery\nfrom weather_tools.silo_api import SiloAPI\nfrom weather_tools.silo_models import AustralianCoordinates\n</pre> import pandas as pd  from weather_tools.merge_weather_data import get_merge_summary, merge_historical_and_forecast from weather_tools.metno_api import MetNoAPI from weather_tools.metno_models import MetNoFormat, MetNoQuery from weather_tools.silo_api import SiloAPI from weather_tools.silo_models import AustralianCoordinates  In\u00a0[12]: Copied! <pre># silo_api = SiloAPI(log_level=\"INFO\")\n# station_meta = silo_api.search_stations(\"Northam\").iloc[0]\n\nstation_meta = {'station_code': 10111,\n 'name': 'NORTHAM',\n 'latitude': -31.651,\n 'longitude': 116.659,\n 'state': 'WA',\n 'elevation': 170.0}\n</pre> # silo_api = SiloAPI(log_level=\"INFO\") # station_meta = silo_api.search_stations(\"Northam\").iloc[0]  station_meta = {'station_code': 10111,  'name': 'NORTHAM',  'latitude': -31.651,  'longitude': 116.659,  'state': 'WA',  'elevation': 170.0} In\u00a0[2]: Copied! <pre>api = MetNoAPI(\n    # user_agent=\"weather-tools-example/0.1 (contact: you@example.com)\",\n    enable_cache=True,\n    log_level=\"DEBUG\",\n)\n</pre> api = MetNoAPI(     # user_agent=\"weather-tools-example/0.1 (contact: you@example.com)\",     enable_cache=True,     log_level=\"DEBUG\", )  In\u00a0[13]: Copied! <pre>coordinates = AustralianCoordinates(latitude=station_meta['latitude'], longitude=station_meta['longitude'])  # Northam, WA\nquery = MetNoQuery(coordinates=coordinates, format=MetNoFormat.COMPACT)\n\nresponse = api.query_forecast(query)\nmetadata = response.get_meta()\n\nmetadata\n</pre> coordinates = AustralianCoordinates(latitude=station_meta['latitude'], longitude=station_meta['longitude'])  # Northam, WA query = MetNoQuery(coordinates=coordinates, format=MetNoFormat.COMPACT)  response = api.query_forecast(query) metadata = response.get_meta()  metadata  <pre>[10/24/25 11:13:31] INFO     Request successful on attempt 1                                                       \n</pre> Out[13]: <pre>{'updated_at': '2025-10-24T01:17:07Z',\n 'units': {'air_pressure_at_sea_level': 'hPa',\n  'air_temperature': 'celsius',\n  'cloud_area_fraction': '%',\n  'precipitation_amount': 'mm',\n  'relative_humidity': '%',\n  'wind_from_direction': 'degrees',\n  'wind_speed': 'm/s'}}</pre> In\u00a0[14]: Copied! <pre>daily_forecasts = api.to_dataframe(response, frequency='daily')\nhourly_forecasts = api.to_dataframe(response, frequency='hourly')\n\ndaily_forecasts.head()\n</pre> daily_forecasts = api.to_dataframe(response, frequency='daily') hourly_forecasts = api.to_dataframe(response, frequency='hourly')  daily_forecasts.head() Out[14]: date min_temperature max_temperature total_precipitation avg_wind_speed max_wind_speed avg_relative_humidity avg_pressure avg_cloud_fraction dominant_weather_symbol 0 2025-10-24 7.7 20.5 0.4 5.714286 10.1 66.847619 1009.771429 27.828571 lightrain 1 2025-10-25 9.3 23.0 0.0 4.237500 5.8 64.400000 1014.687500 40.420833 partlycloudy_day 2 2025-10-26 12.6 23.9 0.0 3.042105 5.1 49.726316 1017.521053 39.263158 partlycloudy_day 3 2025-10-27 15.8 26.5 0.0 2.875000 3.5 35.650000 1016.875000 0.000000 clearsky_day 4 2025-10-28 11.9 34.5 0.0 4.325000 7.1 47.750000 1008.800000 33.000000 partlycloudy_day In\u00a0[15]: Copied! <pre>hourly_forecasts.head()\n</pre> hourly_forecasts.head()  Out[15]: time air_pressure_at_sea_level air_temperature cloud_area_fraction relative_humidity wind_from_direction wind_speed precipitation_amount symbol_code 0 2025-10-24 03:00:00 1009.1 19.5 25.0 43.4 285.9 7.3 0.0 fair_day 1 2025-10-24 04:00:00 1008.6 20.2 12.5 38.1 288.6 7.8 0.0 clearsky_day 2 2025-10-24 05:00:00 1008.1 20.5 37.5 33.2 292.6 8.7 0.0 fair_day 3 2025-10-24 06:00:00 1008.0 19.5 93.7 37.0 282.7 10.1 0.1 lightrain 4 2025-10-24 07:00:00 1008.2 16.7 55.5 55.6 286.3 8.9 0.3 rainshowers_day In\u00a0[16]: Copied! <pre>daily_df = api.get_daily_forecast(\n    latitude=coordinates.latitude,\n    longitude=coordinates.longitude,\n    days=5,\n)\n\ndaily_df  # Already a DataFrame!\n</pre> daily_df = api.get_daily_forecast(     latitude=coordinates.latitude,     longitude=coordinates.longitude,     days=5, )  daily_df  # Already a DataFrame! Out[16]: date min_temperature max_temperature total_precipitation avg_wind_speed max_wind_speed avg_relative_humidity avg_pressure avg_cloud_fraction dominant_weather_symbol 0 2025-10-24 7.7 20.5 0.4 5.714286 10.1 66.847619 1009.771429 27.828571 lightrain 1 2025-10-25 9.3 23.0 0.0 4.237500 5.8 64.400000 1014.687500 40.420833 partlycloudy_day 2 2025-10-26 12.6 23.9 0.0 3.042105 5.1 49.726316 1017.521053 39.263158 partlycloudy_day 3 2025-10-27 15.8 26.5 0.0 2.875000 3.5 35.650000 1016.875000 0.000000 clearsky_day 4 2025-10-28 11.9 34.5 0.0 4.325000 7.1 47.750000 1008.800000 33.000000 partlycloudy_day In\u00a0[17]: Copied! <pre>first_forecast_date = pd.to_datetime(daily_df[\"date\"]).min()\n# history_end = first_forecast_date - pd.Timedelta(days=1)\nhistory_start = first_forecast_date - pd.Timedelta(days=4)\nsilo_api = SiloAPI(log_level=\"INFO\")\nsilo_history = silo_api.get_gridded_data(\n    latitude=coordinates.latitude,\n    longitude=coordinates.longitude,\n    start_date=history_start.strftime(\"%Y%m%d\"),\n    end_date=first_forecast_date.strftime(\"%Y%m%d\"),\n    variables=[\"rainfall\", \"max_temp\", \"min_temp\", \"evaporation\"],\n)\n\n# silo_history = raw_silo.rename(columns={\"YYYY-MM-DD\": \"date\"}).copy()\n\n# silo_history[\"date\"] = pd.to_datetime(silo_history[\"date\"])\n\n# required_cols = [\"date\", \"min_temp\", \"max_temp\", \"daily_rain\"]\n# missing = [col for col in required_cols if col not in silo_history.columns]\n# if missing:\n#     raise ValueError(f\"Missing required columns from SILO response: {missing}\")\n\n# silo_data = silo_history[required_cols].sort_values(\"date\").reset_index(drop=True)\n\nmerged = merge_historical_and_forecast(\n    silo_data=silo_history,\n    metno_data=daily_df,\n    overlap_strategy=\"prefer_silo\",\n    return_cols=\"silo_only\",\n)\n\nmerged\n</pre> first_forecast_date = pd.to_datetime(daily_df[\"date\"]).min() # history_end = first_forecast_date - pd.Timedelta(days=1) history_start = first_forecast_date - pd.Timedelta(days=4) silo_api = SiloAPI(log_level=\"INFO\") silo_history = silo_api.get_gridded_data(     latitude=coordinates.latitude,     longitude=coordinates.longitude,     start_date=history_start.strftime(\"%Y%m%d\"),     end_date=first_forecast_date.strftime(\"%Y%m%d\"),     variables=[\"rainfall\", \"max_temp\", \"min_temp\", \"evaporation\"], )  # silo_history = raw_silo.rename(columns={\"YYYY-MM-DD\": \"date\"}).copy()  # silo_history[\"date\"] = pd.to_datetime(silo_history[\"date\"])  # required_cols = [\"date\", \"min_temp\", \"max_temp\", \"daily_rain\"] # missing = [col for col in required_cols if col not in silo_history.columns] # if missing: #     raise ValueError(f\"Missing required columns from SILO response: {missing}\")  # silo_data = silo_history[required_cols].sort_values(\"date\").reset_index(drop=True)  merged = merge_historical_and_forecast(     silo_data=silo_history,     metno_data=daily_df,     overlap_strategy=\"prefer_silo\",     return_cols=\"silo_only\", )  merged  <pre>[10/24/25 11:14:05] INFO     Request successful on attempt 1                                                       \n</pre> <pre>                    INFO     Auto-detected transition date: 2025-10-24 00:00:00                                    \n</pre> <pre>                    INFO     Merged 4 SILO records with 5 met.no records. Total: 9 records                         \n</pre> Out[17]: latitude longitude daily_rain max_temp min_temp evap_pan date data_source is_forecast 0 -31.651 116.659 0.1 21.2 5.9 3.2 2025-10-20 silo False 1 -31.651 116.659 19.6 22.4 8.6 4.5 2025-10-21 silo False 2 -31.651 116.659 0.0 25.1 8.3 4.7 2025-10-22 silo False 3 -31.651 116.659 0.0 25.5 10.0 5.8 2025-10-23 silo False 4 NaN NaN 0.4 20.5 7.7 NaN 2025-10-24 metno True 5 NaN NaN 0.0 23.0 9.3 NaN 2025-10-25 metno True 6 NaN NaN 0.0 23.9 12.6 NaN 2025-10-26 metno True 7 NaN NaN 0.0 26.5 15.8 NaN 2025-10-27 metno True 8 NaN NaN 0.0 34.5 11.9 NaN 2025-10-28 metno True In\u00a0[19]: Copied! <pre>merge_summary = get_merge_summary(merged)\nmerge_summary\n</pre> merge_summary = get_merge_summary(merged) merge_summary  Out[19]: <pre>{'total_records': 9,\n 'silo_records': np.int64(4),\n 'metno_records': np.int64(5),\n 'date_range': {'start': Timestamp('2025-10-20 00:00:00'),\n  'end': Timestamp('2025-10-28 00:00:00'),\n  'days': 9},\n 'silo_period': {'start': Timestamp('2025-10-20 00:00:00'),\n  'end': Timestamp('2025-10-23 00:00:00')},\n 'metno_period': {'start': Timestamp('2025-10-24 00:00:00'),\n  'end': Timestamp('2025-10-28 00:00:00')},\n 'transition_date': Timestamp('2025-10-24 00:00:00')}</pre> In\u00a0[21]: Copied! <pre>first_forecast_date = pd.to_datetime(daily_forecasts[\"date\"]).min()\nhistory_end = first_forecast_date #- pd.Timedelta(days=1) # Include day before forecast to check overlap handling\nhistory_start = history_end - pd.Timedelta(days=4)\n\n\nsilo_station_data = silo_api.get_station_data(station_code=str(station_meta[\"station_code\"]),\n\t\t\t\t\t\t  start_date=history_start.strftime(\"%Y%m%d\"),\n\t\t\t\t\t\tend_date=history_end.strftime(\"%Y%m%d\"),\n\t\t\t\t\t\tvariables=[\"rainfall\", \"max_temp\", \"min_temp\", \"evaporation\"],\n\t\t)\n\nmerge_historical_and_forecast(\n    silo_data=silo_station_data,\n    metno_data=daily_df,\n\treturn_cols=\"silo_only\",\n)\n</pre>  first_forecast_date = pd.to_datetime(daily_forecasts[\"date\"]).min() history_end = first_forecast_date #- pd.Timedelta(days=1) # Include day before forecast to check overlap handling history_start = history_end - pd.Timedelta(days=4)   silo_station_data = silo_api.get_station_data(station_code=str(station_meta[\"station_code\"]), \t\t\t\t\t\t  start_date=history_start.strftime(\"%Y%m%d\"), \t\t\t\t\t\tend_date=history_end.strftime(\"%Y%m%d\"), \t\t\t\t\t\tvariables=[\"rainfall\", \"max_temp\", \"min_temp\", \"evaporation\"], \t\t)  merge_historical_and_forecast(     silo_data=silo_station_data,     metno_data=daily_df, \treturn_cols=\"silo_only\", ) <pre>[10/24/25 11:17:12] INFO     Request successful on attempt 1                                                       \n</pre> <pre>                    INFO     Auto-detected transition date: 2025-10-24 00:00:00                                    \n</pre> <pre>                    INFO     Merged 4 SILO records with 5 met.no records. Total: 9 records                         \n</pre> Out[21]: station daily_rain max_temp min_temp evap_pan date data_source is_forecast 0 10111.0 0.0 21.4 6.0 3.2 2025-10-20 silo False 1 10111.0 19.8 22.5 9.0 4.5 2025-10-21 silo False 2 10111.0 0.0 25.1 8.7 4.7 2025-10-22 silo False 3 10111.0 0.0 25.6 10.0 0.0 2025-10-23 silo False 4 NaN 0.4 20.5 7.7 NaN 2025-10-24 metno True 5 NaN 0.0 23.0 9.3 NaN 2025-10-25 metno True 6 NaN 0.0 23.9 12.6 NaN 2025-10-26 metno True 7 NaN 0.0 26.5 15.8 NaN 2025-10-27 metno True 8 NaN 0.0 34.5 11.9 NaN 2025-10-28 metno True"},{"location":"notebooks/metno_forecast_example/#using-metno-forecasts-with-weather-tools","title":"Using met.no forecasts with weather-tools\u00b6","text":"<p>This notebook-style script shows how to fetch met.no forecasts and combine them</p> <p>with SILO observations using the new <code>weather_tools</code> APIs. Open it directly in</p> <p>JupyterLab or VS Code with Jupytext to run the cells interactively.</p>"},{"location":"notebooks/metno_forecast_example/#prerequisites","title":"Prerequisites\u00b6","text":"<ul> <li><p>Network access to <code>https://api.met.no</code> and a valid contact e-mail for the User-Agent header.</p> </li> <li><p>Set <code>SILO_API_KEY</code> (your registered SILO e-mail) or pass <code>api_key=</code> directly to <code>SiloAPI</code>.</p> </li> <li><p>Install <code>weather-tools</code> in your environment (either via <code>pip install weather-tools</code> or the local checkout).</p> </li> <li><p>Optional: enable logging (e.g. <code>logging.basicConfig(level=logging.INFO)</code>) to inspect requests.</p> </li> </ul>"},{"location":"notebooks/metno_forecast_example/#1-configure-the-metno-api-client","title":"1. Configure the met.no API client\u00b6","text":"<p>met.no requires a descriptive User-Agent string that includes contact details.</p> <p>Replace the placeholder below with your own application name and e-mail.</p>"},{"location":"notebooks/metno_forecast_example/#2-build-a-forecast-query-for-your-location","title":"2. Build a forecast query for your location\u00b6","text":"<p>The <code>AustralianCoordinates</code> model validates that the latitude and longitude sit</p> <p>within the range supported by SILO (GDA94 datum). Adjust the coordinates to</p> <p>target your site of interest.</p>"},{"location":"notebooks/metno_forecast_example/#3-convert-forecasts-to-daily-and-hourly-tables","title":"3. Convert forecasts to daily and hourly tables\u00b6","text":"<p><code>MetNoAPI.to_dataframe</code> can aggregate the hourly GeoJSON payload to daily summaries</p> <p>or return hourly data. Use the <code>frequency</code> parameter to control aggregation:</p> <ul> <li><p><code>frequency='daily'</code> (default) - Daily aggregates</p> </li> <li><p><code>frequency='hourly'</code> - Raw hourly data</p> </li> <li><p><code>frequency='weekly'</code> or <code>frequency='monthly'</code> - Other time periods</p> </li> </ul>"},{"location":"notebooks/metno_forecast_example/#quick-helper-get_daily_forecast","title":"Quick helper: <code>get_daily_forecast</code>\u00b6","text":"<p><code>get_daily_forecast</code> returns a pandas DataFrame directly with daily summaries,</p>"},{"location":"notebooks/metno_forecast_example/#4-merge-metno-forecasts-with-silo-history","title":"4. Merge met.no forecasts with SILO history\u00b6","text":"<p>Pull the last five days from the SILO DataDrill API for the same coordinates,</p> <p>then merge that history with the met.no forecast. The helper automatically</p> <p>converts column names, fills optional variables (when enabled), and annotates</p> <p>the data source for each record.</p>"},{"location":"notebooks/metno_forecast_example/#4b-merge-forecast-with-silo-patchedpoint","title":"4b. Merge Forecast with SILO PatchedPoint\u00b6","text":"<p>Pull the last four days from the SILO Patch Point API for the same coordinates, using the station code.</p>"},{"location":"notebooks/silo_api_examples/","title":"SILO API","text":"In\u00a0[1]: Copied! <pre>import pandas as pd\nimport matplotlib.pyplot as plt\nimport numpy as np\nfrom datetime import datetime, timedelta\nimport os\n\n# Import the SILO API client\nfrom weather_tools.silo_api import SiloAPI\n\n# Set up plotting style\nplt.style.use('default')\nplt.rcParams['figure.figsize'] = (12, 6)\n\nprint(\"Libraries imported successfully!\")\n</pre> import pandas as pd import matplotlib.pyplot as plt import numpy as np from datetime import datetime, timedelta import os  # Import the SILO API client from weather_tools.silo_api import SiloAPI  # Set up plotting style plt.style.use('default') plt.rcParams['figure.figsize'] = (12, 6)  print(\"Libraries imported successfully!\")  <pre>Libraries imported successfully!\n</pre> In\u00a0[2]: Copied! <pre># Initialize the API client\n# Note: You need to set your SILO_API_KEY environment variable or provide your email as api_key\n# For this example, we'll use a placeholder - replace with your actual email\n\ntry:\n    # Try to use environment variable first\n    api = SiloAPI()  # Uses SILO_API_KEY environment variable\n    print(\"\u2705 API client initialized using SILO_API_KEY environment variable\")\nexcept ValueError:\n    # If no environment variable, use a placeholder (you should replace this with your email)\n    api = SiloAPI(api_key=\"your_email@example.com\")  # Replace with your email\n    print(\"\u26a0\ufe0f  API client initialized with placeholder email - replace with your actual email\")\n    print(\"   Set SILO_API_KEY environment variable or update the api_key parameter above\")\n</pre> # Initialize the API client # Note: You need to set your SILO_API_KEY environment variable or provide your email as api_key # For this example, we'll use a placeholder - replace with your actual email  try:     # Try to use environment variable first     api = SiloAPI()  # Uses SILO_API_KEY environment variable     print(\"\u2705 API client initialized using SILO_API_KEY environment variable\") except ValueError:     # If no environment variable, use a placeholder (you should replace this with your email)     api = SiloAPI(api_key=\"your_email@example.com\")  # Replace with your email     print(\"\u26a0\ufe0f  API client initialized with placeholder email - replace with your actual email\")     print(\"   Set SILO_API_KEY environment variable or update the api_key parameter above\")  <pre>\u2705 API client initialized using SILO_API_KEY environment variable\n</pre> In\u00a0[3]: Copied! <pre># Search for stations containing \"Brisbane\" in the name\nbrisbane_stations = api.search_stations(name_fragment=\"Brisbane\")\n\nprint(f\"Found {len(brisbane_stations)} stations with 'Brisbane' in the name:\")\nprint(\"\\nFirst 10 stations:\")\nprint(brisbane_stations.head(10).to_string(index=False))\n</pre> # Search for stations containing \"Brisbane\" in the name brisbane_stations = api.search_stations(name_fragment=\"Brisbane\")  print(f\"Found {len(brisbane_stations)} stations with 'Brisbane' in the name:\") print(\"\\nFirst 10 stations:\") print(brisbane_stations.head(10).to_string(index=False))    <pre>Found 7 stations with 'Brisbane' in the name:\n\nFirst 10 stations:\n station_code                       name  latitude  longitude state  elevation\n        40140                MT BRISBANE   -27.149    152.578   QLD      100.0\n        40214   BRISBANE REGIONAL OFFICE   -27.478    153.031   QLD       38.0\n        40215 BRISBANE BOTANICAL GARDENS   -27.483    153.033   QLD       15.0\n        40216      BRISBANE SHOW GROUNDS   -27.451    153.033   QLD       16.0\n        40223              BRISBANE AERO   -27.418    153.114   QLD        4.0\n        40842              BRISBANE AERO   -27.392    153.129   QLD        4.5\n        40913                   BRISBANE   -27.481    153.039   QLD        8.1\n</pre> In\u00a0[4]: Copied! <pre># Let's pick a specific Brisbane station for our examples\n# Brisbane Airport is station 30043 - a well-known station with good data coverage\nselected_station = \"30043\"\nstation_info = brisbane_stations.iloc[0]\n\nstation_name = station_info['name']\nstation_lat = station_info['latitude']\nstation_lon = station_info['longitude']\nprint(f\"Selected station: {station_name} (Code: {selected_station})\")\nprint(f\"Location: {station_lat}\u00b0S, {station_lon}\u00b0E\")\n</pre> # Let's pick a specific Brisbane station for our examples # Brisbane Airport is station 30043 - a well-known station with good data coverage selected_station = \"30043\" station_info = brisbane_stations.iloc[0]  station_name = station_info['name'] station_lat = station_info['latitude'] station_lon = station_info['longitude'] print(f\"Selected station: {station_name} (Code: {selected_station})\") print(f\"Location: {station_lat}\u00b0S, {station_lon}\u00b0E\")  <pre>Selected station: MT BRISBANE (Code: 30043)\nLocation: -27.149\u00b0S, 152.578\u00b0E\n</pre> In\u00a0[5]: Copied! <pre># Get weather data for January 2023\nstart_date = \"20230101\"\nend_date = \"20230131\"\nvariables = [\"rainfall\", \"max_temp\", \"min_temp\"]\n\nprint(f\"Getting weather data for station {selected_station} ({station_name})\")\nprint(f\"Date range: {start_date} to {end_date}\")\nprint(f\"Variables: {variables}\")\n\n# Get the data\nstation_data = api.get_station_data(\n    station_code=selected_station,\n    start_date=start_date,\n    end_date=end_date,\n    variables=variables\n)\n\nprint(f\"\\n\ud83d\udcca Retrieved {len(station_data)} days of data\")\nprint(\"\\nFirst 5 rows:\")\nprint(station_data.head())\n</pre> # Get weather data for January 2023 start_date = \"20230101\" end_date = \"20230131\" variables = [\"rainfall\", \"max_temp\", \"min_temp\"]  print(f\"Getting weather data for station {selected_station} ({station_name})\") print(f\"Date range: {start_date} to {end_date}\") print(f\"Variables: {variables}\")  # Get the data station_data = api.get_station_data(     station_code=selected_station,     start_date=start_date,     end_date=end_date,     variables=variables )  print(f\"\\n\ud83d\udcca Retrieved {len(station_data)} days of data\") print(\"\\nFirst 5 rows:\") print(station_data.head())  <pre>Getting weather data for station 30043 (MT BRISBANE)\nDate range: 20230101 to 20230131\nVariables: ['rainfall', 'max_temp', 'min_temp']\n\n\ud83d\udcca Retrieved 31 days of data\n\nFirst 5 rows:\n   station  YYYY-MM-DD  daily_rain  daily_rain_source  max_temp  \\\n0    30043  2023-01-01         0.0                 25      37.4   \n1    30043  2023-01-02         3.2                 25      35.3   \n2    30043  2023-01-03         9.3                 25      35.2   \n3    30043  2023-01-04         0.8                 25      35.3   \n4    30043  2023-01-05         4.4                 25      34.7   \n\n   max_temp_source  min_temp  min_temp_source  \\\n0               25      24.7               25   \n1               25      23.8               25   \n2               25      23.8               25   \n3               25      24.1               25   \n4               25      24.2               25   \n\n                                        metadata  \n0  name=PROA STATION                              \n1                             latitude= -20.8944  \n2                            longitude= 142.1436  \n3                             elevation= 170.0 m  \n4                                  reference=RXN  \n</pre> In\u00a0[6]: Copied! <pre># Let's also get the data with metadata to see what information is included\nstation_data_with_meta, metadata = api.get_station_data(\n    station_code=selected_station,\n    start_date=start_date,\n    end_date=end_date,\n    variables=variables,\n    return_metadata=True\n)\n\nprint(\"Metadata information:\")\nfor key, value in metadata.items():\n    print(f\"  {key}: {value}\")\n</pre> # Let's also get the data with metadata to see what information is included station_data_with_meta, metadata = api.get_station_data(     station_code=selected_station,     start_date=start_date,     end_date=end_date,     variables=variables,     return_metadata=True )  print(\"Metadata information:\") for key, value in metadata.items():     print(f\"  {key}: {value}\")  <pre>Metadata information:\n  station_code: 30043\n  date_range: {'start': '20230101', 'end': '20230131'}\n  variables: ['rainfall', 'max_temp', 'min_temp']\n  format: csv\n  dataset: PatchedPoint\n</pre> In\u00a0[7]: Copied! <pre># Create plots for the station data\nfig, axes = plt.subplots(2, 1, figsize=(14, 10))\n\n# Convert date column to datetime if it's not already\ndate_col = \"YYYY-MM-DD\"\nstation_data[date_col] = pd.to_datetime(station_data[date_col])\n\n\n# Plot 1: Temperature\n\naxes[0].plot(station_data[date_col], station_data[\"max_temp\"], 'r-', label='Max Temperature', linewidth=2)\naxes[0].plot(station_data[date_col], station_data[\"min_temp\"], 'b-', label='Min Temperature', linewidth=2)\n\naxes[0].set_title(f'Daily Temperature - {station_name} (January 2023)', fontsize=14, fontweight='bold')\naxes[0].set_ylabel('Temperature (\u00b0C)', fontsize=12)\naxes[0].legend()\naxes[0].grid(True, alpha=0.3)\n\n# Plot 2: Rainfall\nrain_cols = [col for col in station_data.columns if 'rain' in col.lower() or 'R_' in col]\nif rain_cols:\n    rain_col = rain_cols[0]\n    axes[1].bar(station_data[date_col], station_data[rain_col], color='skyblue', alpha=0.7, width=0.8)\n    axes[1].set_title(f'Daily Rainfall - {station_name} (January 2023)', fontsize=14, fontweight='bold')\n    axes[1].set_ylabel('Rainfall (mm)', fontsize=12)\n    axes[1].set_xlabel('Date', fontsize=12)\n    axes[1].grid(True, alpha=0.3)\n\nplt.tight_layout()\nplt.show()\n\n# Print some basic statistics\nprint(\"\\n\ud83d\udcc8 Basic Statistics:\")\nprint(station_data.describe())\n</pre> # Create plots for the station data fig, axes = plt.subplots(2, 1, figsize=(14, 10))  # Convert date column to datetime if it's not already date_col = \"YYYY-MM-DD\" station_data[date_col] = pd.to_datetime(station_data[date_col])   # Plot 1: Temperature  axes[0].plot(station_data[date_col], station_data[\"max_temp\"], 'r-', label='Max Temperature', linewidth=2) axes[0].plot(station_data[date_col], station_data[\"min_temp\"], 'b-', label='Min Temperature', linewidth=2)  axes[0].set_title(f'Daily Temperature - {station_name} (January 2023)', fontsize=14, fontweight='bold') axes[0].set_ylabel('Temperature (\u00b0C)', fontsize=12) axes[0].legend() axes[0].grid(True, alpha=0.3)  # Plot 2: Rainfall rain_cols = [col for col in station_data.columns if 'rain' in col.lower() or 'R_' in col] if rain_cols:     rain_col = rain_cols[0]     axes[1].bar(station_data[date_col], station_data[rain_col], color='skyblue', alpha=0.7, width=0.8)     axes[1].set_title(f'Daily Rainfall - {station_name} (January 2023)', fontsize=14, fontweight='bold')     axes[1].set_ylabel('Rainfall (mm)', fontsize=12)     axes[1].set_xlabel('Date', fontsize=12)     axes[1].grid(True, alpha=0.3)  plt.tight_layout() plt.show()  # Print some basic statistics print(\"\\n\ud83d\udcc8 Basic Statistics:\") print(station_data.describe())  <pre>\n\ud83d\udcc8 Basic Statistics:\n       station           YYYY-MM-DD  daily_rain  daily_rain_source   max_temp  \\\ncount     31.0                   31   31.000000               31.0  31.000000   \nmean   30043.0  2023-01-16 00:00:00    2.906452               25.0  35.990323   \nmin    30043.0  2023-01-01 00:00:00    0.000000               25.0  31.400000   \n25%    30043.0  2023-01-08 12:00:00    0.250000               25.0  34.450000   \n50%    30043.0  2023-01-16 00:00:00    1.300000               25.0  36.600000   \n75%    30043.0  2023-01-23 12:00:00    4.350000               25.0  38.300000   \nmax    30043.0  2023-01-31 00:00:00   19.200000               25.0  39.300000   \nstd        0.0                  NaN    4.026325                0.0   2.530264   \n\n       max_temp_source   min_temp  min_temp_source  \ncount             31.0  31.000000             31.0  \nmean              25.0  23.783871             25.0  \nmin               25.0  20.500000             25.0  \n25%               25.0  22.950000             25.0  \n50%               25.0  23.800000             25.0  \n75%               25.0  24.500000             25.0  \nmax               25.0  26.700000             25.0  \nstd                0.0   1.376734              0.0  \n</pre> In\u00a0[8]: Copied! <pre># Let's get gridded data for a location near our station\n# Using coordinates close to Brisbane Airport but slightly different\ntarget_lat = -27.5\ntarget_lon = 153.0\n\nprint(f\"Getting gridded climate data for coordinates: {target_lat}\u00b0S, {target_lon}\u00b0E\")\nprint(f\"Date range: {start_date} to {end_date}\")\nprint(f\"Variables: {variables}\")\n\n# Get gridded data\ngridded_data = api.get_gridded_data(\n    latitude=target_lat,\n    longitude=target_lon,\n    start_date=start_date,\n    end_date=end_date,\n    variables=variables\n)\n\nprint(f\"\\n\ud83d\udcca Retrieved {len(gridded_data)} days of gridded data\")\nprint(\"\\nFirst 5 rows:\")\nprint(gridded_data.head())\n</pre> # Let's get gridded data for a location near our station # Using coordinates close to Brisbane Airport but slightly different target_lat = -27.5 target_lon = 153.0  print(f\"Getting gridded climate data for coordinates: {target_lat}\u00b0S, {target_lon}\u00b0E\") print(f\"Date range: {start_date} to {end_date}\") print(f\"Variables: {variables}\")  # Get gridded data gridded_data = api.get_gridded_data(     latitude=target_lat,     longitude=target_lon,     start_date=start_date,     end_date=end_date,     variables=variables )  print(f\"\\n\ud83d\udcca Retrieved {len(gridded_data)} days of gridded data\") print(\"\\nFirst 5 rows:\") print(gridded_data.head())  <pre>Getting gridded climate data for coordinates: -27.5\u00b0S, 153.0\u00b0E\nDate range: 20230101 to 20230131\nVariables: ['rainfall', 'max_temp', 'min_temp']\n\n\ud83d\udcca Retrieved 31 days of gridded data\n\nFirst 5 rows:\n   latitude  longitude  YYYY-MM-DD  daily_rain  daily_rain_source  max_temp  \\\n0     -27.5      153.0  2023-01-01         0.2                 25      29.1   \n1     -27.5      153.0  2023-01-02         0.0                 25      29.5   \n2     -27.5      153.0  2023-01-03         0.0                 25      31.7   \n3     -27.5      153.0  2023-01-04         0.0                 25      32.7   \n4     -27.5      153.0  2023-01-05        37.3                 25      27.7   \n\n   max_temp_source  min_temp  min_temp_source  \\\n0               25      19.4               25   \n1               25      18.2               25   \n2               25      17.3               25   \n3               25      19.8               25   \n4               25      21.8               25   \n\n                                            metadata  \n0                                 elevation=  18.6 m  \n1                                      reference=RXN  \n2                                 extracted=20251022  \n3                                   dataset=BoM Only  \n4  Please read our web site for information about...  \n</pre> In\u00a0[9]: Copied! <pre># Compare station data vs gridded data\nfig, axes = plt.subplots(2, 2, figsize=(16, 10))\n\n# Helper function to find temperature and rainfall columns\ndef find_columns(df, pattern):\n    return [col for col in df.columns if any(p in col.lower() for p in pattern)]\n\n# Find date columns for both datasets\ndate_col = \"YYYY-MM-DD\"\nmax_temp = \"max_temp\"\nmin_temp = \"min_temp\"\n\n# Ensure dates are datetime\nstation_data[date_col] = pd.to_datetime(station_data[date_col])\ngridded_data[date_col] = pd.to_datetime(gridded_data[date_col])\n\n\n# Plot max temperature comparison\naxes[0,0].plot(station_data[date_col], station_data[max_temp], 'r-', label='Station Data', linewidth=2)\naxes[0,0].plot(gridded_data[date_col], gridded_data[max_temp], 'b--', label='Gridded Data', linewidth=2)\naxes[0,0].set_title('Max Temperature Comparison', fontweight='bold')\naxes[0,0].set_ylabel('Temperature (\u00b0C)')\naxes[0,0].legend()\naxes[0,0].grid(True, alpha=0.3)\n\n# Plot min temperature comparison\naxes[0,1].plot(station_data[date_col], station_data[min_temp], 'r-', label='Station Data', linewidth=2)\naxes[0,1].plot(gridded_data[date_col], gridded_data[min_temp], 'b--', label='Gridded Data', linewidth=2)\naxes[0,1].set_title('Min Temperature Comparison', fontweight='bold')\naxes[0,1].set_ylabel('Temperature (\u00b0C)')\naxes[0,1].legend()\naxes[0,1].grid(True, alpha=0.3)\n\n\nwidth = 0.35\nx = np.arange(len(station_data))\n\naxes[1,0].bar(x - width/2, station_data[\"daily_rain\"], width, label='Station Data', color='red', alpha=0.7)\naxes[1,0].bar(x + width/2, gridded_data[\"daily_rain\"], width, label='Gridded Data', color='blue', alpha=0.7)\naxes[1,0].set_title('Rainfall Comparison', fontweight='bold')\naxes[1,0].set_ylabel('Rainfall (mm)')\naxes[1,0].set_xlabel('Day of Month')\naxes[1,0].legend()\naxes[1,0].grid(True, alpha=0.3)\n\n# Scatter plot showing correlation\naxes[1,1].scatter(station_data[max_temp], gridded_data[max_temp], alpha=0.6, color='red', label='Max Temp')\naxes[1,1].scatter(station_data[min_temp], gridded_data[min_temp], alpha=0.6, color='blue', label='Min Temp')\n    \n# Add diagonal line for perfect correlation\nmin_temp = min(station_data[min_temp].min(), gridded_data[min_temp].min())\nmax_temp = max(station_data[max_temp].max(), gridded_data[max_temp].max())\naxes[1,1].plot([min_temp, max_temp], [min_temp, max_temp], 'k--', alpha=0.5, label='Perfect Correlation')\naxes[1,1].set_title('Station vs Gridded Data Correlation', fontweight='bold')\naxes[1,1].set_xlabel('Station Data (\u00b0C)')\naxes[1,1].set_ylabel('Gridded Data (\u00b0C)')\naxes[1,1].legend()\naxes[1,1].grid(True, alpha=0.3)\n\nplt.tight_layout()\nplt.show()\n\nprint(\"\\n\ud83d\udcca Data source comparison completed!\")\nprint(f\"Station location: {station_lat}\u00b0S, {station_lon}\u00b0E\")\nprint(f\"Gridded location: {target_lat}\u00b0S, {target_lon}\u00b0E\")\nprint(f\"Distance: ~{((station_lat - target_lat)**2 + (station_lon - target_lon)**2)**0.5 * 111:.1f} km\")\n</pre> # Compare station data vs gridded data fig, axes = plt.subplots(2, 2, figsize=(16, 10))  # Helper function to find temperature and rainfall columns def find_columns(df, pattern):     return [col for col in df.columns if any(p in col.lower() for p in pattern)]  # Find date columns for both datasets date_col = \"YYYY-MM-DD\" max_temp = \"max_temp\" min_temp = \"min_temp\"  # Ensure dates are datetime station_data[date_col] = pd.to_datetime(station_data[date_col]) gridded_data[date_col] = pd.to_datetime(gridded_data[date_col])   # Plot max temperature comparison axes[0,0].plot(station_data[date_col], station_data[max_temp], 'r-', label='Station Data', linewidth=2) axes[0,0].plot(gridded_data[date_col], gridded_data[max_temp], 'b--', label='Gridded Data', linewidth=2) axes[0,0].set_title('Max Temperature Comparison', fontweight='bold') axes[0,0].set_ylabel('Temperature (\u00b0C)') axes[0,0].legend() axes[0,0].grid(True, alpha=0.3)  # Plot min temperature comparison axes[0,1].plot(station_data[date_col], station_data[min_temp], 'r-', label='Station Data', linewidth=2) axes[0,1].plot(gridded_data[date_col], gridded_data[min_temp], 'b--', label='Gridded Data', linewidth=2) axes[0,1].set_title('Min Temperature Comparison', fontweight='bold') axes[0,1].set_ylabel('Temperature (\u00b0C)') axes[0,1].legend() axes[0,1].grid(True, alpha=0.3)   width = 0.35 x = np.arange(len(station_data))  axes[1,0].bar(x - width/2, station_data[\"daily_rain\"], width, label='Station Data', color='red', alpha=0.7) axes[1,0].bar(x + width/2, gridded_data[\"daily_rain\"], width, label='Gridded Data', color='blue', alpha=0.7) axes[1,0].set_title('Rainfall Comparison', fontweight='bold') axes[1,0].set_ylabel('Rainfall (mm)') axes[1,0].set_xlabel('Day of Month') axes[1,0].legend() axes[1,0].grid(True, alpha=0.3)  # Scatter plot showing correlation axes[1,1].scatter(station_data[max_temp], gridded_data[max_temp], alpha=0.6, color='red', label='Max Temp') axes[1,1].scatter(station_data[min_temp], gridded_data[min_temp], alpha=0.6, color='blue', label='Min Temp')      # Add diagonal line for perfect correlation min_temp = min(station_data[min_temp].min(), gridded_data[min_temp].min()) max_temp = max(station_data[max_temp].max(), gridded_data[max_temp].max()) axes[1,1].plot([min_temp, max_temp], [min_temp, max_temp], 'k--', alpha=0.5, label='Perfect Correlation') axes[1,1].set_title('Station vs Gridded Data Correlation', fontweight='bold') axes[1,1].set_xlabel('Station Data (\u00b0C)') axes[1,1].set_ylabel('Gridded Data (\u00b0C)') axes[1,1].legend() axes[1,1].grid(True, alpha=0.3)  plt.tight_layout() plt.show()  print(\"\\n\ud83d\udcca Data source comparison completed!\") print(f\"Station location: {station_lat}\u00b0S, {station_lon}\u00b0E\") print(f\"Gridded location: {target_lat}\u00b0S, {target_lon}\u00b0E\") print(f\"Distance: ~{((station_lat - target_lat)**2 + (station_lon - target_lon)**2)**0.5 * 111:.1f} km\")  <pre>\n\ud83d\udcca Data source comparison completed!\nStation location: -27.149\u00b0S, 152.578\u00b0E\nGridded location: -27.5\u00b0S, 153.0\u00b0E\nDistance: ~60.9 km\n</pre> In\u00a0[10]: Copied! <pre># Get recent data for our selected station (last 7 days)\nprint(f\"Getting recent data (last 7 days) for station {selected_station}\")\nrecent_station_data = api.get_recent_data(\n    station_code=selected_station,\n    days=7,\n    variables=[\"rainfall\", \"max_temp\", \"min_temp\"]\n)\n\nprint(f\"\ud83d\udcca Retrieved {len(recent_station_data)} days of recent station data\")\nprint(\"\\nRecent station data:\")\nprint(recent_station_data.head(10))\n</pre> # Get recent data for our selected station (last 7 days) print(f\"Getting recent data (last 7 days) for station {selected_station}\") recent_station_data = api.get_recent_data(     station_code=selected_station,     days=7,     variables=[\"rainfall\", \"max_temp\", \"min_temp\"] )  print(f\"\ud83d\udcca Retrieved {len(recent_station_data)} days of recent station data\") print(\"\\nRecent station data:\") print(recent_station_data.head(10))  <pre>Getting recent data (last 7 days) for station 30043\n\ud83d\udcca Retrieved 8 days of recent station data\n\nRecent station data:\n   station  YYYY-MM-DD  daily_rain  daily_rain_source  max_temp  \\\n0    30043  2025-10-15         4.1                 25      37.5   \n1    30043  2025-10-16         0.0                 25      37.8   \n2    30043  2025-10-17         0.0                 25      39.5   \n3    30043  2025-10-18         0.0                 25      40.9   \n4    30043  2025-10-19         0.0                 25      42.1   \n5    30043  2025-10-20         0.0                 25      41.9   \n6    30043  2025-10-21         0.0                 25      41.8   \n7    30043  2025-10-22         0.0                 25      36.1   \n\n   max_temp_source  min_temp  min_temp_source  \\\n0               25      21.0               25   \n1               25      22.1               25   \n2               25      21.5               25   \n3               25      19.1               25   \n4               25      21.4               25   \n5               25      22.3               25   \n6               25      22.7               25   \n7               75      23.6               25   \n\n                                            metadata  \n0      name=PROA STATION                              \n1                                 latitude= -20.8944  \n2                                longitude= 142.1436  \n3                                 elevation= 170.0 m  \n4                                      reference=RXN  \n5                                 extracted=20251022  \n6                                   dataset=BoM Only  \n7  Please read our web site for information about...  \n</pre> In\u00a0[11]: Copied! <pre># Get recent gridded data for our coordinates\nprint(f\"\\nGetting recent gridded data (last 7 days) for {target_lat}\u00b0S, {target_lon}\u00b0E\")\nrecent_gridded_data = api.get_recent_data(\n    latitude=target_lat,\n    longitude=target_lon,\n    days=7,\n    variables=[\"rainfall\", \"max_temp\", \"min_temp\"]\n)\n\nprint(f\"\ud83d\udcca Retrieved {len(recent_gridded_data)} days of recent gridded data\")\nprint(\"\\nRecent gridded data:\")\nprint(recent_gridded_data.head(10))\n</pre> # Get recent gridded data for our coordinates print(f\"\\nGetting recent gridded data (last 7 days) for {target_lat}\u00b0S, {target_lon}\u00b0E\") recent_gridded_data = api.get_recent_data(     latitude=target_lat,     longitude=target_lon,     days=7,     variables=[\"rainfall\", \"max_temp\", \"min_temp\"] )  print(f\"\ud83d\udcca Retrieved {len(recent_gridded_data)} days of recent gridded data\") print(\"\\nRecent gridded data:\") print(recent_gridded_data.head(10)) <pre>\nGetting recent gridded data (last 7 days) for -27.5\u00b0S, 153.0\u00b0E\n\ud83d\udcca Retrieved 8 days of recent gridded data\n\nRecent gridded data:\n   latitude  longitude  YYYY-MM-DD  daily_rain  daily_rain_source  max_temp  \\\n0     -27.5      153.0  2025-10-15         0.0                 25      28.2   \n1     -27.5      153.0  2025-10-16         0.0                 25      26.9   \n2     -27.5      153.0  2025-10-17         0.0                 25      28.9   \n3     -27.5      153.0  2025-10-18         0.0                 25      32.2   \n4     -27.5      153.0  2025-10-19         5.1                 25      29.3   \n5     -27.5      153.0  2025-10-20         0.0                 25      29.1   \n6     -27.5      153.0  2025-10-21         0.0                 25      31.0   \n7     -27.5      153.0  2025-10-22         0.0                 25      26.5   \n\n   max_temp_source  min_temp  min_temp_source  \\\n0               25      19.2               25   \n1               25      17.2               25   \n2               25      15.4               25   \n3               25      17.4               25   \n4               25      17.8               25   \n5               25      17.6               25   \n6               25      17.2               25   \n7               75      17.3               25   \n\n                                            metadata  \n0                                 elevation=  18.6 m  \n1                                      reference=RXN  \n2                                 extracted=20251022  \n3                                   dataset=BoM Only  \n4  Please read our web site for information about...  \n5                                                NaN  \n6                                                NaN  \n7                                                NaN  \n</pre> In\u00a0[12]: Copied! <pre># Tip 1: Getting all available variables\nprint(\"\ud83d\udca1 TIP 1: Getting all available climate variables\")\nprint(\"=\" * 50)\n\n# When variables=None, all available variables are retrieved\nall_vars_data = api.get_station_data(\n    station_code=selected_station,\n    start_date=\"20230101\",\n    end_date=\"20230105\",  # Just a few days to keep output manageable\n    variables=None  # This gets ALL available variables\n)\n\nprint(f\"Available columns when variables=None:\")\nfor i, col in enumerate(all_vars_data.columns, 1):\n    print(f\"  {i:2d}. {col}\")\n\nprint(f\"\\nDataFrame shape: {all_vars_data.shape[0]} rows \u00d7 {all_vars_data.shape[1]} columns\")\n</pre> # Tip 1: Getting all available variables print(\"\ud83d\udca1 TIP 1: Getting all available climate variables\") print(\"=\" * 50)  # When variables=None, all available variables are retrieved all_vars_data = api.get_station_data(     station_code=selected_station,     start_date=\"20230101\",     end_date=\"20230105\",  # Just a few days to keep output manageable     variables=None  # This gets ALL available variables )  print(f\"Available columns when variables=None:\") for i, col in enumerate(all_vars_data.columns, 1):     print(f\"  {i:2d}. {col}\")  print(f\"\\nDataFrame shape: {all_vars_data.shape[0]} rows \u00d7 {all_vars_data.shape[1]} columns\")  <pre>\ud83d\udca1 TIP 1: Getting all available climate variables\n==================================================\nAvailable columns when variables=None:\n   1. station\n   2. YYYY-MM-DD\n   3. daily_rain\n   4. daily_rain_source\n   5. max_temp\n   6. max_temp_source\n   7. min_temp\n   8. min_temp_source\n   9. evap_pan\n  10. evap_pan_source\n  11. radiation\n  12. radiation_source\n  13. vp\n  14. vp_source\n  15. metadata\n\nDataFrame shape: 8 rows \u00d7 15 columns\n</pre> In\u00a0[13]: Copied! <pre># Tip 2: Working with different time periods\nprint(\"\\n\ud83d\udca1 TIP 2: Working with different time periods\")\nprint(\"=\" * 50)\n\n# Get data for different months to compare\nmonths_data = {}\nmonths = [\n    (\"January\", \"20230101\", \"20230131\"),\n    (\"July\", \"20230701\", \"20230731\")\n]\n\nfor month_name, start, end in months:\n    try:\n        month_data = api.get_station_data(\n            station_code=selected_station,\n            start_date=start,\n            end_date=end,\n            variables=[\"max_temp\", \"min_temp\", \"rainfall\"]\n        )\n        months_data[month_name] = month_data\n        print(f\"{month_name} 2023: {len(month_data)} days of data retrieved\")\n    except Exception as e:\n        print(f\"Error getting {month_name} data: {e}\")\n\n# Compare the months\nif len(months_data) == 2:\n    jan_data = months_data[\"January\"]\n    jul_data = months_data[\"July\"]\n    \n    jan_max_col = find_columns(jan_data, ['max', 'T_max'])[0] if find_columns(jan_data, ['max', 'T_max']) else None\n    jul_max_col = find_columns(jul_data, ['max', 'T_max'])[0] if find_columns(jul_data, ['max', 'T_max']) else None\n    \n    if jan_max_col and jul_max_col:\n        print(f\"\\nSeasonal comparison:\")\n        print(f\"  January average max temp: {jan_data[jan_max_col].mean():.1f}\u00b0C\")\n        print(f\"  July average max temp: {jul_data[jul_max_col].mean():.1f}\u00b0C\")\n        print(f\"  Seasonal difference: {jan_data[jan_max_col].mean() - jul_data[jul_max_col].mean():.1f}\u00b0C\")\n</pre> # Tip 2: Working with different time periods print(\"\\n\ud83d\udca1 TIP 2: Working with different time periods\") print(\"=\" * 50)  # Get data for different months to compare months_data = {} months = [     (\"January\", \"20230101\", \"20230131\"),     (\"July\", \"20230701\", \"20230731\") ]  for month_name, start, end in months:     try:         month_data = api.get_station_data(             station_code=selected_station,             start_date=start,             end_date=end,             variables=[\"max_temp\", \"min_temp\", \"rainfall\"]         )         months_data[month_name] = month_data         print(f\"{month_name} 2023: {len(month_data)} days of data retrieved\")     except Exception as e:         print(f\"Error getting {month_name} data: {e}\")  # Compare the months if len(months_data) == 2:     jan_data = months_data[\"January\"]     jul_data = months_data[\"July\"]          jan_max_col = find_columns(jan_data, ['max', 'T_max'])[0] if find_columns(jan_data, ['max', 'T_max']) else None     jul_max_col = find_columns(jul_data, ['max', 'T_max'])[0] if find_columns(jul_data, ['max', 'T_max']) else None          if jan_max_col and jul_max_col:         print(f\"\\nSeasonal comparison:\")         print(f\"  January average max temp: {jan_data[jan_max_col].mean():.1f}\u00b0C\")         print(f\"  July average max temp: {jul_data[jul_max_col].mean():.1f}\u00b0C\")         print(f\"  Seasonal difference: {jan_data[jan_max_col].mean() - jul_data[jul_max_col].mean():.1f}\u00b0C\")  <pre>\n\ud83d\udca1 TIP 2: Working with different time periods\n==================================================\nJanuary 2023: 31 days of data retrieved\nJuly 2023: 31 days of data retrieved\n\nSeasonal comparison:\n  January average max temp: 36.0\u00b0C\n  July average max temp: 25.8\u00b0C\n  Seasonal difference: 10.2\u00b0C\n</pre> In\u00a0[14]: Copied! <pre># Tip 3: Error handling and data validation\nprint(\"\\n\ud83d\udca1 TIP 3: Error handling and data validation\")\nprint(\"=\" * 50)\n\ndef safe_get_station_data(api, station_code, start_date, end_date, variables=None):\n    \"\"\"\n    Safely get station data with error handling and validation.\n    \"\"\"\n    try:\n        data = api.get_station_data(\n            station_code=station_code,\n            start_date=start_date,\n            end_date=end_date,\n            variables=variables\n        )\n        \n        # Validate the data\n        if data.empty:\n            print(f\"\u26a0\ufe0f Warning: No data returned for station {station_code}\")\n            return None\n            \n        # Check for missing values\n        missing_data = safe_data.drop(columns=\"metadata\").isnull().sum()\n        if missing_data.any():\n            print(f\"\ud83d\udcca Data quality report for station {station_code}:\")\n            for col, missing_count in missing_data.items():\n                if missing_count &gt; 0:\n                    percentage = (missing_count / len(data)) * 100\n                    print(f\"   {col}: {missing_count} missing values ({percentage:.1f}%)\")\n        else:\n            print(f\"\u2705 Data quality: No missing values found\")\n            \n        return data\n        \n    except Exception as e:\n        print(f\"\u274c Error getting data for station {station_code}: {e}\")\n        return None\n\n# Test the safe function\nsafe_data = safe_get_station_data(\n    api, \n    selected_station, \n    \"20230101\", \n    \"20230131\", \n    [\"rainfall\", \"max_temp\"]\n)\n\nif safe_data is not None:\n    print(f\"Successfully retrieved {len(safe_data)} days of data\")\n</pre> # Tip 3: Error handling and data validation print(\"\\n\ud83d\udca1 TIP 3: Error handling and data validation\") print(\"=\" * 50)  def safe_get_station_data(api, station_code, start_date, end_date, variables=None):     \"\"\"     Safely get station data with error handling and validation.     \"\"\"     try:         data = api.get_station_data(             station_code=station_code,             start_date=start_date,             end_date=end_date,             variables=variables         )                  # Validate the data         if data.empty:             print(f\"\u26a0\ufe0f Warning: No data returned for station {station_code}\")             return None                      # Check for missing values         missing_data = safe_data.drop(columns=\"metadata\").isnull().sum()         if missing_data.any():             print(f\"\ud83d\udcca Data quality report for station {station_code}:\")             for col, missing_count in missing_data.items():                 if missing_count &gt; 0:                     percentage = (missing_count / len(data)) * 100                     print(f\"   {col}: {missing_count} missing values ({percentage:.1f}%)\")         else:             print(f\"\u2705 Data quality: No missing values found\")                      return data              except Exception as e:         print(f\"\u274c Error getting data for station {station_code}: {e}\")         return None  # Test the safe function safe_data = safe_get_station_data(     api,      selected_station,      \"20230101\",      \"20230131\",      [\"rainfall\", \"max_temp\"] )  if safe_data is not None:     print(f\"Successfully retrieved {len(safe_data)} days of data\")  <pre>\n\ud83d\udca1 TIP 3: Error handling and data validation\n==================================================\n\u274c Error getting data for station 30043: name 'safe_data' is not defined\n</pre>"},{"location":"notebooks/silo_api_examples/#silo-api-simple-interface-examples","title":"SILO API Simple Interface Examples\u00b6","text":"<p>This notebook demonstrates the simple, high-level interface methods in the SILO API client. These methods provide an easy way to access Australian climate data without needing to work with complex Pydantic models.</p>"},{"location":"notebooks/silo_api_examples/#available-simple-methods","title":"Available Simple Methods\u00b6","text":"<ul> <li><p><code>get_station_data()</code> - Get weather station data using simple string parameters</p> </li> <li><p><code>get_gridded_data()</code> - Get climate data for any coordinates using lat/lon</p> </li> <li><p><code>search_stations()</code> - Search for weather stations by name or state</p> </li> <li><p><code>get_recent_data()</code> - Quick access to recent data (last N days)</p> </li> </ul>"},{"location":"notebooks/silo_api_examples/#setup","title":"Setup\u00b6","text":"<p>First, let's import the required libraries and set up our API client.</p>"},{"location":"notebooks/silo_api_examples/#1-searching-for-weather-stations","title":"1. Searching for Weather Stations\u00b6","text":"<p>Let's start by finding weather stations. The <code>search_stations()</code> method makes it easy to find stations by name or state.</p>"},{"location":"notebooks/silo_api_examples/#2-getting-weather-station-data","title":"2. Getting Weather Station Data\u00b6","text":"<p>Now let's get some historical weather data for our selected station using the <code>get_station_data()</code> method.</p>"},{"location":"notebooks/silo_api_examples/#3-visualizing-station-data","title":"3. Visualizing Station Data\u00b6","text":"<p>Let's create some plots to visualize the weather data we retrieved.</p>"},{"location":"notebooks/silo_api_examples/#4-getting-gridded-data-for-any-coordinates","title":"4. Getting Gridded Data for Any Coordinates\u00b6","text":"<p>The <code>get_gridded_data()</code> method allows you to get climate data for any latitude/longitude coordinates, even where there's no weather station.</p>"},{"location":"notebooks/silo_api_examples/#5-getting-recent-data","title":"5. Getting Recent Data\u00b6","text":"<p>The <code>get_recent_data()</code> method provides a quick way to get recent weather data for the last N days.</p>"},{"location":"notebooks/silo_api_examples/#6-data-processing-and-analysis","title":"6. Data Processing and Analysis\u00b6","text":"<p>Let's perform some basic analysis on our data to show how easy it is to work with the DataFrames returned by the API.</p>"},{"location":"notebooks/silo_api_examples/#7-advanced-usage-tips","title":"7. Advanced Usage Tips\u00b6","text":"<p>Here are some advanced tips for using the SILO API simple interface methods effectively.</p>"}]}